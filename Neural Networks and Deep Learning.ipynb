{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instalação do pacote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.1.7)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.24.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.16.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.33.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: h5py in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: keras in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from keras) (1.16.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from keras) (1.3.1)\n",
      "Requirement already satisfied: h5py in /Users/igorjuliopimenta/anaconda3/lib/python3.7/site-packages (from keras) (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow\n",
    "! pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "base = datasets.load_iris()\n",
    "\n",
    "previsores = base.data\n",
    "classe = base.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settar a quantidade de neurônios a partir da quantidade de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "classe_dummy = np_utils.to_categorical(classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declarar variáveis para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(previsores,\n",
    "                                                    classe_dummy,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "modelo = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definir quantidade de neurônios nas camadas ocultas, na de entrada e na de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "modelo.add(Dense(units = 5, input_dim = np.shape(X_train)[1]))\n",
    "modelo.add(Dense(units = 4))\n",
    "modelo.add(Dense(units = np.shape(classe_dummy)[1], activation = 'softmax')) # softmax é utilizado quando houver mais de duas classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 24        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 64\n",
      "Trainable params: 64\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer = 'adam', # algoritmo utilizado\n",
    "               loss = 'categorical_crossentropy', # quando houver mais de duas classes\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/1000\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 2.8032 - accuracy: 0.3714 - val_loss: 3.2266 - val_accuracy: 0.2444\n",
      "Epoch 2/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 2.6715 - accuracy: 0.3619 - val_loss: 3.0637 - val_accuracy: 0.2444\n",
      "Epoch 3/1000\n",
      "105/105 [==============================] - 0s 86us/step - loss: 2.5483 - accuracy: 0.3524 - val_loss: 2.9157 - val_accuracy: 0.2222\n",
      "Epoch 4/1000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 2.4261 - accuracy: 0.3333 - val_loss: 2.7835 - val_accuracy: 0.2000\n",
      "Epoch 5/1000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 2.3409 - accuracy: 0.3238 - val_loss: 2.6640 - val_accuracy: 0.2000\n",
      "Epoch 6/1000\n",
      "105/105 [==============================] - 0s 75us/step - loss: 2.2538 - accuracy: 0.3048 - val_loss: 2.5619 - val_accuracy: 0.2000\n",
      "Epoch 7/1000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 2.1819 - accuracy: 0.3048 - val_loss: 2.4705 - val_accuracy: 0.2000\n",
      "Epoch 8/1000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 2.1114 - accuracy: 0.3048 - val_loss: 2.3889 - val_accuracy: 0.2000\n",
      "Epoch 9/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 2.0470 - accuracy: 0.3048 - val_loss: 2.3124 - val_accuracy: 0.2000\n",
      "Epoch 10/1000\n",
      "105/105 [==============================] - 0s 72us/step - loss: 1.9917 - accuracy: 0.3048 - val_loss: 2.2381 - val_accuracy: 0.2000\n",
      "Epoch 11/1000\n",
      "105/105 [==============================] - 0s 74us/step - loss: 1.9326 - accuracy: 0.3048 - val_loss: 2.1716 - val_accuracy: 0.2000\n",
      "Epoch 12/1000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 1.8769 - accuracy: 0.3048 - val_loss: 2.1101 - val_accuracy: 0.2000\n",
      "Epoch 13/1000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 1.8261 - accuracy: 0.3048 - val_loss: 2.0483 - val_accuracy: 0.2000\n",
      "Epoch 14/1000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 1.7744 - accuracy: 0.3048 - val_loss: 1.9900 - val_accuracy: 0.2000\n",
      "Epoch 15/1000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.7270 - accuracy: 0.3048 - val_loss: 1.9309 - val_accuracy: 0.2000\n",
      "Epoch 16/1000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 1.6810 - accuracy: 0.3048 - val_loss: 1.8747 - val_accuracy: 0.2000\n",
      "Epoch 17/1000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 1.6346 - accuracy: 0.3048 - val_loss: 1.8250 - val_accuracy: 0.2000\n",
      "Epoch 18/1000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 1.5906 - accuracy: 0.3048 - val_loss: 1.7743 - val_accuracy: 0.2000\n",
      "Epoch 19/1000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 1.5546 - accuracy: 0.2952 - val_loss: 1.7229 - val_accuracy: 0.2000\n",
      "Epoch 20/1000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 1.5134 - accuracy: 0.2952 - val_loss: 1.6763 - val_accuracy: 0.2000\n",
      "Epoch 21/1000\n",
      "105/105 [==============================] - 0s 82us/step - loss: 1.4759 - accuracy: 0.2952 - val_loss: 1.6319 - val_accuracy: 0.2000\n",
      "Epoch 22/1000\n",
      "105/105 [==============================] - 0s 209us/step - loss: 1.4378 - accuracy: 0.2952 - val_loss: 1.5900 - val_accuracy: 0.2000\n",
      "Epoch 23/1000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.4025 - accuracy: 0.2952 - val_loss: 1.5505 - val_accuracy: 0.2000\n",
      "Epoch 24/1000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 1.3688 - accuracy: 0.3048 - val_loss: 1.5126 - val_accuracy: 0.2000\n",
      "Epoch 25/1000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 1.3369 - accuracy: 0.3048 - val_loss: 1.4784 - val_accuracy: 0.2000\n",
      "Epoch 26/1000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 1.3056 - accuracy: 0.3143 - val_loss: 1.4454 - val_accuracy: 0.2000\n",
      "Epoch 27/1000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 1.2761 - accuracy: 0.3143 - val_loss: 1.4101 - val_accuracy: 0.2000\n",
      "Epoch 28/1000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 1.2468 - accuracy: 0.3143 - val_loss: 1.3782 - val_accuracy: 0.2000\n",
      "Epoch 29/1000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 1.2183 - accuracy: 0.3143 - val_loss: 1.3482 - val_accuracy: 0.2000\n",
      "Epoch 30/1000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 1.1917 - accuracy: 0.3143 - val_loss: 1.3171 - val_accuracy: 0.2000\n",
      "Epoch 31/1000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 1.1644 - accuracy: 0.3429 - val_loss: 1.2851 - val_accuracy: 0.2000\n",
      "Epoch 32/1000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 1.1389 - accuracy: 0.3429 - val_loss: 1.2542 - val_accuracy: 0.2222\n",
      "Epoch 33/1000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 1.1131 - accuracy: 0.3524 - val_loss: 1.2252 - val_accuracy: 0.2222\n",
      "Epoch 34/1000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 1.0899 - accuracy: 0.3619 - val_loss: 1.1974 - val_accuracy: 0.2222\n",
      "Epoch 35/1000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 1.0654 - accuracy: 0.4000 - val_loss: 1.1727 - val_accuracy: 0.2444\n",
      "Epoch 36/1000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0421 - accuracy: 0.4095 - val_loss: 1.1491 - val_accuracy: 0.2444\n",
      "Epoch 37/1000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 1.0196 - accuracy: 0.4286 - val_loss: 1.1259 - val_accuracy: 0.2444\n",
      "Epoch 38/1000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.9978 - accuracy: 0.4476 - val_loss: 1.1040 - val_accuracy: 0.2667\n",
      "Epoch 39/1000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.9769 - accuracy: 0.4476 - val_loss: 1.0819 - val_accuracy: 0.2889\n",
      "Epoch 40/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.9576 - accuracy: 0.5048 - val_loss: 1.0595 - val_accuracy: 0.3556\n",
      "Epoch 41/1000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.9373 - accuracy: 0.5333 - val_loss: 1.0400 - val_accuracy: 0.4000\n",
      "Epoch 42/1000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.9183 - accuracy: 0.5524 - val_loss: 1.0214 - val_accuracy: 0.4444\n",
      "Epoch 43/1000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.9010 - accuracy: 0.5810 - val_loss: 1.0038 - val_accuracy: 0.4444\n",
      "Epoch 44/1000\n",
      "105/105 [==============================] - 0s 72us/step - loss: 0.8845 - accuracy: 0.5810 - val_loss: 0.9861 - val_accuracy: 0.4444\n",
      "Epoch 45/1000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.8684 - accuracy: 0.6000 - val_loss: 0.9674 - val_accuracy: 0.4444\n",
      "Epoch 46/1000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.8539 - accuracy: 0.6190 - val_loss: 0.9463 - val_accuracy: 0.4444\n",
      "Epoch 47/1000\n",
      "105/105 [==============================] - 0s 78us/step - loss: 0.8372 - accuracy: 0.6286 - val_loss: 0.9272 - val_accuracy: 0.4889\n",
      "Epoch 48/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 0.8218 - accuracy: 0.6476 - val_loss: 0.9096 - val_accuracy: 0.5333\n",
      "Epoch 49/1000\n",
      "105/105 [==============================] - 0s 139us/step - loss: 0.8069 - accuracy: 0.6667 - val_loss: 0.8930 - val_accuracy: 0.5556\n",
      "Epoch 50/1000\n",
      "105/105 [==============================] - 0s 116us/step - loss: 0.7933 - accuracy: 0.6857 - val_loss: 0.8781 - val_accuracy: 0.5778\n",
      "Epoch 51/1000\n",
      "105/105 [==============================] - 0s 112us/step - loss: 0.7795 - accuracy: 0.6857 - val_loss: 0.8629 - val_accuracy: 0.5778\n",
      "Epoch 52/1000\n",
      "105/105 [==============================] - 0s 148us/step - loss: 0.7663 - accuracy: 0.6857 - val_loss: 0.8472 - val_accuracy: 0.5778\n",
      "Epoch 53/1000\n",
      "105/105 [==============================] - 0s 138us/step - loss: 0.7537 - accuracy: 0.6952 - val_loss: 0.8321 - val_accuracy: 0.6000\n",
      "Epoch 54/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.7416 - accuracy: 0.6952 - val_loss: 0.8182 - val_accuracy: 0.6000\n",
      "Epoch 55/1000\n",
      "105/105 [==============================] - 0s 125us/step - loss: 0.7296 - accuracy: 0.6952 - val_loss: 0.8067 - val_accuracy: 0.6000\n",
      "Epoch 56/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.7180 - accuracy: 0.6952 - val_loss: 0.7944 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "105/105 [==============================] - 0s 98us/step - loss: 0.7065 - accuracy: 0.6952 - val_loss: 0.7820 - val_accuracy: 0.6000\n",
      "Epoch 58/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.6959 - accuracy: 0.6952 - val_loss: 0.7689 - val_accuracy: 0.6000\n",
      "Epoch 59/1000\n",
      "105/105 [==============================] - 0s 109us/step - loss: 0.6861 - accuracy: 0.6952 - val_loss: 0.7567 - val_accuracy: 0.6000\n",
      "Epoch 60/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.6754 - accuracy: 0.7048 - val_loss: 0.7456 - val_accuracy: 0.6000\n",
      "Epoch 61/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.6656 - accuracy: 0.7048 - val_loss: 0.7355 - val_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.6563 - accuracy: 0.7048 - val_loss: 0.7251 - val_accuracy: 0.6000\n",
      "Epoch 63/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.6469 - accuracy: 0.7048 - val_loss: 0.7143 - val_accuracy: 0.6000\n",
      "Epoch 64/1000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.6385 - accuracy: 0.7048 - val_loss: 0.7037 - val_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "105/105 [==============================] - 0s 166us/step - loss: 0.6303 - accuracy: 0.7048 - val_loss: 0.6935 - val_accuracy: 0.6000\n",
      "Epoch 66/1000\n",
      "105/105 [==============================] - 0s 145us/step - loss: 0.6220 - accuracy: 0.7048 - val_loss: 0.6839 - val_accuracy: 0.6000\n",
      "Epoch 67/1000\n",
      "105/105 [==============================] - 0s 197us/step - loss: 0.6136 - accuracy: 0.7048 - val_loss: 0.6759 - val_accuracy: 0.6000\n",
      "Epoch 68/1000\n",
      "105/105 [==============================] - 0s 196us/step - loss: 0.6057 - accuracy: 0.7048 - val_loss: 0.6686 - val_accuracy: 0.6000\n",
      "Epoch 69/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.5983 - accuracy: 0.7048 - val_loss: 0.6617 - val_accuracy: 0.6000\n",
      "Epoch 70/1000\n",
      "105/105 [==============================] - 0s 100us/step - loss: 0.5912 - accuracy: 0.7048 - val_loss: 0.6549 - val_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.5843 - accuracy: 0.7048 - val_loss: 0.6473 - val_accuracy: 0.6000\n",
      "Epoch 72/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.5778 - accuracy: 0.7143 - val_loss: 0.6406 - val_accuracy: 0.6000\n",
      "Epoch 73/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.5714 - accuracy: 0.7143 - val_loss: 0.6347 - val_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.5654 - accuracy: 0.7143 - val_loss: 0.6294 - val_accuracy: 0.6000\n",
      "Epoch 75/1000\n",
      "105/105 [==============================] - 0s 187us/step - loss: 0.5595 - accuracy: 0.7143 - val_loss: 0.6235 - val_accuracy: 0.6000\n",
      "Epoch 76/1000\n",
      "105/105 [==============================] - 0s 192us/step - loss: 0.5539 - accuracy: 0.7143 - val_loss: 0.6163 - val_accuracy: 0.6000\n",
      "Epoch 77/1000\n",
      "105/105 [==============================] - 0s 126us/step - loss: 0.5481 - accuracy: 0.7143 - val_loss: 0.6099 - val_accuracy: 0.6000\n",
      "Epoch 78/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.5427 - accuracy: 0.7143 - val_loss: 0.6027 - val_accuracy: 0.6000\n",
      "Epoch 79/1000\n",
      "105/105 [==============================] - 0s 92us/step - loss: 0.5372 - accuracy: 0.7238 - val_loss: 0.5958 - val_accuracy: 0.6000\n",
      "Epoch 80/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.5320 - accuracy: 0.7333 - val_loss: 0.5888 - val_accuracy: 0.6222\n",
      "Epoch 81/1000\n",
      "105/105 [==============================] - 0s 98us/step - loss: 0.5267 - accuracy: 0.7333 - val_loss: 0.5832 - val_accuracy: 0.6222\n",
      "Epoch 82/1000\n",
      "105/105 [==============================] - 0s 163us/step - loss: 0.5217 - accuracy: 0.7333 - val_loss: 0.5760 - val_accuracy: 0.6222\n",
      "Epoch 83/1000\n",
      "105/105 [==============================] - 0s 166us/step - loss: 0.5170 - accuracy: 0.7333 - val_loss: 0.5696 - val_accuracy: 0.6222\n",
      "Epoch 84/1000\n",
      "105/105 [==============================] - 0s 147us/step - loss: 0.5120 - accuracy: 0.7333 - val_loss: 0.5642 - val_accuracy: 0.6222\n",
      "Epoch 85/1000\n",
      "105/105 [==============================] - 0s 117us/step - loss: 0.5074 - accuracy: 0.7333 - val_loss: 0.5598 - val_accuracy: 0.6222\n",
      "Epoch 86/1000\n",
      "105/105 [==============================] - 0s 150us/step - loss: 0.5029 - accuracy: 0.7333 - val_loss: 0.5565 - val_accuracy: 0.6222\n",
      "Epoch 87/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.4986 - accuracy: 0.7333 - val_loss: 0.5535 - val_accuracy: 0.6222\n",
      "Epoch 88/1000\n",
      "105/105 [==============================] - 0s 92us/step - loss: 0.4944 - accuracy: 0.7333 - val_loss: 0.5501 - val_accuracy: 0.6222\n",
      "Epoch 89/1000\n",
      "105/105 [==============================] - 0s 88us/step - loss: 0.4903 - accuracy: 0.7333 - val_loss: 0.5451 - val_accuracy: 0.6222\n",
      "Epoch 90/1000\n",
      "105/105 [==============================] - 0s 88us/step - loss: 0.4862 - accuracy: 0.7333 - val_loss: 0.5392 - val_accuracy: 0.6222\n",
      "Epoch 91/1000\n",
      "105/105 [==============================] - 0s 110us/step - loss: 0.4820 - accuracy: 0.7429 - val_loss: 0.5341 - val_accuracy: 0.6222\n",
      "Epoch 92/1000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.4781 - accuracy: 0.7524 - val_loss: 0.5295 - val_accuracy: 0.6444\n",
      "Epoch 93/1000\n",
      "105/105 [==============================] - 0s 78us/step - loss: 0.4739 - accuracy: 0.7619 - val_loss: 0.5231 - val_accuracy: 0.6444\n",
      "Epoch 94/1000\n",
      "105/105 [==============================] - 0s 78us/step - loss: 0.4703 - accuracy: 0.7714 - val_loss: 0.5164 - val_accuracy: 0.6444\n",
      "Epoch 95/1000\n",
      "105/105 [==============================] - 0s 118us/step - loss: 0.4665 - accuracy: 0.8190 - val_loss: 0.5114 - val_accuracy: 0.6889\n",
      "Epoch 96/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.4631 - accuracy: 0.8381 - val_loss: 0.5064 - val_accuracy: 0.7111\n",
      "Epoch 97/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.4595 - accuracy: 0.8381 - val_loss: 0.5030 - val_accuracy: 0.7111\n",
      "Epoch 98/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.4558 - accuracy: 0.8381 - val_loss: 0.5012 - val_accuracy: 0.7111\n",
      "Epoch 99/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.4523 - accuracy: 0.8381 - val_loss: 0.4999 - val_accuracy: 0.6667\n",
      "Epoch 100/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.4487 - accuracy: 0.8381 - val_loss: 0.4970 - val_accuracy: 0.6667\n",
      "Epoch 101/1000\n",
      "105/105 [==============================] - 0s 110us/step - loss: 0.4455 - accuracy: 0.8381 - val_loss: 0.4947 - val_accuracy: 0.6444\n",
      "Epoch 102/1000\n",
      "105/105 [==============================] - 0s 122us/step - loss: 0.4423 - accuracy: 0.8286 - val_loss: 0.4924 - val_accuracy: 0.6444\n",
      "Epoch 103/1000\n",
      "105/105 [==============================] - 0s 82us/step - loss: 0.4396 - accuracy: 0.8286 - val_loss: 0.4879 - val_accuracy: 0.7111\n",
      "Epoch 104/1000\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.4360 - accuracy: 0.8381 - val_loss: 0.4852 - val_accuracy: 0.7111\n",
      "Epoch 105/1000\n",
      "105/105 [==============================] - 0s 107us/step - loss: 0.4329 - accuracy: 0.8381 - val_loss: 0.4816 - val_accuracy: 0.7111\n",
      "Epoch 106/1000\n",
      "105/105 [==============================] - 0s 115us/step - loss: 0.4298 - accuracy: 0.8381 - val_loss: 0.4769 - val_accuracy: 0.7111\n",
      "Epoch 107/1000\n",
      "105/105 [==============================] - 0s 122us/step - loss: 0.4268 - accuracy: 0.8476 - val_loss: 0.4722 - val_accuracy: 0.7111\n",
      "Epoch 108/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.4238 - accuracy: 0.8667 - val_loss: 0.4680 - val_accuracy: 0.7333\n",
      "Epoch 109/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.4211 - accuracy: 0.8762 - val_loss: 0.4639 - val_accuracy: 0.7333\n",
      "Epoch 110/1000\n",
      "105/105 [==============================] - 0s 110us/step - loss: 0.4179 - accuracy: 0.8762 - val_loss: 0.4595 - val_accuracy: 0.7556\n",
      "Epoch 111/1000\n",
      "105/105 [==============================] - 0s 110us/step - loss: 0.4154 - accuracy: 0.8762 - val_loss: 0.4544 - val_accuracy: 0.7778\n",
      "Epoch 112/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.4123 - accuracy: 0.8857 - val_loss: 0.4522 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.4094 - accuracy: 0.8857 - val_loss: 0.4506 - val_accuracy: 0.7556\n",
      "Epoch 114/1000\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.4069 - accuracy: 0.8762 - val_loss: 0.4491 - val_accuracy: 0.7556\n",
      "Epoch 115/1000\n",
      "105/105 [==============================] - 0s 88us/step - loss: 0.4040 - accuracy: 0.8762 - val_loss: 0.4464 - val_accuracy: 0.7556\n",
      "Epoch 116/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.4012 - accuracy: 0.8762 - val_loss: 0.4449 - val_accuracy: 0.7556\n",
      "Epoch 117/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.3986 - accuracy: 0.8762 - val_loss: 0.4418 - val_accuracy: 0.7778\n",
      "Epoch 118/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.3959 - accuracy: 0.8762 - val_loss: 0.4373 - val_accuracy: 0.7778\n",
      "Epoch 119/1000\n",
      "105/105 [==============================] - 0s 124us/step - loss: 0.3931 - accuracy: 0.8857 - val_loss: 0.4332 - val_accuracy: 0.7778\n",
      "Epoch 120/1000\n",
      "105/105 [==============================] - 0s 100us/step - loss: 0.3906 - accuracy: 0.9048 - val_loss: 0.4302 - val_accuracy: 0.8000\n",
      "Epoch 121/1000\n",
      "105/105 [==============================] - 0s 120us/step - loss: 0.3882 - accuracy: 0.9048 - val_loss: 0.4279 - val_accuracy: 0.8000\n",
      "Epoch 122/1000\n",
      "105/105 [==============================] - 0s 131us/step - loss: 0.3853 - accuracy: 0.9238 - val_loss: 0.4234 - val_accuracy: 0.8444\n",
      "Epoch 123/1000\n",
      "105/105 [==============================] - 0s 206us/step - loss: 0.3829 - accuracy: 0.9238 - val_loss: 0.4191 - val_accuracy: 0.8444\n",
      "Epoch 124/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.3806 - accuracy: 0.9333 - val_loss: 0.4163 - val_accuracy: 0.8444\n",
      "Epoch 125/1000\n",
      "105/105 [==============================] - 0s 177us/step - loss: 0.3782 - accuracy: 0.9333 - val_loss: 0.4142 - val_accuracy: 0.8444\n",
      "Epoch 126/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.3758 - accuracy: 0.9333 - val_loss: 0.4143 - val_accuracy: 0.8444\n",
      "Epoch 127/1000\n",
      "105/105 [==============================] - 0s 154us/step - loss: 0.3733 - accuracy: 0.9238 - val_loss: 0.4146 - val_accuracy: 0.8222\n",
      "Epoch 128/1000\n",
      "105/105 [==============================] - 0s 133us/step - loss: 0.3707 - accuracy: 0.9238 - val_loss: 0.4126 - val_accuracy: 0.8222\n",
      "Epoch 129/1000\n",
      "105/105 [==============================] - 0s 193us/step - loss: 0.3684 - accuracy: 0.9143 - val_loss: 0.4114 - val_accuracy: 0.8222\n",
      "Epoch 130/1000\n",
      "105/105 [==============================] - 0s 147us/step - loss: 0.3660 - accuracy: 0.9238 - val_loss: 0.4079 - val_accuracy: 0.8444\n",
      "Epoch 131/1000\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.90 - 0s 260us/step - loss: 0.3640 - accuracy: 0.9238 - val_loss: 0.4027 - val_accuracy: 0.8444\n",
      "Epoch 132/1000\n",
      "105/105 [==============================] - 0s 149us/step - loss: 0.3615 - accuracy: 0.9333 - val_loss: 0.3991 - val_accuracy: 0.8667\n",
      "Epoch 133/1000\n",
      "105/105 [==============================] - 0s 146us/step - loss: 0.3590 - accuracy: 0.9333 - val_loss: 0.3971 - val_accuracy: 0.8667\n",
      "Epoch 134/1000\n",
      "105/105 [==============================] - 0s 171us/step - loss: 0.3567 - accuracy: 0.9333 - val_loss: 0.3977 - val_accuracy: 0.8444\n",
      "Epoch 135/1000\n",
      "105/105 [==============================] - 0s 125us/step - loss: 0.3547 - accuracy: 0.9333 - val_loss: 0.3971 - val_accuracy: 0.8444\n",
      "Epoch 136/1000\n",
      "105/105 [==============================] - 0s 223us/step - loss: 0.3524 - accuracy: 0.9333 - val_loss: 0.3963 - val_accuracy: 0.8444\n",
      "Epoch 137/1000\n",
      "105/105 [==============================] - 0s 125us/step - loss: 0.3502 - accuracy: 0.9238 - val_loss: 0.3939 - val_accuracy: 0.8444\n",
      "Epoch 138/1000\n",
      "105/105 [==============================] - 0s 153us/step - loss: 0.3479 - accuracy: 0.9333 - val_loss: 0.3892 - val_accuracy: 0.8444\n",
      "Epoch 139/1000\n",
      "105/105 [==============================] - 0s 119us/step - loss: 0.3461 - accuracy: 0.9429 - val_loss: 0.3842 - val_accuracy: 0.8889\n",
      "Epoch 140/1000\n",
      "105/105 [==============================] - 0s 181us/step - loss: 0.3435 - accuracy: 0.9619 - val_loss: 0.3833 - val_accuracy: 0.8667\n",
      "Epoch 141/1000\n",
      "105/105 [==============================] - 0s 120us/step - loss: 0.3413 - accuracy: 0.9524 - val_loss: 0.3816 - val_accuracy: 0.8889\n",
      "Epoch 142/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.3391 - accuracy: 0.9524 - val_loss: 0.3777 - val_accuracy: 0.8889\n",
      "Epoch 143/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.3369 - accuracy: 0.9619 - val_loss: 0.3740 - val_accuracy: 0.9333\n",
      "Epoch 144/1000\n",
      "105/105 [==============================] - 0s 177us/step - loss: 0.3347 - accuracy: 0.9619 - val_loss: 0.3715 - val_accuracy: 0.9333\n",
      "Epoch 145/1000\n",
      "105/105 [==============================] - 0s 138us/step - loss: 0.3324 - accuracy: 0.9619 - val_loss: 0.3674 - val_accuracy: 0.9333\n",
      "Epoch 146/1000\n",
      "105/105 [==============================] - 0s 130us/step - loss: 0.3308 - accuracy: 0.9619 - val_loss: 0.3625 - val_accuracy: 0.9333\n",
      "Epoch 147/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.3286 - accuracy: 0.9619 - val_loss: 0.3599 - val_accuracy: 0.9333\n",
      "Epoch 148/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.3265 - accuracy: 0.9619 - val_loss: 0.3574 - val_accuracy: 0.9556\n",
      "Epoch 149/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.3242 - accuracy: 0.9619 - val_loss: 0.3570 - val_accuracy: 0.9333\n",
      "Epoch 150/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.3217 - accuracy: 0.9619 - val_loss: 0.3559 - val_accuracy: 0.9333\n",
      "Epoch 151/1000\n",
      "105/105 [==============================] - 0s 125us/step - loss: 0.3197 - accuracy: 0.9619 - val_loss: 0.3546 - val_accuracy: 0.9333\n",
      "Epoch 152/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.3176 - accuracy: 0.9619 - val_loss: 0.3526 - val_accuracy: 0.9333\n",
      "Epoch 153/1000\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.3151 - accuracy: 0.9619 - val_loss: 0.3553 - val_accuracy: 0.9333\n",
      "Epoch 154/1000\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.3131 - accuracy: 0.9619 - val_loss: 0.3565 - val_accuracy: 0.9333\n",
      "Epoch 155/1000\n",
      "105/105 [==============================] - 0s 165us/step - loss: 0.3115 - accuracy: 0.9619 - val_loss: 0.3567 - val_accuracy: 0.9111\n",
      "Epoch 156/1000\n",
      "105/105 [==============================] - 0s 169us/step - loss: 0.3093 - accuracy: 0.9619 - val_loss: 0.3538 - val_accuracy: 0.9333\n",
      "Epoch 157/1000\n",
      "105/105 [==============================] - 0s 133us/step - loss: 0.3071 - accuracy: 0.9619 - val_loss: 0.3500 - val_accuracy: 0.9333\n",
      "Epoch 158/1000\n",
      "105/105 [==============================] - 0s 107us/step - loss: 0.3054 - accuracy: 0.9619 - val_loss: 0.3449 - val_accuracy: 0.9333\n",
      "Epoch 159/1000\n",
      "105/105 [==============================] - 0s 130us/step - loss: 0.3025 - accuracy: 0.9619 - val_loss: 0.3444 - val_accuracy: 0.9333\n",
      "Epoch 160/1000\n",
      "105/105 [==============================] - 0s 117us/step - loss: 0.3008 - accuracy: 0.9619 - val_loss: 0.3453 - val_accuracy: 0.9333\n",
      "Epoch 161/1000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.2988 - accuracy: 0.9619 - val_loss: 0.3416 - val_accuracy: 0.9333\n",
      "Epoch 162/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.2967 - accuracy: 0.9619 - val_loss: 0.3386 - val_accuracy: 0.9333\n",
      "Epoch 163/1000\n",
      "105/105 [==============================] - 0s 120us/step - loss: 0.2945 - accuracy: 0.9619 - val_loss: 0.3338 - val_accuracy: 0.9333\n",
      "Epoch 164/1000\n",
      "105/105 [==============================] - 0s 140us/step - loss: 0.2921 - accuracy: 0.9619 - val_loss: 0.3310 - val_accuracy: 0.9333\n",
      "Epoch 165/1000\n",
      "105/105 [==============================] - 0s 132us/step - loss: 0.2902 - accuracy: 0.9619 - val_loss: 0.3274 - val_accuracy: 0.9556\n",
      "Epoch 166/1000\n",
      "105/105 [==============================] - 0s 136us/step - loss: 0.2881 - accuracy: 0.9619 - val_loss: 0.3250 - val_accuracy: 0.9556\n",
      "Epoch 167/1000\n",
      "105/105 [==============================] - 0s 145us/step - loss: 0.2861 - accuracy: 0.9619 - val_loss: 0.3233 - val_accuracy: 0.9556\n",
      "Epoch 168/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 185us/step - loss: 0.2840 - accuracy: 0.9619 - val_loss: 0.3230 - val_accuracy: 0.9556\n",
      "Epoch 169/1000\n",
      "105/105 [==============================] - 0s 126us/step - loss: 0.2821 - accuracy: 0.9619 - val_loss: 0.3240 - val_accuracy: 0.9333\n",
      "Epoch 170/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.2804 - accuracy: 0.9619 - val_loss: 0.3227 - val_accuracy: 0.9333\n",
      "Epoch 171/1000\n",
      "105/105 [==============================] - 0s 126us/step - loss: 0.2787 - accuracy: 0.9619 - val_loss: 0.3210 - val_accuracy: 0.9333\n",
      "Epoch 172/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.2765 - accuracy: 0.9619 - val_loss: 0.3205 - val_accuracy: 0.9333\n",
      "Epoch 173/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.2751 - accuracy: 0.9619 - val_loss: 0.3189 - val_accuracy: 0.9333\n",
      "Epoch 174/1000\n",
      "105/105 [==============================] - 0s 82us/step - loss: 0.2726 - accuracy: 0.9619 - val_loss: 0.3123 - val_accuracy: 0.9556\n",
      "Epoch 175/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.2705 - accuracy: 0.9619 - val_loss: 0.3044 - val_accuracy: 0.9556\n",
      "Epoch 176/1000\n",
      "105/105 [==============================] - 0s 140us/step - loss: 0.2687 - accuracy: 0.9619 - val_loss: 0.2994 - val_accuracy: 0.9778\n",
      "Epoch 177/1000\n",
      "105/105 [==============================] - 0s 162us/step - loss: 0.2673 - accuracy: 0.9619 - val_loss: 0.2965 - val_accuracy: 0.9778\n",
      "Epoch 178/1000\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.2656 - accuracy: 0.9619 - val_loss: 0.2957 - val_accuracy: 0.9778\n",
      "Epoch 179/1000\n",
      "105/105 [==============================] - 0s 125us/step - loss: 0.2634 - accuracy: 0.9619 - val_loss: 0.2962 - val_accuracy: 0.9778\n",
      "Epoch 180/1000\n",
      "105/105 [==============================] - 0s 148us/step - loss: 0.2611 - accuracy: 0.9619 - val_loss: 0.3023 - val_accuracy: 0.9556\n",
      "Epoch 181/1000\n",
      "105/105 [==============================] - 0s 241us/step - loss: 0.2591 - accuracy: 0.9619 - val_loss: 0.3044 - val_accuracy: 0.9333\n",
      "Epoch 182/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.2582 - accuracy: 0.9619 - val_loss: 0.3049 - val_accuracy: 0.9333\n",
      "Epoch 183/1000\n",
      "105/105 [==============================] - 0s 184us/step - loss: 0.2567 - accuracy: 0.9619 - val_loss: 0.3034 - val_accuracy: 0.9333\n",
      "Epoch 184/1000\n",
      "105/105 [==============================] - 0s 139us/step - loss: 0.2549 - accuracy: 0.9619 - val_loss: 0.2990 - val_accuracy: 0.9556\n",
      "Epoch 185/1000\n",
      "105/105 [==============================] - 0s 138us/step - loss: 0.2528 - accuracy: 0.9619 - val_loss: 0.2947 - val_accuracy: 0.9556\n",
      "Epoch 186/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.2505 - accuracy: 0.9619 - val_loss: 0.2912 - val_accuracy: 0.9556\n",
      "Epoch 187/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.2488 - accuracy: 0.9619 - val_loss: 0.2857 - val_accuracy: 0.9556\n",
      "Epoch 188/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.2467 - accuracy: 0.9619 - val_loss: 0.2850 - val_accuracy: 0.9556\n",
      "Epoch 189/1000\n",
      "105/105 [==============================] - 0s 133us/step - loss: 0.2451 - accuracy: 0.9619 - val_loss: 0.2835 - val_accuracy: 0.9556\n",
      "Epoch 190/1000\n",
      "105/105 [==============================] - 0s 153us/step - loss: 0.2433 - accuracy: 0.9619 - val_loss: 0.2809 - val_accuracy: 0.9556\n",
      "Epoch 191/1000\n",
      "105/105 [==============================] - 0s 103us/step - loss: 0.2416 - accuracy: 0.9619 - val_loss: 0.2789 - val_accuracy: 0.9556\n",
      "Epoch 192/1000\n",
      "105/105 [==============================] - 0s 147us/step - loss: 0.2401 - accuracy: 0.9619 - val_loss: 0.2799 - val_accuracy: 0.9556\n",
      "Epoch 193/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.2382 - accuracy: 0.9619 - val_loss: 0.2760 - val_accuracy: 0.9556\n",
      "Epoch 194/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.2364 - accuracy: 0.9619 - val_loss: 0.2753 - val_accuracy: 0.9556\n",
      "Epoch 195/1000\n",
      "105/105 [==============================] - 0s 124us/step - loss: 0.2350 - accuracy: 0.9619 - val_loss: 0.2693 - val_accuracy: 0.9778\n",
      "Epoch 196/1000\n",
      "105/105 [==============================] - 0s 166us/step - loss: 0.2328 - accuracy: 0.9619 - val_loss: 0.2682 - val_accuracy: 0.9778\n",
      "Epoch 197/1000\n",
      "105/105 [==============================] - 0s 120us/step - loss: 0.2313 - accuracy: 0.9619 - val_loss: 0.2691 - val_accuracy: 0.9778\n",
      "Epoch 198/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.2304 - accuracy: 0.9619 - val_loss: 0.2662 - val_accuracy: 0.9778\n",
      "Epoch 199/1000\n",
      "105/105 [==============================] - 0s 124us/step - loss: 0.2279 - accuracy: 0.9619 - val_loss: 0.2688 - val_accuracy: 0.9556\n",
      "Epoch 200/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.2265 - accuracy: 0.9619 - val_loss: 0.2700 - val_accuracy: 0.9556\n",
      "Epoch 201/1000\n",
      "105/105 [==============================] - 0s 320us/step - loss: 0.2250 - accuracy: 0.9619 - val_loss: 0.2701 - val_accuracy: 0.9556\n",
      "Epoch 202/1000\n",
      "105/105 [==============================] - 0s 222us/step - loss: 0.2238 - accuracy: 0.9619 - val_loss: 0.2707 - val_accuracy: 0.9556\n",
      "Epoch 203/1000\n",
      "105/105 [==============================] - 0s 187us/step - loss: 0.2225 - accuracy: 0.9619 - val_loss: 0.2670 - val_accuracy: 0.9556\n",
      "Epoch 204/1000\n",
      "105/105 [==============================] - 0s 219us/step - loss: 0.2204 - accuracy: 0.9619 - val_loss: 0.2634 - val_accuracy: 0.9556\n",
      "Epoch 205/1000\n",
      "105/105 [==============================] - 0s 251us/step - loss: 0.2186 - accuracy: 0.9619 - val_loss: 0.2596 - val_accuracy: 0.9556\n",
      "Epoch 206/1000\n",
      "105/105 [==============================] - 0s 222us/step - loss: 0.2169 - accuracy: 0.9619 - val_loss: 0.2583 - val_accuracy: 0.9556\n",
      "Epoch 207/1000\n",
      "105/105 [==============================] - 0s 138us/step - loss: 0.2155 - accuracy: 0.9619 - val_loss: 0.2556 - val_accuracy: 0.9778\n",
      "Epoch 208/1000\n",
      "105/105 [==============================] - 0s 172us/step - loss: 0.2132 - accuracy: 0.9619 - val_loss: 0.2491 - val_accuracy: 0.9778\n",
      "Epoch 209/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.2128 - accuracy: 0.9619 - val_loss: 0.2402 - val_accuracy: 0.9778\n",
      "Epoch 210/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.2117 - accuracy: 0.9714 - val_loss: 0.2374 - val_accuracy: 0.9778\n",
      "Epoch 211/1000\n",
      "105/105 [==============================] - 0s 143us/step - loss: 0.2101 - accuracy: 0.9714 - val_loss: 0.2380 - val_accuracy: 0.9778\n",
      "Epoch 212/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.2077 - accuracy: 0.9714 - val_loss: 0.2408 - val_accuracy: 0.9778\n",
      "Epoch 213/1000\n",
      "105/105 [==============================] - 0s 118us/step - loss: 0.2058 - accuracy: 0.9714 - val_loss: 0.2422 - val_accuracy: 0.9778\n",
      "Epoch 214/1000\n",
      "105/105 [==============================] - 0s 177us/step - loss: 0.2045 - accuracy: 0.9619 - val_loss: 0.2431 - val_accuracy: 0.9778\n",
      "Epoch 215/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.2031 - accuracy: 0.9619 - val_loss: 0.2404 - val_accuracy: 0.9778\n",
      "Epoch 216/1000\n",
      "105/105 [==============================] - 0s 139us/step - loss: 0.2019 - accuracy: 0.9619 - val_loss: 0.2407 - val_accuracy: 0.9778\n",
      "Epoch 217/1000\n",
      "105/105 [==============================] - 0s 116us/step - loss: 0.2001 - accuracy: 0.9619 - val_loss: 0.2360 - val_accuracy: 0.9778\n",
      "Epoch 218/1000\n",
      "105/105 [==============================] - 0s 203us/step - loss: 0.1995 - accuracy: 0.9714 - val_loss: 0.2293 - val_accuracy: 0.9778\n",
      "Epoch 219/1000\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.1980 - accuracy: 0.9714 - val_loss: 0.2297 - val_accuracy: 0.9778\n",
      "Epoch 220/1000\n",
      "105/105 [==============================] - 0s 139us/step - loss: 0.1964 - accuracy: 0.9714 - val_loss: 0.2296 - val_accuracy: 0.9778\n",
      "Epoch 221/1000\n",
      "105/105 [==============================] - 0s 183us/step - loss: 0.1947 - accuracy: 0.9714 - val_loss: 0.2319 - val_accuracy: 0.9778\n",
      "Epoch 222/1000\n",
      "105/105 [==============================] - 0s 155us/step - loss: 0.1935 - accuracy: 0.9619 - val_loss: 0.2332 - val_accuracy: 0.9778\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 183us/step - loss: 0.1931 - accuracy: 0.9619 - val_loss: 0.2345 - val_accuracy: 0.9778\n",
      "Epoch 224/1000\n",
      "105/105 [==============================] - 0s 173us/step - loss: 0.1912 - accuracy: 0.9619 - val_loss: 0.2306 - val_accuracy: 0.9778\n",
      "Epoch 225/1000\n",
      "105/105 [==============================] - 0s 136us/step - loss: 0.1897 - accuracy: 0.9619 - val_loss: 0.2289 - val_accuracy: 0.9778\n",
      "Epoch 226/1000\n",
      "105/105 [==============================] - 0s 203us/step - loss: 0.1884 - accuracy: 0.9619 - val_loss: 0.2279 - val_accuracy: 0.9778\n",
      "Epoch 227/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.1870 - accuracy: 0.9619 - val_loss: 0.2263 - val_accuracy: 0.9778\n",
      "Epoch 228/1000\n",
      "105/105 [==============================] - 0s 134us/step - loss: 0.1857 - accuracy: 0.9619 - val_loss: 0.2232 - val_accuracy: 0.9778\n",
      "Epoch 229/1000\n",
      "105/105 [==============================] - 0s 145us/step - loss: 0.1845 - accuracy: 0.9714 - val_loss: 0.2181 - val_accuracy: 0.9778\n",
      "Epoch 230/1000\n",
      "105/105 [==============================] - 0s 150us/step - loss: 0.1832 - accuracy: 0.9714 - val_loss: 0.2168 - val_accuracy: 0.9778\n",
      "Epoch 231/1000\n",
      "105/105 [==============================] - 0s 155us/step - loss: 0.1818 - accuracy: 0.9714 - val_loss: 0.2192 - val_accuracy: 0.9778\n",
      "Epoch 232/1000\n",
      "105/105 [==============================] - 0s 153us/step - loss: 0.1813 - accuracy: 0.9619 - val_loss: 0.2252 - val_accuracy: 0.9778\n",
      "Epoch 233/1000\n",
      "105/105 [==============================] - 0s 141us/step - loss: 0.1801 - accuracy: 0.9619 - val_loss: 0.2225 - val_accuracy: 0.9778\n",
      "Epoch 234/1000\n",
      "105/105 [==============================] - 0s 159us/step - loss: 0.1785 - accuracy: 0.9619 - val_loss: 0.2159 - val_accuracy: 0.9778\n",
      "Epoch 235/1000\n",
      "105/105 [==============================] - 0s 140us/step - loss: 0.1767 - accuracy: 0.9714 - val_loss: 0.2111 - val_accuracy: 0.9778\n",
      "Epoch 236/1000\n",
      "105/105 [==============================] - 0s 177us/step - loss: 0.1761 - accuracy: 0.9714 - val_loss: 0.2075 - val_accuracy: 0.9778\n",
      "Epoch 237/1000\n",
      "105/105 [==============================] - 0s 164us/step - loss: 0.1748 - accuracy: 0.9714 - val_loss: 0.2090 - val_accuracy: 0.9778\n",
      "Epoch 238/1000\n",
      "105/105 [==============================] - 0s 151us/step - loss: 0.1733 - accuracy: 0.9714 - val_loss: 0.2085 - val_accuracy: 0.9778\n",
      "Epoch 239/1000\n",
      "105/105 [==============================] - 0s 118us/step - loss: 0.1721 - accuracy: 0.9714 - val_loss: 0.2078 - val_accuracy: 0.9778\n",
      "Epoch 240/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.1712 - accuracy: 0.9714 - val_loss: 0.2076 - val_accuracy: 0.9778\n",
      "Epoch 241/1000\n",
      "105/105 [==============================] - 0s 113us/step - loss: 0.1698 - accuracy: 0.9714 - val_loss: 0.2050 - val_accuracy: 0.9778\n",
      "Epoch 242/1000\n",
      "105/105 [==============================] - 0s 147us/step - loss: 0.1686 - accuracy: 0.9714 - val_loss: 0.2002 - val_accuracy: 0.9778\n",
      "Epoch 243/1000\n",
      "105/105 [==============================] - 0s 150us/step - loss: 0.1678 - accuracy: 0.9714 - val_loss: 0.1959 - val_accuracy: 0.9778\n",
      "Epoch 244/1000\n",
      "105/105 [==============================] - 0s 236us/step - loss: 0.1672 - accuracy: 0.9714 - val_loss: 0.1929 - val_accuracy: 0.9778\n",
      "Epoch 245/1000\n",
      "105/105 [==============================] - 0s 137us/step - loss: 0.1666 - accuracy: 0.9714 - val_loss: 0.1939 - val_accuracy: 0.9778\n",
      "Epoch 246/1000\n",
      "105/105 [==============================] - 0s 149us/step - loss: 0.1650 - accuracy: 0.9714 - val_loss: 0.1960 - val_accuracy: 0.9778\n",
      "Epoch 247/1000\n",
      "105/105 [==============================] - 0s 142us/step - loss: 0.1638 - accuracy: 0.9714 - val_loss: 0.1967 - val_accuracy: 0.9778\n",
      "Epoch 248/1000\n",
      "105/105 [==============================] - 0s 177us/step - loss: 0.1621 - accuracy: 0.9714 - val_loss: 0.1932 - val_accuracy: 0.9778\n",
      "Epoch 249/1000\n",
      "105/105 [==============================] - 0s 146us/step - loss: 0.1613 - accuracy: 0.9714 - val_loss: 0.1922 - val_accuracy: 0.9778\n",
      "Epoch 250/1000\n",
      "105/105 [==============================] - 0s 146us/step - loss: 0.1601 - accuracy: 0.9714 - val_loss: 0.1959 - val_accuracy: 0.9778\n",
      "Epoch 251/1000\n",
      "105/105 [==============================] - 0s 158us/step - loss: 0.1595 - accuracy: 0.9714 - val_loss: 0.1976 - val_accuracy: 0.9778\n",
      "Epoch 252/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.1579 - accuracy: 0.9714 - val_loss: 0.1934 - val_accuracy: 0.9778\n",
      "Epoch 253/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.1569 - accuracy: 0.9714 - val_loss: 0.1909 - val_accuracy: 0.9778\n",
      "Epoch 254/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.1561 - accuracy: 0.9714 - val_loss: 0.1919 - val_accuracy: 0.9778\n",
      "Epoch 255/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.1550 - accuracy: 0.9714 - val_loss: 0.1910 - val_accuracy: 0.9778\n",
      "Epoch 256/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 0.1550 - accuracy: 0.9714 - val_loss: 0.1930 - val_accuracy: 0.9778\n",
      "Epoch 257/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.1532 - accuracy: 0.9714 - val_loss: 0.1889 - val_accuracy: 0.9778\n",
      "Epoch 258/1000\n",
      "105/105 [==============================] - 0s 153us/step - loss: 0.1513 - accuracy: 0.9714 - val_loss: 0.1825 - val_accuracy: 0.9778\n",
      "Epoch 259/1000\n",
      "105/105 [==============================] - 0s 141us/step - loss: 0.1513 - accuracy: 0.9714 - val_loss: 0.1779 - val_accuracy: 0.9778\n",
      "Epoch 260/1000\n",
      "105/105 [==============================] - 0s 98us/step - loss: 0.1510 - accuracy: 0.9714 - val_loss: 0.1780 - val_accuracy: 0.9778\n",
      "Epoch 261/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.1497 - accuracy: 0.9714 - val_loss: 0.1782 - val_accuracy: 0.9778\n",
      "Epoch 262/1000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.1486 - accuracy: 0.9714 - val_loss: 0.1802 - val_accuracy: 0.9778\n",
      "Epoch 263/1000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.1475 - accuracy: 0.9714 - val_loss: 0.1803 - val_accuracy: 0.9778\n",
      "Epoch 264/1000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 0.1465 - accuracy: 0.9714 - val_loss: 0.1778 - val_accuracy: 0.9778\n",
      "Epoch 265/1000\n",
      "105/105 [==============================] - 0s 100us/step - loss: 0.1461 - accuracy: 0.9714 - val_loss: 0.1780 - val_accuracy: 0.9778\n",
      "Epoch 266/1000\n",
      "105/105 [==============================] - 0s 183us/step - loss: 0.1449 - accuracy: 0.9714 - val_loss: 0.1744 - val_accuracy: 0.9778\n",
      "Epoch 267/1000\n",
      "105/105 [==============================] - 0s 169us/step - loss: 0.1443 - accuracy: 0.9714 - val_loss: 0.1739 - val_accuracy: 0.9778\n",
      "Epoch 268/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.1430 - accuracy: 0.9714 - val_loss: 0.1706 - val_accuracy: 0.9778\n",
      "Epoch 269/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.1430 - accuracy: 0.9714 - val_loss: 0.1678 - val_accuracy: 0.9778\n",
      "Epoch 270/1000\n",
      "105/105 [==============================] - 0s 134us/step - loss: 0.1427 - accuracy: 0.9714 - val_loss: 0.1670 - val_accuracy: 0.9778\n",
      "Epoch 271/1000\n",
      "105/105 [==============================] - 0s 163us/step - loss: 0.1420 - accuracy: 0.9714 - val_loss: 0.1670 - val_accuracy: 0.9778\n",
      "Epoch 272/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.1403 - accuracy: 0.9714 - val_loss: 0.1692 - val_accuracy: 0.9778\n",
      "Epoch 273/1000\n",
      "105/105 [==============================] - 0s 318us/step - loss: 0.1401 - accuracy: 0.9714 - val_loss: 0.1736 - val_accuracy: 0.9778\n",
      "Epoch 274/1000\n",
      "105/105 [==============================] - 0s 149us/step - loss: 0.1387 - accuracy: 0.9714 - val_loss: 0.1695 - val_accuracy: 0.9778\n",
      "Epoch 275/1000\n",
      "105/105 [==============================] - 0s 115us/step - loss: 0.1375 - accuracy: 0.9714 - val_loss: 0.1698 - val_accuracy: 0.9778\n",
      "Epoch 276/1000\n",
      "105/105 [==============================] - 0s 170us/step - loss: 0.1366 - accuracy: 0.9714 - val_loss: 0.1682 - val_accuracy: 0.9778\n",
      "Epoch 277/1000\n",
      "105/105 [==============================] - 0s 133us/step - loss: 0.1358 - accuracy: 0.9714 - val_loss: 0.1671 - val_accuracy: 0.9778\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 134us/step - loss: 0.1362 - accuracy: 0.9714 - val_loss: 0.1684 - val_accuracy: 0.9778\n",
      "Epoch 279/1000\n",
      "105/105 [==============================] - 0s 171us/step - loss: 0.1344 - accuracy: 0.9714 - val_loss: 0.1633 - val_accuracy: 0.9778\n",
      "Epoch 280/1000\n",
      "105/105 [==============================] - 0s 156us/step - loss: 0.1339 - accuracy: 0.9714 - val_loss: 0.1626 - val_accuracy: 0.9778\n",
      "Epoch 281/1000\n",
      "105/105 [==============================] - 0s 149us/step - loss: 0.1329 - accuracy: 0.9714 - val_loss: 0.1646 - val_accuracy: 0.9778\n",
      "Epoch 282/1000\n",
      "105/105 [==============================] - 0s 142us/step - loss: 0.1324 - accuracy: 0.9714 - val_loss: 0.1703 - val_accuracy: 0.9778\n",
      "Epoch 283/1000\n",
      "105/105 [==============================] - 0s 126us/step - loss: 0.1317 - accuracy: 0.9714 - val_loss: 0.1703 - val_accuracy: 0.9778\n",
      "Epoch 284/1000\n",
      "105/105 [==============================] - 0s 146us/step - loss: 0.1312 - accuracy: 0.9714 - val_loss: 0.1684 - val_accuracy: 0.9778\n",
      "Epoch 285/1000\n",
      "105/105 [==============================] - 0s 179us/step - loss: 0.1302 - accuracy: 0.9714 - val_loss: 0.1650 - val_accuracy: 0.9778\n",
      "Epoch 286/1000\n",
      "105/105 [==============================] - 0s 200us/step - loss: 0.1296 - accuracy: 0.9714 - val_loss: 0.1600 - val_accuracy: 0.9778\n",
      "Epoch 287/1000\n",
      "105/105 [==============================] - 0s 138us/step - loss: 0.1290 - accuracy: 0.9714 - val_loss: 0.1606 - val_accuracy: 0.9778\n",
      "Epoch 288/1000\n",
      "105/105 [==============================] - 0s 137us/step - loss: 0.1272 - accuracy: 0.9714 - val_loss: 0.1680 - val_accuracy: 0.9778\n",
      "Epoch 289/1000\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.1287 - accuracy: 0.9714 - val_loss: 0.1753 - val_accuracy: 0.9778\n",
      "Epoch 290/1000\n",
      "105/105 [==============================] - 0s 131us/step - loss: 0.1292 - accuracy: 0.9619 - val_loss: 0.1730 - val_accuracy: 0.9778\n",
      "Epoch 291/1000\n",
      "105/105 [==============================] - 0s 149us/step - loss: 0.1280 - accuracy: 0.9619 - val_loss: 0.1711 - val_accuracy: 0.9778\n",
      "Epoch 292/1000\n",
      "105/105 [==============================] - 0s 142us/step - loss: 0.1274 - accuracy: 0.9619 - val_loss: 0.1651 - val_accuracy: 0.9778\n",
      "Epoch 293/1000\n",
      "105/105 [==============================] - 0s 167us/step - loss: 0.1252 - accuracy: 0.9714 - val_loss: 0.1609 - val_accuracy: 0.9778\n",
      "Epoch 294/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.1242 - accuracy: 0.9714 - val_loss: 0.1558 - val_accuracy: 0.9778\n",
      "Epoch 295/1000\n",
      "105/105 [==============================] - 0s 117us/step - loss: 0.1234 - accuracy: 0.9714 - val_loss: 0.1530 - val_accuracy: 0.9778\n",
      "Epoch 296/1000\n",
      "105/105 [==============================] - 0s 142us/step - loss: 0.1233 - accuracy: 0.9714 - val_loss: 0.1515 - val_accuracy: 0.9778\n",
      "Epoch 297/1000\n",
      "105/105 [==============================] - 0s 286us/step - loss: 0.1231 - accuracy: 0.9714 - val_loss: 0.1532 - val_accuracy: 0.9778\n",
      "Epoch 298/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.1218 - accuracy: 0.9714 - val_loss: 0.1533 - val_accuracy: 0.9778\n",
      "Epoch 299/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.1213 - accuracy: 0.9714 - val_loss: 0.1529 - val_accuracy: 0.9778\n",
      "Epoch 300/1000\n",
      "105/105 [==============================] - 0s 151us/step - loss: 0.1204 - accuracy: 0.9714 - val_loss: 0.1554 - val_accuracy: 0.9778\n",
      "Epoch 301/1000\n",
      "105/105 [==============================] - 0s 125us/step - loss: 0.1201 - accuracy: 0.9714 - val_loss: 0.1557 - val_accuracy: 0.9778\n",
      "Epoch 302/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.1196 - accuracy: 0.9714 - val_loss: 0.1527 - val_accuracy: 0.9778\n",
      "Epoch 303/1000\n",
      "105/105 [==============================] - 0s 150us/step - loss: 0.1191 - accuracy: 0.9714 - val_loss: 0.1489 - val_accuracy: 0.9778\n",
      "Epoch 304/1000\n",
      "105/105 [==============================] - 0s 160us/step - loss: 0.1185 - accuracy: 0.9714 - val_loss: 0.1474 - val_accuracy: 0.9778\n",
      "Epoch 305/1000\n",
      "105/105 [==============================] - 0s 131us/step - loss: 0.1180 - accuracy: 0.9714 - val_loss: 0.1464 - val_accuracy: 0.9778\n",
      "Epoch 306/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.1173 - accuracy: 0.9714 - val_loss: 0.1484 - val_accuracy: 0.9778\n",
      "Epoch 307/1000\n",
      "105/105 [==============================] - 0s 119us/step - loss: 0.1167 - accuracy: 0.9714 - val_loss: 0.1476 - val_accuracy: 0.9778\n",
      "Epoch 308/1000\n",
      "105/105 [==============================] - 0s 138us/step - loss: 0.1160 - accuracy: 0.9714 - val_loss: 0.1465 - val_accuracy: 0.9778\n",
      "Epoch 309/1000\n",
      "105/105 [==============================] - 0s 217us/step - loss: 0.1155 - accuracy: 0.9714 - val_loss: 0.1460 - val_accuracy: 0.9778\n",
      "Epoch 310/1000\n",
      "105/105 [==============================] - 0s 299us/step - loss: 0.1150 - accuracy: 0.9714 - val_loss: 0.1483 - val_accuracy: 0.9778\n",
      "Epoch 311/1000\n",
      "105/105 [==============================] - 0s 177us/step - loss: 0.1151 - accuracy: 0.9714 - val_loss: 0.1547 - val_accuracy: 0.9778\n",
      "Epoch 312/1000\n",
      "105/105 [==============================] - 0s 141us/step - loss: 0.1156 - accuracy: 0.9714 - val_loss: 0.1584 - val_accuracy: 0.9778\n",
      "Epoch 313/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.1154 - accuracy: 0.9714 - val_loss: 0.1586 - val_accuracy: 0.9778\n",
      "Epoch 314/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.1149 - accuracy: 0.9714 - val_loss: 0.1537 - val_accuracy: 0.9778\n",
      "Epoch 315/1000\n",
      "105/105 [==============================] - 0s 153us/step - loss: 0.1138 - accuracy: 0.9714 - val_loss: 0.1478 - val_accuracy: 0.9778\n",
      "Epoch 316/1000\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.1121 - accuracy: 0.9714 - val_loss: 0.1461 - val_accuracy: 0.9778\n",
      "Epoch 317/1000\n",
      "105/105 [==============================] - 0s 243us/step - loss: 0.1118 - accuracy: 0.9714 - val_loss: 0.1474 - val_accuracy: 0.9778\n",
      "Epoch 318/1000\n",
      "105/105 [==============================] - 0s 210us/step - loss: 0.1111 - accuracy: 0.9714 - val_loss: 0.1443 - val_accuracy: 0.9778\n",
      "Epoch 319/1000\n",
      "105/105 [==============================] - 0s 198us/step - loss: 0.1109 - accuracy: 0.9714 - val_loss: 0.1432 - val_accuracy: 0.9778\n",
      "Epoch 320/1000\n",
      "105/105 [==============================] - 0s 179us/step - loss: 0.1099 - accuracy: 0.9714 - val_loss: 0.1389 - val_accuracy: 0.9778\n",
      "Epoch 321/1000\n",
      "105/105 [==============================] - 0s 153us/step - loss: 0.1096 - accuracy: 0.9714 - val_loss: 0.1383 - val_accuracy: 0.9778\n",
      "Epoch 322/1000\n",
      "105/105 [==============================] - 0s 173us/step - loss: 0.1093 - accuracy: 0.9714 - val_loss: 0.1377 - val_accuracy: 0.9778\n",
      "Epoch 323/1000\n",
      "105/105 [==============================] - 0s 159us/step - loss: 0.1086 - accuracy: 0.9714 - val_loss: 0.1376 - val_accuracy: 0.9778\n",
      "Epoch 324/1000\n",
      "105/105 [==============================] - 0s 232us/step - loss: 0.1081 - accuracy: 0.9714 - val_loss: 0.1372 - val_accuracy: 0.9778\n",
      "Epoch 325/1000\n",
      "105/105 [==============================] - 0s 143us/step - loss: 0.1076 - accuracy: 0.9714 - val_loss: 0.1391 - val_accuracy: 0.9778\n",
      "Epoch 326/1000\n",
      "105/105 [==============================] - 0s 137us/step - loss: 0.1071 - accuracy: 0.9714 - val_loss: 0.1392 - val_accuracy: 0.9778\n",
      "Epoch 327/1000\n",
      "105/105 [==============================] - 0s 149us/step - loss: 0.1067 - accuracy: 0.9714 - val_loss: 0.1390 - val_accuracy: 0.9778\n",
      "Epoch 328/1000\n",
      "105/105 [==============================] - 0s 148us/step - loss: 0.1063 - accuracy: 0.9714 - val_loss: 0.1382 - val_accuracy: 0.9778\n",
      "Epoch 329/1000\n",
      "105/105 [==============================] - 0s 158us/step - loss: 0.1057 - accuracy: 0.9714 - val_loss: 0.1392 - val_accuracy: 0.9778\n",
      "Epoch 330/1000\n",
      "105/105 [==============================] - 0s 271us/step - loss: 0.1054 - accuracy: 0.9714 - val_loss: 0.1398 - val_accuracy: 0.9778\n",
      "Epoch 331/1000\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.1051 - accuracy: 0.9714 - val_loss: 0.1385 - val_accuracy: 0.9778\n",
      "Epoch 332/1000\n",
      "105/105 [==============================] - 0s 216us/step - loss: 0.1044 - accuracy: 0.9714 - val_loss: 0.1361 - val_accuracy: 0.9778\n",
      "Epoch 333/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 164us/step - loss: 0.1043 - accuracy: 0.9714 - val_loss: 0.1329 - val_accuracy: 0.9778\n",
      "Epoch 334/1000\n",
      "105/105 [==============================] - 0s 165us/step - loss: 0.1037 - accuracy: 0.9714 - val_loss: 0.1314 - val_accuracy: 0.9778\n",
      "Epoch 335/1000\n",
      "105/105 [==============================] - 0s 110us/step - loss: 0.1033 - accuracy: 0.9714 - val_loss: 0.1311 - val_accuracy: 0.9778\n",
      "Epoch 336/1000\n",
      "105/105 [==============================] - 0s 116us/step - loss: 0.1029 - accuracy: 0.9714 - val_loss: 0.1310 - val_accuracy: 0.9778\n",
      "Epoch 337/1000\n",
      "105/105 [==============================] - 0s 113us/step - loss: 0.1026 - accuracy: 0.9714 - val_loss: 0.1282 - val_accuracy: 0.9778\n",
      "Epoch 338/1000\n",
      "105/105 [==============================] - 0s 127us/step - loss: 0.1032 - accuracy: 0.9619 - val_loss: 0.1248 - val_accuracy: 0.9778\n",
      "Epoch 339/1000\n",
      "105/105 [==============================] - 0s 169us/step - loss: 0.1029 - accuracy: 0.9714 - val_loss: 0.1272 - val_accuracy: 0.9778\n",
      "Epoch 340/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.1023 - accuracy: 0.9714 - val_loss: 0.1300 - val_accuracy: 0.9778\n",
      "Epoch 341/1000\n",
      "105/105 [==============================] - 0s 137us/step - loss: 0.1009 - accuracy: 0.9714 - val_loss: 0.1267 - val_accuracy: 0.9778\n",
      "Epoch 342/1000\n",
      "105/105 [==============================] - 0s 151us/step - loss: 0.1010 - accuracy: 0.9619 - val_loss: 0.1248 - val_accuracy: 0.9778\n",
      "Epoch 343/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.1009 - accuracy: 0.9619 - val_loss: 0.1251 - val_accuracy: 0.9778\n",
      "Epoch 344/1000\n",
      "105/105 [==============================] - 0s 143us/step - loss: 0.1001 - accuracy: 0.9714 - val_loss: 0.1269 - val_accuracy: 0.9778\n",
      "Epoch 345/1000\n",
      "105/105 [==============================] - 0s 158us/step - loss: 0.0996 - accuracy: 0.9714 - val_loss: 0.1330 - val_accuracy: 0.9778\n",
      "Epoch 346/1000\n",
      "105/105 [==============================] - 0s 158us/step - loss: 0.0993 - accuracy: 0.9714 - val_loss: 0.1362 - val_accuracy: 0.9778\n",
      "Epoch 347/1000\n",
      "105/105 [==============================] - 0s 234us/step - loss: 0.0992 - accuracy: 0.9714 - val_loss: 0.1369 - val_accuracy: 0.9778\n",
      "Epoch 348/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.0991 - accuracy: 0.9714 - val_loss: 0.1359 - val_accuracy: 0.9778\n",
      "Epoch 349/1000\n",
      "105/105 [==============================] - 0s 145us/step - loss: 0.0986 - accuracy: 0.9714 - val_loss: 0.1324 - val_accuracy: 0.9778\n",
      "Epoch 350/1000\n",
      "105/105 [==============================] - 0s 254us/step - loss: 0.0977 - accuracy: 0.9714 - val_loss: 0.1242 - val_accuracy: 0.9778\n",
      "Epoch 351/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.0982 - accuracy: 0.9619 - val_loss: 0.1187 - val_accuracy: 0.9778\n",
      "Epoch 352/1000\n",
      "105/105 [==============================] - 0s 112us/step - loss: 0.0990 - accuracy: 0.9714 - val_loss: 0.1174 - val_accuracy: 0.9778\n",
      "Epoch 353/1000\n",
      "105/105 [==============================] - 0s 126us/step - loss: 0.0997 - accuracy: 0.9714 - val_loss: 0.1179 - val_accuracy: 0.9778\n",
      "Epoch 354/1000\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0978 - accuracy: 0.9714 - val_loss: 0.1215 - val_accuracy: 0.9778\n",
      "Epoch 355/1000\n",
      "105/105 [==============================] - 0s 160us/step - loss: 0.0960 - accuracy: 0.9714 - val_loss: 0.1264 - val_accuracy: 0.9778\n",
      "Epoch 356/1000\n",
      "105/105 [==============================] - 0s 114us/step - loss: 0.0953 - accuracy: 0.9714 - val_loss: 0.1321 - val_accuracy: 0.9778\n",
      "Epoch 357/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0962 - accuracy: 0.9714 - val_loss: 0.1347 - val_accuracy: 0.9778\n",
      "Epoch 358/1000\n",
      "105/105 [==============================] - 0s 92us/step - loss: 0.0957 - accuracy: 0.9714 - val_loss: 0.1301 - val_accuracy: 0.9778\n",
      "Epoch 359/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.0946 - accuracy: 0.9714 - val_loss: 0.1257 - val_accuracy: 0.9778\n",
      "Epoch 360/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.0940 - accuracy: 0.9714 - val_loss: 0.1230 - val_accuracy: 0.9778\n",
      "Epoch 361/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0942 - accuracy: 0.9714 - val_loss: 0.1195 - val_accuracy: 0.9778\n",
      "Epoch 362/1000\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.0939 - accuracy: 0.9714 - val_loss: 0.1191 - val_accuracy: 0.9778\n",
      "Epoch 363/1000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.0932 - accuracy: 0.9714 - val_loss: 0.1207 - val_accuracy: 0.9778\n",
      "Epoch 364/1000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 0.0933 - accuracy: 0.9714 - val_loss: 0.1232 - val_accuracy: 0.9778\n",
      "Epoch 365/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.0927 - accuracy: 0.9714 - val_loss: 0.1231 - val_accuracy: 0.9778\n",
      "Epoch 366/1000\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0920 - accuracy: 0.9714 - val_loss: 0.1229 - val_accuracy: 0.9778\n",
      "Epoch 367/1000\n",
      "105/105 [==============================] - 0s 220us/step - loss: 0.0917 - accuracy: 0.9714 - val_loss: 0.1217 - val_accuracy: 0.9778\n",
      "Epoch 368/1000\n",
      "105/105 [==============================] - 0s 170us/step - loss: 0.0915 - accuracy: 0.9714 - val_loss: 0.1202 - val_accuracy: 0.9778\n",
      "Epoch 369/1000\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.96 - 0s 196us/step - loss: 0.0912 - accuracy: 0.9714 - val_loss: 0.1202 - val_accuracy: 0.9778\n",
      "Epoch 370/1000\n",
      "105/105 [==============================] - 0s 159us/step - loss: 0.0908 - accuracy: 0.9714 - val_loss: 0.1207 - val_accuracy: 0.9778\n",
      "Epoch 371/1000\n",
      "105/105 [==============================] - 0s 210us/step - loss: 0.0906 - accuracy: 0.9714 - val_loss: 0.1203 - val_accuracy: 0.9778\n",
      "Epoch 372/1000\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.0904 - accuracy: 0.9714 - val_loss: 0.1167 - val_accuracy: 0.9778\n",
      "Epoch 373/1000\n",
      "105/105 [==============================] - 0s 220us/step - loss: 0.0902 - accuracy: 0.9714 - val_loss: 0.1151 - val_accuracy: 0.9778\n",
      "Epoch 374/1000\n",
      "105/105 [==============================] - 0s 197us/step - loss: 0.0902 - accuracy: 0.9714 - val_loss: 0.1157 - val_accuracy: 0.9778\n",
      "Epoch 375/1000\n",
      "105/105 [==============================] - 0s 100us/step - loss: 0.0900 - accuracy: 0.9714 - val_loss: 0.1194 - val_accuracy: 0.9778\n",
      "Epoch 376/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 0.1191 - val_accuracy: 0.9778\n",
      "Epoch 377/1000\n",
      "105/105 [==============================] - 0s 88us/step - loss: 0.0887 - accuracy: 0.9714 - val_loss: 0.1220 - val_accuracy: 0.9778\n",
      "Epoch 378/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 0.1260 - val_accuracy: 0.9778\n",
      "Epoch 379/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.0895 - accuracy: 0.9714 - val_loss: 0.1251 - val_accuracy: 0.9778\n",
      "Epoch 380/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0889 - accuracy: 0.9714 - val_loss: 0.1179 - val_accuracy: 0.9778\n",
      "Epoch 381/1000\n",
      "105/105 [==============================] - 0s 125us/step - loss: 0.0894 - accuracy: 0.9714 - val_loss: 0.1133 - val_accuracy: 0.9778\n",
      "Epoch 382/1000\n",
      "105/105 [==============================] - 0s 103us/step - loss: 0.0877 - accuracy: 0.9714 - val_loss: 0.1140 - val_accuracy: 0.9778\n",
      "Epoch 383/1000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.0873 - accuracy: 0.9714 - val_loss: 0.1166 - val_accuracy: 0.9778\n",
      "Epoch 384/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0868 - accuracy: 0.9714 - val_loss: 0.1173 - val_accuracy: 0.9778\n",
      "Epoch 385/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.0867 - accuracy: 0.9714 - val_loss: 0.1203 - val_accuracy: 0.9778\n",
      "Epoch 386/1000\n",
      "105/105 [==============================] - 0s 113us/step - loss: 0.0872 - accuracy: 0.9714 - val_loss: 0.1215 - val_accuracy: 0.9778\n",
      "Epoch 387/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.0867 - accuracy: 0.9714 - val_loss: 0.1212 - val_accuracy: 0.9778\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 86us/step - loss: 0.0866 - accuracy: 0.9714 - val_loss: 0.1186 - val_accuracy: 0.9778\n",
      "Epoch 389/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0857 - accuracy: 0.9714 - val_loss: 0.1143 - val_accuracy: 0.9778\n",
      "Epoch 390/1000\n",
      "105/105 [==============================] - 0s 82us/step - loss: 0.0852 - accuracy: 0.9714 - val_loss: 0.1119 - val_accuracy: 0.9778\n",
      "Epoch 391/1000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.0858 - accuracy: 0.9714 - val_loss: 0.1091 - val_accuracy: 0.9778\n",
      "Epoch 392/1000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.0860 - accuracy: 0.9619 - val_loss: 0.1120 - val_accuracy: 0.9778\n",
      "Epoch 393/1000\n",
      "105/105 [==============================] - 0s 92us/step - loss: 0.0852 - accuracy: 0.9714 - val_loss: 0.1140 - val_accuracy: 0.9778\n",
      "Epoch 394/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0850 - accuracy: 0.9714 - val_loss: 0.1128 - val_accuracy: 0.9778\n",
      "Epoch 395/1000\n",
      "105/105 [==============================] - 0s 98us/step - loss: 0.0840 - accuracy: 0.9714 - val_loss: 0.1143 - val_accuracy: 0.9778\n",
      "Epoch 396/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0838 - accuracy: 0.9714 - val_loss: 0.1151 - val_accuracy: 0.9778\n",
      "Epoch 397/1000\n",
      "105/105 [==============================] - 0s 103us/step - loss: 0.0839 - accuracy: 0.9714 - val_loss: 0.1146 - val_accuracy: 0.9778\n",
      "Epoch 398/1000\n",
      "105/105 [==============================] - 0s 113us/step - loss: 0.0837 - accuracy: 0.9714 - val_loss: 0.1174 - val_accuracy: 0.9778\n",
      "Epoch 399/1000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 0.0834 - accuracy: 0.9714 - val_loss: 0.1149 - val_accuracy: 0.9778\n",
      "Epoch 400/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0830 - accuracy: 0.9714 - val_loss: 0.1131 - val_accuracy: 0.9778\n",
      "Epoch 401/1000\n",
      "105/105 [==============================] - 0s 133us/step - loss: 0.0829 - accuracy: 0.9714 - val_loss: 0.1098 - val_accuracy: 0.9778\n",
      "Epoch 402/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0825 - accuracy: 0.9714 - val_loss: 0.1080 - val_accuracy: 0.9778\n",
      "Epoch 403/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.0824 - accuracy: 0.9714 - val_loss: 0.1059 - val_accuracy: 0.9778\n",
      "Epoch 404/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.0827 - accuracy: 0.9714 - val_loss: 0.1057 - val_accuracy: 0.9778\n",
      "Epoch 405/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.0831 - accuracy: 0.9714 - val_loss: 0.1053 - val_accuracy: 0.9778\n",
      "Epoch 406/1000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 0.0816 - accuracy: 0.9810 - val_loss: 0.1113 - val_accuracy: 0.9778\n",
      "Epoch 407/1000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.0824 - accuracy: 0.9714 - val_loss: 0.1168 - val_accuracy: 0.9778\n",
      "Epoch 408/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.0816 - accuracy: 0.9714 - val_loss: 0.1123 - val_accuracy: 0.9778\n",
      "Epoch 409/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.1064 - val_accuracy: 0.9778\n",
      "Epoch 410/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.0808 - accuracy: 0.9714 - val_loss: 0.1071 - val_accuracy: 0.9778\n",
      "Epoch 411/1000\n",
      "105/105 [==============================] - 0s 82us/step - loss: 0.0806 - accuracy: 0.9714 - val_loss: 0.1073 - val_accuracy: 0.9778\n",
      "Epoch 412/1000\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.0808 - accuracy: 0.9714 - val_loss: 0.1053 - val_accuracy: 0.9778\n",
      "Epoch 413/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.0804 - accuracy: 0.9619 - val_loss: 0.1057 - val_accuracy: 0.9778\n",
      "Epoch 414/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.0802 - accuracy: 0.9619 - val_loss: 0.1059 - val_accuracy: 0.9778\n",
      "Epoch 415/1000\n",
      "105/105 [==============================] - 0s 134us/step - loss: 0.0795 - accuracy: 0.9714 - val_loss: 0.1080 - val_accuracy: 0.9778\n",
      "Epoch 416/1000\n",
      "105/105 [==============================] - 0s 88us/step - loss: 0.0790 - accuracy: 0.9714 - val_loss: 0.1111 - val_accuracy: 0.9778\n",
      "Epoch 417/1000\n",
      "105/105 [==============================] - 0s 103us/step - loss: 0.0790 - accuracy: 0.9714 - val_loss: 0.1180 - val_accuracy: 0.9778\n",
      "Epoch 418/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.1230 - val_accuracy: 0.9778\n",
      "Epoch 419/1000\n",
      "105/105 [==============================] - 0s 120us/step - loss: 0.0815 - accuracy: 0.9714 - val_loss: 0.1153 - val_accuracy: 0.9778\n",
      "Epoch 420/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.0797 - accuracy: 0.9714 - val_loss: 0.1085 - val_accuracy: 0.9778\n",
      "Epoch 421/1000\n",
      "105/105 [==============================] - 0s 117us/step - loss: 0.0783 - accuracy: 0.9714 - val_loss: 0.1044 - val_accuracy: 0.9778\n",
      "Epoch 422/1000\n",
      "105/105 [==============================] - 0s 122us/step - loss: 0.0783 - accuracy: 0.9714 - val_loss: 0.1046 - val_accuracy: 0.9778\n",
      "Epoch 423/1000\n",
      "105/105 [==============================] - 0s 136us/step - loss: 0.0781 - accuracy: 0.9714 - val_loss: 0.1065 - val_accuracy: 0.9778\n",
      "Epoch 424/1000\n",
      "105/105 [==============================] - 0s 159us/step - loss: 0.0775 - accuracy: 0.9714 - val_loss: 0.1098 - val_accuracy: 0.9778\n",
      "Epoch 425/1000\n",
      "105/105 [==============================] - 0s 206us/step - loss: 0.0776 - accuracy: 0.9714 - val_loss: 0.1124 - val_accuracy: 0.9778\n",
      "Epoch 426/1000\n",
      "105/105 [==============================] - 0s 158us/step - loss: 0.0783 - accuracy: 0.9714 - val_loss: 0.1134 - val_accuracy: 0.9778\n",
      "Epoch 427/1000\n",
      "105/105 [==============================] - 0s 140us/step - loss: 0.0780 - accuracy: 0.9714 - val_loss: 0.1099 - val_accuracy: 0.9778\n",
      "Epoch 428/1000\n",
      "105/105 [==============================] - 0s 138us/step - loss: 0.0772 - accuracy: 0.9714 - val_loss: 0.1077 - val_accuracy: 0.9778\n",
      "Epoch 429/1000\n",
      "105/105 [==============================] - 0s 136us/step - loss: 0.0770 - accuracy: 0.9714 - val_loss: 0.1043 - val_accuracy: 0.9778\n",
      "Epoch 430/1000\n",
      "105/105 [==============================] - 0s 181us/step - loss: 0.0768 - accuracy: 0.9714 - val_loss: 0.1043 - val_accuracy: 0.9778\n",
      "Epoch 431/1000\n",
      "105/105 [==============================] - 0s 138us/step - loss: 0.0765 - accuracy: 0.9714 - val_loss: 0.1029 - val_accuracy: 0.9778\n",
      "Epoch 432/1000\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.0760 - accuracy: 0.9714 - val_loss: 0.0997 - val_accuracy: 0.9778\n",
      "Epoch 433/1000\n",
      "105/105 [==============================] - 0s 210us/step - loss: 0.0772 - accuracy: 0.9714 - val_loss: 0.0969 - val_accuracy: 0.9778\n",
      "Epoch 434/1000\n",
      "105/105 [==============================] - 0s 122us/step - loss: 0.0793 - accuracy: 0.9810 - val_loss: 0.0958 - val_accuracy: 0.9778\n",
      "Epoch 435/1000\n",
      "105/105 [==============================] - 0s 131us/step - loss: 0.0794 - accuracy: 0.9905 - val_loss: 0.0971 - val_accuracy: 0.9778\n",
      "Epoch 436/1000\n",
      "105/105 [==============================] - 0s 116us/step - loss: 0.0795 - accuracy: 0.9619 - val_loss: 0.1043 - val_accuracy: 0.9778\n",
      "Epoch 437/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.0752 - accuracy: 0.9714 - val_loss: 0.1085 - val_accuracy: 0.9778\n",
      "Epoch 438/1000\n",
      "105/105 [==============================] - 0s 128us/step - loss: 0.0756 - accuracy: 0.9714 - val_loss: 0.1101 - val_accuracy: 0.9778\n",
      "Epoch 439/1000\n",
      "105/105 [==============================] - 0s 158us/step - loss: 0.0761 - accuracy: 0.9714 - val_loss: 0.1092 - val_accuracy: 0.9778\n",
      "Epoch 440/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.0753 - accuracy: 0.9714 - val_loss: 0.1084 - val_accuracy: 0.9778\n",
      "Epoch 441/1000\n",
      "105/105 [==============================] - 0s 177us/step - loss: 0.0753 - accuracy: 0.9714 - val_loss: 0.1064 - val_accuracy: 0.9778\n",
      "Epoch 442/1000\n",
      "105/105 [==============================] - 0s 143us/step - loss: 0.0747 - accuracy: 0.9714 - val_loss: 0.1061 - val_accuracy: 0.9778\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 118us/step - loss: 0.0752 - accuracy: 0.9714 - val_loss: 0.1038 - val_accuracy: 0.9778\n",
      "Epoch 444/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.0748 - accuracy: 0.9714 - val_loss: 0.1051 - val_accuracy: 0.9778\n",
      "Epoch 445/1000\n",
      "105/105 [==============================] - 0s 118us/step - loss: 0.0742 - accuracy: 0.9714 - val_loss: 0.1008 - val_accuracy: 0.9778\n",
      "Epoch 446/1000\n",
      "105/105 [==============================] - 0s 109us/step - loss: 0.0738 - accuracy: 0.9714 - val_loss: 0.1014 - val_accuracy: 0.9778\n",
      "Epoch 447/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.0734 - accuracy: 0.9714 - val_loss: 0.1041 - val_accuracy: 0.9778\n",
      "Epoch 448/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.0737 - accuracy: 0.9714 - val_loss: 0.1077 - val_accuracy: 0.9778\n",
      "Epoch 449/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0741 - accuracy: 0.9714 - val_loss: 0.1078 - val_accuracy: 0.9778\n",
      "Epoch 450/1000\n",
      "105/105 [==============================] - 0s 106us/step - loss: 0.0737 - accuracy: 0.9714 - val_loss: 0.1056 - val_accuracy: 0.9778\n",
      "Epoch 451/1000\n",
      "105/105 [==============================] - 0s 127us/step - loss: 0.0733 - accuracy: 0.9714 - val_loss: 0.1017 - val_accuracy: 0.9778\n",
      "Epoch 452/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.0730 - accuracy: 0.9714 - val_loss: 0.0999 - val_accuracy: 0.9778\n",
      "Epoch 453/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.0729 - accuracy: 0.9714 - val_loss: 0.1001 - val_accuracy: 0.9778\n",
      "Epoch 454/1000\n",
      "105/105 [==============================] - 0s 115us/step - loss: 0.0729 - accuracy: 0.9714 - val_loss: 0.0994 - val_accuracy: 0.9778\n",
      "Epoch 455/1000\n",
      "105/105 [==============================] - 0s 145us/step - loss: 0.0724 - accuracy: 0.9714 - val_loss: 0.1002 - val_accuracy: 0.9778\n",
      "Epoch 456/1000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.0724 - accuracy: 0.9714 - val_loss: 0.1022 - val_accuracy: 0.9778\n",
      "Epoch 457/1000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.0720 - accuracy: 0.9714 - val_loss: 0.1035 - val_accuracy: 0.9778\n",
      "Epoch 458/1000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.0721 - accuracy: 0.9714 - val_loss: 0.1043 - val_accuracy: 0.9778\n",
      "Epoch 459/1000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.0724 - accuracy: 0.9714 - val_loss: 0.1069 - val_accuracy: 0.9778\n",
      "Epoch 460/1000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.0724 - accuracy: 0.9714 - val_loss: 0.1057 - val_accuracy: 0.9778\n",
      "Epoch 461/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.0719 - accuracy: 0.9714 - val_loss: 0.1035 - val_accuracy: 0.9778\n",
      "Epoch 462/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.0723 - accuracy: 0.9714 - val_loss: 0.1000 - val_accuracy: 0.9778\n",
      "Epoch 463/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0711 - accuracy: 0.9714 - val_loss: 0.0990 - val_accuracy: 0.9778\n",
      "Epoch 464/1000\n",
      "105/105 [==============================] - 0s 148us/step - loss: 0.0709 - accuracy: 0.9714 - val_loss: 0.0978 - val_accuracy: 0.9778\n",
      "Epoch 465/1000\n",
      "105/105 [==============================] - 0s 186us/step - loss: 0.0712 - accuracy: 0.9714 - val_loss: 0.0967 - val_accuracy: 0.9778\n",
      "Epoch 466/1000\n",
      "105/105 [==============================] - 0s 115us/step - loss: 0.0709 - accuracy: 0.9619 - val_loss: 0.0971 - val_accuracy: 0.9778\n",
      "Epoch 467/1000\n",
      "105/105 [==============================] - 0s 116us/step - loss: 0.0709 - accuracy: 0.9714 - val_loss: 0.0977 - val_accuracy: 0.9778\n",
      "Epoch 468/1000\n",
      "105/105 [==============================] - 0s 114us/step - loss: 0.0725 - accuracy: 0.9619 - val_loss: 0.0955 - val_accuracy: 0.9778\n",
      "Epoch 469/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0705 - accuracy: 0.9714 - val_loss: 0.0971 - val_accuracy: 0.9778\n",
      "Epoch 470/1000\n",
      "105/105 [==============================] - 0s 138us/step - loss: 0.0698 - accuracy: 0.9714 - val_loss: 0.1000 - val_accuracy: 0.9778\n",
      "Epoch 471/1000\n",
      "105/105 [==============================] - 0s 206us/step - loss: 0.0707 - accuracy: 0.9714 - val_loss: 0.1021 - val_accuracy: 0.9778\n",
      "Epoch 472/1000\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.0697 - accuracy: 0.9714 - val_loss: 0.0970 - val_accuracy: 0.9778\n",
      "Epoch 473/1000\n",
      "105/105 [==============================] - 0s 211us/step - loss: 0.0697 - accuracy: 0.9714 - val_loss: 0.0949 - val_accuracy: 0.9778\n",
      "Epoch 474/1000\n",
      "105/105 [==============================] - 0s 159us/step - loss: 0.0702 - accuracy: 0.9714 - val_loss: 0.0938 - val_accuracy: 0.9778\n",
      "Epoch 475/1000\n",
      "105/105 [==============================] - 0s 160us/step - loss: 0.0704 - accuracy: 0.9714 - val_loss: 0.0912 - val_accuracy: 0.9778\n",
      "Epoch 476/1000\n",
      "105/105 [==============================] - 0s 188us/step - loss: 0.0716 - accuracy: 0.9714 - val_loss: 0.0916 - val_accuracy: 0.9778\n",
      "Epoch 477/1000\n",
      "105/105 [==============================] - 0s 232us/step - loss: 0.0708 - accuracy: 0.9714 - val_loss: 0.0922 - val_accuracy: 0.9778\n",
      "Epoch 478/1000\n",
      "105/105 [==============================] - 0s 155us/step - loss: 0.0698 - accuracy: 0.9714 - val_loss: 0.0947 - val_accuracy: 0.9778\n",
      "Epoch 479/1000\n",
      "105/105 [==============================] - 0s 179us/step - loss: 0.0690 - accuracy: 0.9810 - val_loss: 0.0967 - val_accuracy: 0.9778\n",
      "Epoch 480/1000\n",
      "105/105 [==============================] - 0s 110us/step - loss: 0.0689 - accuracy: 0.9714 - val_loss: 0.0991 - val_accuracy: 0.9778\n",
      "Epoch 481/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 0.0689 - accuracy: 0.9714 - val_loss: 0.1006 - val_accuracy: 0.9778\n",
      "Epoch 482/1000\n",
      "105/105 [==============================] - 0s 82us/step - loss: 0.0698 - accuracy: 0.9714 - val_loss: 0.1032 - val_accuracy: 0.9778\n",
      "Epoch 483/1000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.0691 - accuracy: 0.9714 - val_loss: 0.1041 - val_accuracy: 0.9778\n",
      "Epoch 484/1000\n",
      "105/105 [==============================] - 0s 78us/step - loss: 0.0692 - accuracy: 0.9714 - val_loss: 0.1022 - val_accuracy: 0.9778\n",
      "Epoch 485/1000\n",
      "105/105 [==============================] - 0s 78us/step - loss: 0.0681 - accuracy: 0.9714 - val_loss: 0.0974 - val_accuracy: 0.9778\n",
      "Epoch 486/1000\n",
      "105/105 [==============================] - 0s 100us/step - loss: 0.0677 - accuracy: 0.9714 - val_loss: 0.0922 - val_accuracy: 0.9778\n",
      "Epoch 487/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0690 - accuracy: 0.9714 - val_loss: 0.0911 - val_accuracy: 0.9778\n",
      "Epoch 488/1000\n",
      "105/105 [==============================] - 0s 128us/step - loss: 0.0692 - accuracy: 0.9714 - val_loss: 0.0921 - val_accuracy: 0.9778\n",
      "Epoch 489/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.0671 - accuracy: 0.9714 - val_loss: 0.0978 - val_accuracy: 0.9778\n",
      "Epoch 490/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0686 - accuracy: 0.9714 - val_loss: 0.1055 - val_accuracy: 0.9778\n",
      "Epoch 491/1000\n",
      "105/105 [==============================] - 0s 82us/step - loss: 0.0689 - accuracy: 0.9714 - val_loss: 0.1100 - val_accuracy: 0.9778\n",
      "Epoch 492/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0705 - accuracy: 0.9714 - val_loss: 0.1086 - val_accuracy: 0.9778\n",
      "Epoch 493/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.0697 - accuracy: 0.9714 - val_loss: 0.1006 - val_accuracy: 0.9778\n",
      "Epoch 494/1000\n",
      "105/105 [==============================] - 0s 125us/step - loss: 0.0676 - accuracy: 0.9714 - val_loss: 0.0973 - val_accuracy: 0.9778\n",
      "Epoch 495/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0669 - accuracy: 0.9714 - val_loss: 0.0972 - val_accuracy: 0.9778\n",
      "Epoch 496/1000\n",
      "105/105 [==============================] - 0s 79us/step - loss: 0.0667 - accuracy: 0.9714 - val_loss: 0.0969 - val_accuracy: 0.9778\n",
      "Epoch 497/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.0667 - accuracy: 0.9714 - val_loss: 0.0964 - val_accuracy: 0.9778\n",
      "Epoch 498/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 112us/step - loss: 0.0662 - accuracy: 0.9714 - val_loss: 0.0940 - val_accuracy: 0.9778\n",
      "Epoch 499/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.0665 - accuracy: 0.9714 - val_loss: 0.0924 - val_accuracy: 0.9778\n",
      "Epoch 500/1000\n",
      "105/105 [==============================] - 0s 116us/step - loss: 0.0666 - accuracy: 0.9714 - val_loss: 0.0911 - val_accuracy: 0.9778\n",
      "Epoch 501/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0687 - accuracy: 0.9714 - val_loss: 0.0892 - val_accuracy: 0.9778\n",
      "Epoch 502/1000\n",
      "105/105 [==============================] - 0s 92us/step - loss: 0.0673 - accuracy: 0.9714 - val_loss: 0.0911 - val_accuracy: 0.9778\n",
      "Epoch 503/1000\n",
      "105/105 [==============================] - 0s 100us/step - loss: 0.0670 - accuracy: 0.9619 - val_loss: 0.0965 - val_accuracy: 0.9778\n",
      "Epoch 504/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 0.0677 - accuracy: 0.9714 - val_loss: 0.1011 - val_accuracy: 0.9778\n",
      "Epoch 505/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0665 - accuracy: 0.9714 - val_loss: 0.0995 - val_accuracy: 0.9778\n",
      "Epoch 506/1000\n",
      "105/105 [==============================] - 0s 100us/step - loss: 0.0665 - accuracy: 0.9714 - val_loss: 0.0983 - val_accuracy: 0.9778\n",
      "Epoch 507/1000\n",
      "105/105 [==============================] - 0s 116us/step - loss: 0.0656 - accuracy: 0.9714 - val_loss: 0.0941 - val_accuracy: 0.9778\n",
      "Epoch 508/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0653 - accuracy: 0.9714 - val_loss: 0.0933 - val_accuracy: 0.9778\n",
      "Epoch 509/1000\n",
      "105/105 [==============================] - 0s 103us/step - loss: 0.0650 - accuracy: 0.9714 - val_loss: 0.0948 - val_accuracy: 0.9778\n",
      "Epoch 510/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.0655 - accuracy: 0.9714 - val_loss: 0.0980 - val_accuracy: 0.9778\n",
      "Epoch 511/1000\n",
      "105/105 [==============================] - 0s 144us/step - loss: 0.0655 - accuracy: 0.9714 - val_loss: 0.0978 - val_accuracy: 0.9778\n",
      "Epoch 512/1000\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0651 - accuracy: 0.9714 - val_loss: 0.0980 - val_accuracy: 0.9778\n",
      "Epoch 513/1000\n",
      "105/105 [==============================] - 0s 175us/step - loss: 0.0651 - accuracy: 0.9714 - val_loss: 0.0969 - val_accuracy: 0.9778\n",
      "Epoch 514/1000\n",
      "105/105 [==============================] - 0s 163us/step - loss: 0.0648 - accuracy: 0.9714 - val_loss: 0.0970 - val_accuracy: 0.9778\n",
      "Epoch 515/1000\n",
      "105/105 [==============================] - 0s 131us/step - loss: 0.0646 - accuracy: 0.9714 - val_loss: 0.0976 - val_accuracy: 0.9778\n",
      "Epoch 516/1000\n",
      "105/105 [==============================] - 0s 259us/step - loss: 0.0647 - accuracy: 0.9714 - val_loss: 0.0973 - val_accuracy: 0.9778\n",
      "Epoch 517/1000\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0651 - accuracy: 0.9714 - val_loss: 0.0972 - val_accuracy: 0.9778\n",
      "Epoch 518/1000\n",
      "105/105 [==============================] - 0s 238us/step - loss: 0.0635 - accuracy: 0.9714 - val_loss: 0.0919 - val_accuracy: 0.9778\n",
      "Epoch 519/1000\n",
      "105/105 [==============================] - 0s 197us/step - loss: 0.0640 - accuracy: 0.9810 - val_loss: 0.0893 - val_accuracy: 0.9778\n",
      "Epoch 520/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.0645 - accuracy: 0.9714 - val_loss: 0.0901 - val_accuracy: 0.9778\n",
      "Epoch 521/1000\n",
      "105/105 [==============================] - 0s 185us/step - loss: 0.0656 - accuracy: 0.9619 - val_loss: 0.0936 - val_accuracy: 0.9778\n",
      "Epoch 522/1000\n",
      "105/105 [==============================] - 0s 120us/step - loss: 0.0640 - accuracy: 0.9714 - val_loss: 0.0920 - val_accuracy: 0.9778\n",
      "Epoch 523/1000\n",
      "105/105 [==============================] - 0s 115us/step - loss: 0.0642 - accuracy: 0.9714 - val_loss: 0.0923 - val_accuracy: 0.9778\n",
      "Epoch 524/1000\n",
      "105/105 [==============================] - 0s 196us/step - loss: 0.0639 - accuracy: 0.9714 - val_loss: 0.0958 - val_accuracy: 0.9778\n",
      "Epoch 525/1000\n",
      "105/105 [==============================] - 0s 126us/step - loss: 0.0640 - accuracy: 0.9714 - val_loss: 0.0972 - val_accuracy: 0.9778\n",
      "Epoch 526/1000\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0638 - accuracy: 0.9714 - val_loss: 0.0968 - val_accuracy: 0.9778\n",
      "Epoch 527/1000\n",
      "105/105 [==============================] - 0s 192us/step - loss: 0.0636 - accuracy: 0.9714 - val_loss: 0.0953 - val_accuracy: 0.9778\n",
      "Epoch 528/1000\n",
      "105/105 [==============================] - 0s 193us/step - loss: 0.0637 - accuracy: 0.9714 - val_loss: 0.0958 - val_accuracy: 0.9778\n",
      "Epoch 529/1000\n",
      "105/105 [==============================] - 0s 432us/step - loss: 0.0633 - accuracy: 0.9714 - val_loss: 0.0934 - val_accuracy: 0.9778\n",
      "Epoch 530/1000\n",
      "105/105 [==============================] - 0s 316us/step - loss: 0.0630 - accuracy: 0.9714 - val_loss: 0.0917 - val_accuracy: 0.9778\n",
      "Epoch 531/1000\n",
      "105/105 [==============================] - 0s 163us/step - loss: 0.0628 - accuracy: 0.9714 - val_loss: 0.0914 - val_accuracy: 0.9778\n",
      "Epoch 532/1000\n",
      "105/105 [==============================] - 0s 195us/step - loss: 0.0626 - accuracy: 0.9714 - val_loss: 0.0919 - val_accuracy: 0.9778\n",
      "Epoch 533/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.0628 - accuracy: 0.9714 - val_loss: 0.0938 - val_accuracy: 0.9778\n",
      "Epoch 534/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.0625 - accuracy: 0.9714 - val_loss: 0.0938 - val_accuracy: 0.9778\n",
      "Epoch 535/1000\n",
      "105/105 [==============================] - 0s 176us/step - loss: 0.0629 - accuracy: 0.9714 - val_loss: 0.0942 - val_accuracy: 0.9778\n",
      "Epoch 536/1000\n",
      "105/105 [==============================] - 0s 150us/step - loss: 0.0623 - accuracy: 0.9714 - val_loss: 0.0931 - val_accuracy: 0.9778\n",
      "Epoch 537/1000\n",
      "105/105 [==============================] - 0s 151us/step - loss: 0.0621 - accuracy: 0.9714 - val_loss: 0.0913 - val_accuracy: 0.9778\n",
      "Epoch 538/1000\n",
      "105/105 [==============================] - 0s 205us/step - loss: 0.0624 - accuracy: 0.9714 - val_loss: 0.0885 - val_accuracy: 0.9778\n",
      "Epoch 539/1000\n",
      "105/105 [==============================] - 0s 182us/step - loss: 0.0626 - accuracy: 0.9714 - val_loss: 0.0905 - val_accuracy: 0.9778\n",
      "Epoch 540/1000\n",
      "105/105 [==============================] - 0s 175us/step - loss: 0.0616 - accuracy: 0.9714 - val_loss: 0.0932 - val_accuracy: 0.9778\n",
      "Epoch 541/1000\n",
      "105/105 [==============================] - 0s 195us/step - loss: 0.0619 - accuracy: 0.9714 - val_loss: 0.0949 - val_accuracy: 0.9778\n",
      "Epoch 542/1000\n",
      "105/105 [==============================] - 0s 158us/step - loss: 0.0621 - accuracy: 0.9714 - val_loss: 0.0922 - val_accuracy: 0.9778\n",
      "Epoch 543/1000\n",
      "105/105 [==============================] - 0s 158us/step - loss: 0.0618 - accuracy: 0.9714 - val_loss: 0.0914 - val_accuracy: 0.9778\n",
      "Epoch 544/1000\n",
      "105/105 [==============================] - 0s 203us/step - loss: 0.0623 - accuracy: 0.9714 - val_loss: 0.0940 - val_accuracy: 0.9778\n",
      "Epoch 545/1000\n",
      "105/105 [==============================] - 0s 208us/step - loss: 0.0616 - accuracy: 0.9714 - val_loss: 0.0911 - val_accuracy: 0.9778\n",
      "Epoch 546/1000\n",
      "105/105 [==============================] - 0s 144us/step - loss: 0.0611 - accuracy: 0.9714 - val_loss: 0.0892 - val_accuracy: 0.9778\n",
      "Epoch 547/1000\n",
      "105/105 [==============================] - 0s 262us/step - loss: 0.0632 - accuracy: 0.9714 - val_loss: 0.0866 - val_accuracy: 0.9778\n",
      "Epoch 548/1000\n",
      "105/105 [==============================] - 0s 107us/step - loss: 0.0617 - accuracy: 0.9714 - val_loss: 0.0883 - val_accuracy: 0.9778\n",
      "Epoch 549/1000\n",
      "105/105 [==============================] - 0s 144us/step - loss: 0.0615 - accuracy: 0.9714 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
      "Epoch 550/1000\n",
      "105/105 [==============================] - 0s 199us/step - loss: 0.0610 - accuracy: 0.9714 - val_loss: 0.0893 - val_accuracy: 0.9778\n",
      "Epoch 551/1000\n",
      "105/105 [==============================] - 0s 149us/step - loss: 0.0617 - accuracy: 0.9714 - val_loss: 0.0925 - val_accuracy: 0.9778\n",
      "Epoch 552/1000\n",
      "105/105 [==============================] - 0s 175us/step - loss: 0.0614 - accuracy: 0.9714 - val_loss: 0.0951 - val_accuracy: 0.9778\n",
      "Epoch 553/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 109us/step - loss: 0.0611 - accuracy: 0.9714 - val_loss: 0.0942 - val_accuracy: 0.9778\n",
      "Epoch 554/1000\n",
      "105/105 [==============================] - 0s 117us/step - loss: 0.0613 - accuracy: 0.9714 - val_loss: 0.0918 - val_accuracy: 0.9778\n",
      "Epoch 555/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0614 - accuracy: 0.9714 - val_loss: 0.0933 - val_accuracy: 0.9778\n",
      "Epoch 556/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.0609 - accuracy: 0.9714 - val_loss: 0.0911 - val_accuracy: 0.9778\n",
      "Epoch 557/1000\n",
      "105/105 [==============================] - 0s 72us/step - loss: 0.0611 - accuracy: 0.9714 - val_loss: 0.0900 - val_accuracy: 0.9778\n",
      "Epoch 558/1000\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.0609 - accuracy: 0.9714 - val_loss: 0.0915 - val_accuracy: 0.9778\n",
      "Epoch 559/1000\n",
      "105/105 [==============================] - 0s 75us/step - loss: 0.0605 - accuracy: 0.9810 - val_loss: 0.0881 - val_accuracy: 0.9778\n",
      "Epoch 560/1000\n",
      "105/105 [==============================] - 0s 109us/step - loss: 0.0601 - accuracy: 0.9714 - val_loss: 0.0879 - val_accuracy: 0.9778\n",
      "Epoch 561/1000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.0601 - accuracy: 0.9714 - val_loss: 0.0882 - val_accuracy: 0.9778\n",
      "Epoch 562/1000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.0599 - accuracy: 0.9714 - val_loss: 0.0892 - val_accuracy: 0.9778\n",
      "Epoch 563/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.0600 - accuracy: 0.9714 - val_loss: 0.0930 - val_accuracy: 0.9778\n",
      "Epoch 564/1000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.0601 - accuracy: 0.9714 - val_loss: 0.0914 - val_accuracy: 0.9778\n",
      "Epoch 565/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.0610 - accuracy: 0.9714 - val_loss: 0.0855 - val_accuracy: 0.9778\n",
      "Epoch 566/1000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.0603 - accuracy: 0.9714 - val_loss: 0.0856 - val_accuracy: 0.9778\n",
      "Epoch 567/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.0598 - accuracy: 0.9714 - val_loss: 0.0876 - val_accuracy: 0.9778\n",
      "Epoch 568/1000\n",
      "105/105 [==============================] - 0s 72us/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.0933 - val_accuracy: 0.9778\n",
      "Epoch 569/1000\n",
      "105/105 [==============================] - 0s 88us/step - loss: 0.0599 - accuracy: 0.9714 - val_loss: 0.0945 - val_accuracy: 0.9778\n",
      "Epoch 570/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.0596 - accuracy: 0.9714 - val_loss: 0.0929 - val_accuracy: 0.9778\n",
      "Epoch 571/1000\n",
      "105/105 [==============================] - 0s 107us/step - loss: 0.0598 - accuracy: 0.9714 - val_loss: 0.0913 - val_accuracy: 0.9778\n",
      "Epoch 572/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0592 - accuracy: 0.9714 - val_loss: 0.0918 - val_accuracy: 0.9778\n",
      "Epoch 573/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.0587 - accuracy: 0.9714 - val_loss: 0.0889 - val_accuracy: 0.9778\n",
      "Epoch 574/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 0.0593 - accuracy: 0.9714 - val_loss: 0.0842 - val_accuracy: 0.9778\n",
      "Epoch 575/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.0601 - accuracy: 0.9810 - val_loss: 0.0832 - val_accuracy: 0.9778\n",
      "Epoch 576/1000\n",
      "105/105 [==============================] - 0s 175us/step - loss: 0.0627 - accuracy: 0.9905 - val_loss: 0.0826 - val_accuracy: 0.9778\n",
      "Epoch 577/1000\n",
      "105/105 [==============================] - 0s 147us/step - loss: 0.0616 - accuracy: 0.9714 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
      "Epoch 578/1000\n",
      "105/105 [==============================] - 0s 130us/step - loss: 0.0600 - accuracy: 0.9619 - val_loss: 0.0905 - val_accuracy: 0.9778\n",
      "Epoch 579/1000\n",
      "105/105 [==============================] - 0s 171us/step - loss: 0.0584 - accuracy: 0.9714 - val_loss: 0.0901 - val_accuracy: 0.9778\n",
      "Epoch 580/1000\n",
      "105/105 [==============================] - 0s 98us/step - loss: 0.0586 - accuracy: 0.9714 - val_loss: 0.0902 - val_accuracy: 0.9778\n",
      "Epoch 581/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0588 - accuracy: 0.9714 - val_loss: 0.0884 - val_accuracy: 0.9778\n",
      "Epoch 582/1000\n",
      "105/105 [==============================] - 0s 137us/step - loss: 0.0583 - accuracy: 0.9714 - val_loss: 0.0889 - val_accuracy: 0.9778\n",
      "Epoch 583/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.0578 - accuracy: 0.9810 - val_loss: 0.0863 - val_accuracy: 0.9778\n",
      "Epoch 584/1000\n",
      "105/105 [==============================] - 0s 144us/step - loss: 0.0582 - accuracy: 0.9714 - val_loss: 0.0854 - val_accuracy: 0.9778\n",
      "Epoch 585/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.0592 - accuracy: 0.9714 - val_loss: 0.0871 - val_accuracy: 0.9778\n",
      "Epoch 586/1000\n",
      "105/105 [==============================] - 0s 117us/step - loss: 0.0578 - accuracy: 0.9714 - val_loss: 0.0866 - val_accuracy: 0.9778\n",
      "Epoch 587/1000\n",
      "105/105 [==============================] - 0s 138us/step - loss: 0.0579 - accuracy: 0.9714 - val_loss: 0.0858 - val_accuracy: 0.9778\n",
      "Epoch 588/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.0579 - accuracy: 0.9714 - val_loss: 0.0856 - val_accuracy: 0.9778\n",
      "Epoch 589/1000\n",
      "105/105 [==============================] - 0s 139us/step - loss: 0.0578 - accuracy: 0.9714 - val_loss: 0.0862 - val_accuracy: 0.9778\n",
      "Epoch 590/1000\n",
      "105/105 [==============================] - 0s 164us/step - loss: 0.0578 - accuracy: 0.9810 - val_loss: 0.0882 - val_accuracy: 0.9778\n",
      "Epoch 591/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.0892 - val_accuracy: 0.9778\n",
      "Epoch 592/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.0858 - val_accuracy: 0.9778\n",
      "Epoch 593/1000\n",
      "105/105 [==============================] - 0s 149us/step - loss: 0.0587 - accuracy: 0.9714 - val_loss: 0.0828 - val_accuracy: 0.9778\n",
      "Epoch 594/1000\n",
      "105/105 [==============================] - 0s 133us/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.0859 - val_accuracy: 0.9778\n",
      "Epoch 595/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0568 - accuracy: 0.9714 - val_loss: 0.0920 - val_accuracy: 0.9778\n",
      "Epoch 596/1000\n",
      "105/105 [==============================] - 0s 120us/step - loss: 0.0581 - accuracy: 0.9714 - val_loss: 0.0986 - val_accuracy: 0.9778\n",
      "Epoch 597/1000\n",
      "105/105 [==============================] - 0s 120us/step - loss: 0.0598 - accuracy: 0.9714 - val_loss: 0.1000 - val_accuracy: 0.9778\n",
      "Epoch 598/1000\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0594 - accuracy: 0.9714 - val_loss: 0.0968 - val_accuracy: 0.9778\n",
      "Epoch 599/1000\n",
      "105/105 [==============================] - 0s 238us/step - loss: 0.0582 - accuracy: 0.9714 - val_loss: 0.0930 - val_accuracy: 0.9778\n",
      "Epoch 600/1000\n",
      "105/105 [==============================] - 0s 113us/step - loss: 0.0573 - accuracy: 0.9714 - val_loss: 0.0891 - val_accuracy: 0.9778\n",
      "Epoch 601/1000\n",
      "105/105 [==============================] - 0s 132us/step - loss: 0.0565 - accuracy: 0.9810 - val_loss: 0.0872 - val_accuracy: 0.9778\n",
      "Epoch 602/1000\n",
      "105/105 [==============================] - 0s 145us/step - loss: 0.0568 - accuracy: 0.9714 - val_loss: 0.0857 - val_accuracy: 0.9778\n",
      "Epoch 603/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.0567 - accuracy: 0.9714 - val_loss: 0.0852 - val_accuracy: 0.9778\n",
      "Epoch 604/1000\n",
      "105/105 [==============================] - 0s 122us/step - loss: 0.0567 - accuracy: 0.9714 - val_loss: 0.0865 - val_accuracy: 0.9778\n",
      "Epoch 605/1000\n",
      "105/105 [==============================] - 0s 110us/step - loss: 0.0566 - accuracy: 0.9810 - val_loss: 0.0909 - val_accuracy: 0.9778\n",
      "Epoch 606/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.0566 - accuracy: 0.9714 - val_loss: 0.0934 - val_accuracy: 0.9778\n",
      "Epoch 607/1000\n",
      "105/105 [==============================] - 0s 100us/step - loss: 0.0603 - accuracy: 0.9714 - val_loss: 0.0962 - val_accuracy: 0.9778\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 111us/step - loss: 0.0556 - accuracy: 0.9714 - val_loss: 0.0857 - val_accuracy: 0.9778\n",
      "Epoch 609/1000\n",
      "105/105 [==============================] - 0s 115us/step - loss: 0.0566 - accuracy: 0.9810 - val_loss: 0.0808 - val_accuracy: 0.9778\n",
      "Epoch 610/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0602 - accuracy: 0.9905 - val_loss: 0.0798 - val_accuracy: 0.9778\n",
      "Epoch 611/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.0628 - accuracy: 0.9905 - val_loss: 0.0800 - val_accuracy: 0.9778\n",
      "Epoch 612/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0587 - accuracy: 0.9905 - val_loss: 0.0826 - val_accuracy: 0.9778\n",
      "Epoch 613/1000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.0561 - accuracy: 0.9714 - val_loss: 0.0892 - val_accuracy: 0.9778\n",
      "Epoch 614/1000\n",
      "105/105 [==============================] - 0s 75us/step - loss: 0.0561 - accuracy: 0.9714 - val_loss: 0.0932 - val_accuracy: 0.9778\n",
      "Epoch 615/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.0564 - accuracy: 0.9714 - val_loss: 0.0912 - val_accuracy: 0.9778\n",
      "Epoch 616/1000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.0554 - accuracy: 0.9714 - val_loss: 0.0876 - val_accuracy: 0.9778\n",
      "Epoch 617/1000\n",
      "105/105 [==============================] - 0s 82us/step - loss: 0.0555 - accuracy: 0.9810 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 618/1000\n",
      "105/105 [==============================] - 0s 73us/step - loss: 0.0555 - accuracy: 0.9714 - val_loss: 0.0842 - val_accuracy: 0.9778\n",
      "Epoch 619/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.0558 - accuracy: 0.9714 - val_loss: 0.0837 - val_accuracy: 0.9778\n",
      "Epoch 620/1000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.0561 - accuracy: 0.9810 - val_loss: 0.0818 - val_accuracy: 0.9778\n",
      "Epoch 621/1000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.0563 - accuracy: 0.9810 - val_loss: 0.0832 - val_accuracy: 0.9778\n",
      "Epoch 622/1000\n",
      "105/105 [==============================] - 0s 127us/step - loss: 0.0553 - accuracy: 0.9714 - val_loss: 0.0871 - val_accuracy: 0.9778\n",
      "Epoch 623/1000\n",
      "105/105 [==============================] - 0s 98us/step - loss: 0.0550 - accuracy: 0.9810 - val_loss: 0.0920 - val_accuracy: 0.9778\n",
      "Epoch 624/1000\n",
      "105/105 [==============================] - 0s 112us/step - loss: 0.0556 - accuracy: 0.9714 - val_loss: 0.0918 - val_accuracy: 0.9778\n",
      "Epoch 625/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.0555 - accuracy: 0.9714 - val_loss: 0.0912 - val_accuracy: 0.9778\n",
      "Epoch 626/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0554 - accuracy: 0.9714 - val_loss: 0.0915 - val_accuracy: 0.9778\n",
      "Epoch 627/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0562 - accuracy: 0.9714 - val_loss: 0.0947 - val_accuracy: 0.9778\n",
      "Epoch 628/1000\n",
      "105/105 [==============================] - 0s 160us/step - loss: 0.0562 - accuracy: 0.9714 - val_loss: 0.0938 - val_accuracy: 0.9778\n",
      "Epoch 629/1000\n",
      "105/105 [==============================] - 0s 112us/step - loss: 0.0560 - accuracy: 0.9714 - val_loss: 0.0930 - val_accuracy: 0.9778\n",
      "Epoch 630/1000\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.0545 - accuracy: 0.9714 - val_loss: 0.0868 - val_accuracy: 0.9778\n",
      "Epoch 631/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0570 - accuracy: 0.9714 - val_loss: 0.0814 - val_accuracy: 0.9778\n",
      "Epoch 632/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0561 - accuracy: 0.9810 - val_loss: 0.0817 - val_accuracy: 0.9778\n",
      "Epoch 633/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.0551 - accuracy: 0.9714 - val_loss: 0.0844 - val_accuracy: 0.9778\n",
      "Epoch 634/1000\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.0546 - accuracy: 0.9714 - val_loss: 0.0856 - val_accuracy: 0.9778\n",
      "Epoch 635/1000\n",
      "105/105 [==============================] - 0s 141us/step - loss: 0.0547 - accuracy: 0.9714 - val_loss: 0.0840 - val_accuracy: 0.9778\n",
      "Epoch 636/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0541 - accuracy: 0.9714 - val_loss: 0.0825 - val_accuracy: 0.9778\n",
      "Epoch 637/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.0550 - accuracy: 0.9714 - val_loss: 0.0819 - val_accuracy: 0.9778\n",
      "Epoch 638/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0550 - accuracy: 0.9810 - val_loss: 0.0831 - val_accuracy: 0.9778\n",
      "Epoch 639/1000\n",
      "105/105 [==============================] - 0s 138us/step - loss: 0.0544 - accuracy: 0.9714 - val_loss: 0.0850 - val_accuracy: 0.9778\n",
      "Epoch 640/1000\n",
      "105/105 [==============================] - 0s 155us/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.0853 - val_accuracy: 0.9778\n",
      "Epoch 641/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.0539 - accuracy: 0.9714 - val_loss: 0.0848 - val_accuracy: 0.9778\n",
      "Epoch 642/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.0541 - accuracy: 0.9714 - val_loss: 0.0842 - val_accuracy: 0.9778\n",
      "Epoch 643/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 0.0536 - accuracy: 0.9714 - val_loss: 0.0868 - val_accuracy: 0.9778\n",
      "Epoch 644/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.0906 - val_accuracy: 0.9778\n",
      "Epoch 645/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.0910 - val_accuracy: 0.9778\n",
      "Epoch 646/1000\n",
      "105/105 [==============================] - 0s 107us/step - loss: 0.0541 - accuracy: 0.9714 - val_loss: 0.0903 - val_accuracy: 0.9778\n",
      "Epoch 647/1000\n",
      "105/105 [==============================] - 0s 109us/step - loss: 0.0540 - accuracy: 0.9714 - val_loss: 0.0879 - val_accuracy: 0.9778\n",
      "Epoch 648/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.0861 - val_accuracy: 0.9778\n",
      "Epoch 649/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0854 - val_accuracy: 0.9778\n",
      "Epoch 650/1000\n",
      "105/105 [==============================] - 0s 118us/step - loss: 0.0536 - accuracy: 0.9714 - val_loss: 0.0831 - val_accuracy: 0.9778\n",
      "Epoch 651/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.0537 - accuracy: 0.9714 - val_loss: 0.0842 - val_accuracy: 0.9778\n",
      "Epoch 652/1000\n",
      "105/105 [==============================] - 0s 100us/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0891 - val_accuracy: 0.9778\n",
      "Epoch 653/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.0547 - accuracy: 0.9714 - val_loss: 0.0937 - val_accuracy: 0.9778\n",
      "Epoch 654/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.0548 - accuracy: 0.9714 - val_loss: 0.0938 - val_accuracy: 0.9778\n",
      "Epoch 655/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.0899 - val_accuracy: 0.9778\n",
      "Epoch 656/1000\n",
      "105/105 [==============================] - 0s 92us/step - loss: 0.0532 - accuracy: 0.9714 - val_loss: 0.0833 - val_accuracy: 0.9778\n",
      "Epoch 657/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.0545 - accuracy: 0.9714 - val_loss: 0.0806 - val_accuracy: 0.9778\n",
      "Epoch 658/1000\n",
      "105/105 [==============================] - 0s 141us/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0806 - val_accuracy: 0.9778\n",
      "Epoch 659/1000\n",
      "105/105 [==============================] - 0s 197us/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
      "Epoch 660/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.0537 - accuracy: 0.9714 - val_loss: 0.0885 - val_accuracy: 0.9778\n",
      "Epoch 661/1000\n",
      "105/105 [==============================] - 0s 124us/step - loss: 0.0539 - accuracy: 0.9714 - val_loss: 0.0909 - val_accuracy: 0.9778\n",
      "Epoch 662/1000\n",
      "105/105 [==============================] - 0s 126us/step - loss: 0.0533 - accuracy: 0.9714 - val_loss: 0.0886 - val_accuracy: 0.9778\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 124us/step - loss: 0.0530 - accuracy: 0.9714 - val_loss: 0.0877 - val_accuracy: 0.9778\n",
      "Epoch 664/1000\n",
      "105/105 [==============================] - 0s 215us/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0839 - val_accuracy: 0.9778\n",
      "Epoch 665/1000\n",
      "105/105 [==============================] - 0s 269us/step - loss: 0.0539 - accuracy: 0.9714 - val_loss: 0.0806 - val_accuracy: 0.9778\n",
      "Epoch 666/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0543 - accuracy: 0.9905 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
      "Epoch 667/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0830 - val_accuracy: 0.9778\n",
      "Epoch 668/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.0521 - accuracy: 0.9714 - val_loss: 0.0855 - val_accuracy: 0.9778\n",
      "Epoch 669/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0879 - val_accuracy: 0.9778\n",
      "Epoch 670/1000\n",
      "105/105 [==============================] - 0s 126us/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0876 - val_accuracy: 0.9778\n",
      "Epoch 671/1000\n",
      "105/105 [==============================] - 0s 128us/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0888 - val_accuracy: 0.9778\n",
      "Epoch 672/1000\n",
      "105/105 [==============================] - 0s 109us/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0884 - val_accuracy: 0.9778\n",
      "Epoch 673/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0886 - val_accuracy: 0.9778\n",
      "Epoch 674/1000\n",
      "105/105 [==============================] - 0s 143us/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0884 - val_accuracy: 0.9778\n",
      "Epoch 675/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.0528 - accuracy: 0.9714 - val_loss: 0.0912 - val_accuracy: 0.9778\n",
      "Epoch 676/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.0532 - accuracy: 0.9714 - val_loss: 0.0913 - val_accuracy: 0.9778\n",
      "Epoch 677/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.0524 - accuracy: 0.9714 - val_loss: 0.0882 - val_accuracy: 0.9778\n",
      "Epoch 678/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0512 - accuracy: 0.9810 - val_loss: 0.0840 - val_accuracy: 0.9778\n",
      "Epoch 679/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.0538 - accuracy: 0.9714 - val_loss: 0.0809 - val_accuracy: 0.9778\n",
      "Epoch 680/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0518 - accuracy: 0.9810 - val_loss: 0.0837 - val_accuracy: 0.9778\n",
      "Epoch 681/1000\n",
      "105/105 [==============================] - 0s 153us/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0875 - val_accuracy: 0.9778\n",
      "Epoch 682/1000\n",
      "105/105 [==============================] - 0s 173us/step - loss: 0.0519 - accuracy: 0.9810 - val_loss: 0.0861 - val_accuracy: 0.9778\n",
      "Epoch 683/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0520 - accuracy: 0.9810 - val_loss: 0.0845 - val_accuracy: 0.9778\n",
      "Epoch 684/1000\n",
      "105/105 [==============================] - 0s 132us/step - loss: 0.0514 - accuracy: 0.9714 - val_loss: 0.0830 - val_accuracy: 0.9778\n",
      "Epoch 685/1000\n",
      "105/105 [==============================] - 0s 103us/step - loss: 0.0515 - accuracy: 0.9714 - val_loss: 0.0815 - val_accuracy: 0.9778\n",
      "Epoch 686/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0519 - accuracy: 0.9714 - val_loss: 0.0818 - val_accuracy: 0.9778\n",
      "Epoch 687/1000\n",
      "105/105 [==============================] - 0s 139us/step - loss: 0.0517 - accuracy: 0.9714 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
      "Epoch 688/1000\n",
      "105/105 [==============================] - 0s 114us/step - loss: 0.0513 - accuracy: 0.9714 - val_loss: 0.0840 - val_accuracy: 0.9778\n",
      "Epoch 689/1000\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.0516 - accuracy: 0.9810 - val_loss: 0.0886 - val_accuracy: 0.9778\n",
      "Epoch 690/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.0514 - accuracy: 0.9714 - val_loss: 0.0908 - val_accuracy: 0.9778\n",
      "Epoch 691/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.0524 - accuracy: 0.9714 - val_loss: 0.0908 - val_accuracy: 0.9778\n",
      "Epoch 692/1000\n",
      "105/105 [==============================] - 0s 124us/step - loss: 0.0517 - accuracy: 0.9714 - val_loss: 0.0938 - val_accuracy: 0.9778\n",
      "Epoch 693/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0528 - accuracy: 0.9714 - val_loss: 0.0930 - val_accuracy: 0.9778\n",
      "Epoch 694/1000\n",
      "105/105 [==============================] - 0s 100us/step - loss: 0.0526 - accuracy: 0.9714 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
      "Epoch 695/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.0521 - accuracy: 0.9714 - val_loss: 0.0862 - val_accuracy: 0.9778\n",
      "Epoch 696/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.0507 - accuracy: 0.9810 - val_loss: 0.0849 - val_accuracy: 0.9778\n",
      "Epoch 697/1000\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.0510 - accuracy: 0.9810 - val_loss: 0.0842 - val_accuracy: 0.9778\n",
      "Epoch 698/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.0515 - accuracy: 0.9714 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
      "Epoch 699/1000\n",
      "105/105 [==============================] - 0s 113us/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0803 - val_accuracy: 0.9778\n",
      "Epoch 700/1000\n",
      "105/105 [==============================] - 0s 88us/step - loss: 0.0519 - accuracy: 0.9905 - val_loss: 0.0788 - val_accuracy: 0.9778\n",
      "Epoch 701/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.0532 - accuracy: 0.9905 - val_loss: 0.0797 - val_accuracy: 0.9778\n",
      "Epoch 702/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.0521 - accuracy: 0.9714 - val_loss: 0.0815 - val_accuracy: 0.9778\n",
      "Epoch 703/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.0513 - accuracy: 0.9714 - val_loss: 0.0826 - val_accuracy: 0.9778\n",
      "Epoch 704/1000\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.0505 - accuracy: 0.9714 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
      "Epoch 705/1000\n",
      "105/105 [==============================] - 0s 109us/step - loss: 0.0505 - accuracy: 0.9714 - val_loss: 0.0826 - val_accuracy: 0.9778\n",
      "Epoch 706/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0507 - accuracy: 0.9714 - val_loss: 0.0836 - val_accuracy: 0.9778\n",
      "Epoch 707/1000\n",
      "105/105 [==============================] - 0s 124us/step - loss: 0.0498 - accuracy: 0.9714 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
      "Epoch 708/1000\n",
      "105/105 [==============================] - 0s 143us/step - loss: 0.0508 - accuracy: 0.9810 - val_loss: 0.0897 - val_accuracy: 0.9778\n",
      "Epoch 709/1000\n",
      "105/105 [==============================] - 0s 92us/step - loss: 0.0508 - accuracy: 0.9714 - val_loss: 0.0914 - val_accuracy: 0.9778\n",
      "Epoch 710/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0515 - accuracy: 0.9714 - val_loss: 0.0903 - val_accuracy: 0.9778\n",
      "Epoch 711/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0513 - accuracy: 0.9714 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 712/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.0512 - accuracy: 0.9714 - val_loss: 0.0835 - val_accuracy: 0.9778\n",
      "Epoch 713/1000\n",
      "105/105 [==============================] - 0s 98us/step - loss: 0.0493 - accuracy: 0.9810 - val_loss: 0.0887 - val_accuracy: 0.9778\n",
      "Epoch 714/1000\n",
      "105/105 [==============================] - 0s 140us/step - loss: 0.0508 - accuracy: 0.9714 - val_loss: 0.0951 - val_accuracy: 0.9778\n",
      "Epoch 715/1000\n",
      "105/105 [==============================] - 0s 119us/step - loss: 0.0523 - accuracy: 0.9714 - val_loss: 0.0954 - val_accuracy: 0.9778\n",
      "Epoch 716/1000\n",
      "105/105 [==============================] - 0s 184us/step - loss: 0.0517 - accuracy: 0.9714 - val_loss: 0.0904 - val_accuracy: 0.9778\n",
      "Epoch 717/1000\n",
      "105/105 [==============================] - 0s 249us/step - loss: 0.0509 - accuracy: 0.9810 - val_loss: 0.0839 - val_accuracy: 0.9778\n",
      "Epoch 718/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 179us/step - loss: 0.0499 - accuracy: 0.9714 - val_loss: 0.0823 - val_accuracy: 0.9778\n",
      "Epoch 719/1000\n",
      "105/105 [==============================] - 0s 221us/step - loss: 0.0496 - accuracy: 0.9905 - val_loss: 0.0786 - val_accuracy: 0.9778\n",
      "Epoch 720/1000\n",
      "105/105 [==============================] - 0s 187us/step - loss: 0.0545 - accuracy: 0.9905 - val_loss: 0.0777 - val_accuracy: 0.9778\n",
      "Epoch 721/1000\n",
      "105/105 [==============================] - 0s 168us/step - loss: 0.0551 - accuracy: 0.9905 - val_loss: 0.0783 - val_accuracy: 0.9778\n",
      "Epoch 722/1000\n",
      "105/105 [==============================] - 0s 173us/step - loss: 0.0520 - accuracy: 0.9905 - val_loss: 0.0807 - val_accuracy: 0.9778\n",
      "Epoch 723/1000\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0496 - accuracy: 0.9714 - val_loss: 0.0846 - val_accuracy: 0.9778\n",
      "Epoch 724/1000\n",
      "105/105 [==============================] - 0s 222us/step - loss: 0.0501 - accuracy: 0.9810 - val_loss: 0.0880 - val_accuracy: 0.9778\n",
      "Epoch 725/1000\n",
      "105/105 [==============================] - 0s 159us/step - loss: 0.0497 - accuracy: 0.9810 - val_loss: 0.0858 - val_accuracy: 0.9778\n",
      "Epoch 726/1000\n",
      "105/105 [==============================] - 0s 166us/step - loss: 0.0496 - accuracy: 0.9714 - val_loss: 0.0833 - val_accuracy: 0.9778\n",
      "Epoch 727/1000\n",
      "105/105 [==============================] - 0s 195us/step - loss: 0.0500 - accuracy: 0.9714 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
      "Epoch 728/1000\n",
      "105/105 [==============================] - 0s 198us/step - loss: 0.0491 - accuracy: 0.9714 - val_loss: 0.0844 - val_accuracy: 0.9778\n",
      "Epoch 729/1000\n",
      "105/105 [==============================] - 0s 225us/step - loss: 0.0499 - accuracy: 0.9810 - val_loss: 0.0890 - val_accuracy: 0.9778\n",
      "Epoch 730/1000\n",
      "105/105 [==============================] - 0s 238us/step - loss: 0.0495 - accuracy: 0.9810 - val_loss: 0.0895 - val_accuracy: 0.9778\n",
      "Epoch 731/1000\n",
      "105/105 [==============================] - 0s 198us/step - loss: 0.0496 - accuracy: 0.9810 - val_loss: 0.0884 - val_accuracy: 0.9778\n",
      "Epoch 732/1000\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.0493 - accuracy: 0.9810 - val_loss: 0.0866 - val_accuracy: 0.9778\n",
      "Epoch 733/1000\n",
      "105/105 [==============================] - 0s 224us/step - loss: 0.0492 - accuracy: 0.9810 - val_loss: 0.0845 - val_accuracy: 0.9778\n",
      "Epoch 734/1000\n",
      "105/105 [==============================] - 0s 356us/step - loss: 0.0488 - accuracy: 0.9810 - val_loss: 0.0843 - val_accuracy: 0.9778\n",
      "Epoch 735/1000\n",
      "105/105 [==============================] - 0s 215us/step - loss: 0.0487 - accuracy: 0.9810 - val_loss: 0.0857 - val_accuracy: 0.9778\n",
      "Epoch 736/1000\n",
      "105/105 [==============================] - 0s 187us/step - loss: 0.0487 - accuracy: 0.9810 - val_loss: 0.0874 - val_accuracy: 0.9778\n",
      "Epoch 737/1000\n",
      "105/105 [==============================] - 0s 144us/step - loss: 0.0496 - accuracy: 0.9810 - val_loss: 0.0883 - val_accuracy: 0.9778\n",
      "Epoch 738/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0492 - accuracy: 0.9810 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 739/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0485 - accuracy: 0.9810 - val_loss: 0.0828 - val_accuracy: 0.9778\n",
      "Epoch 740/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.0488 - accuracy: 0.9714 - val_loss: 0.0826 - val_accuracy: 0.9778\n",
      "Epoch 741/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.0489 - accuracy: 0.9714 - val_loss: 0.0823 - val_accuracy: 0.9778\n",
      "Epoch 742/1000\n",
      "105/105 [==============================] - 0s 112us/step - loss: 0.0486 - accuracy: 0.9714 - val_loss: 0.0828 - val_accuracy: 0.9778\n",
      "Epoch 743/1000\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0489 - accuracy: 0.9714 - val_loss: 0.0829 - val_accuracy: 0.9778\n",
      "Epoch 744/1000\n",
      "105/105 [==============================] - 0s 100us/step - loss: 0.0492 - accuracy: 0.9714 - val_loss: 0.0810 - val_accuracy: 0.9778\n",
      "Epoch 745/1000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.0490 - accuracy: 0.9714 - val_loss: 0.0816 - val_accuracy: 0.9778\n",
      "Epoch 746/1000\n",
      "105/105 [==============================] - 0s 126us/step - loss: 0.0488 - accuracy: 0.9714 - val_loss: 0.0829 - val_accuracy: 0.9778\n",
      "Epoch 747/1000\n",
      "105/105 [==============================] - 0s 128us/step - loss: 0.0484 - accuracy: 0.9714 - val_loss: 0.0838 - val_accuracy: 0.9778\n",
      "Epoch 748/1000\n",
      "105/105 [==============================] - 0s 146us/step - loss: 0.0481 - accuracy: 0.9714 - val_loss: 0.0873 - val_accuracy: 0.9778\n",
      "Epoch 749/1000\n",
      "105/105 [==============================] - 0s 139us/step - loss: 0.0484 - accuracy: 0.9810 - val_loss: 0.0906 - val_accuracy: 0.9778\n",
      "Epoch 750/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0491 - accuracy: 0.9810 - val_loss: 0.0910 - val_accuracy: 0.9778\n",
      "Epoch 751/1000\n",
      "105/105 [==============================] - 0s 126us/step - loss: 0.0491 - accuracy: 0.9714 - val_loss: 0.0891 - val_accuracy: 0.9778\n",
      "Epoch 752/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.0487 - accuracy: 0.9810 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
      "Epoch 753/1000\n",
      "105/105 [==============================] - 0s 127us/step - loss: 0.0480 - accuracy: 0.9810 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
      "Epoch 754/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.0480 - accuracy: 0.9810 - val_loss: 0.0865 - val_accuracy: 0.9778\n",
      "Epoch 755/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0486 - accuracy: 0.9810 - val_loss: 0.0858 - val_accuracy: 0.9778\n",
      "Epoch 756/1000\n",
      "105/105 [==============================] - 0s 107us/step - loss: 0.0489 - accuracy: 0.9810 - val_loss: 0.0895 - val_accuracy: 0.9778\n",
      "Epoch 757/1000\n",
      "105/105 [==============================] - 0s 155us/step - loss: 0.0489 - accuracy: 0.9810 - val_loss: 0.0901 - val_accuracy: 0.9778\n",
      "Epoch 758/1000\n",
      "105/105 [==============================] - 0s 114us/step - loss: 0.0484 - accuracy: 0.9810 - val_loss: 0.0872 - val_accuracy: 0.9778\n",
      "Epoch 759/1000\n",
      "105/105 [==============================] - 0s 107us/step - loss: 0.0478 - accuracy: 0.9810 - val_loss: 0.0848 - val_accuracy: 0.9778\n",
      "Epoch 760/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.0481 - accuracy: 0.9714 - val_loss: 0.0836 - val_accuracy: 0.9778\n",
      "Epoch 761/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.0477 - accuracy: 0.9714 - val_loss: 0.0843 - val_accuracy: 0.9778\n",
      "Epoch 762/1000\n",
      "105/105 [==============================] - 0s 131us/step - loss: 0.0475 - accuracy: 0.9810 - val_loss: 0.0866 - val_accuracy: 0.9778\n",
      "Epoch 763/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0478 - accuracy: 0.9810 - val_loss: 0.0890 - val_accuracy: 0.9778\n",
      "Epoch 764/1000\n",
      "105/105 [==============================] - 0s 96us/step - loss: 0.0479 - accuracy: 0.9810 - val_loss: 0.0912 - val_accuracy: 0.9778\n",
      "Epoch 765/1000\n",
      "105/105 [==============================] - 0s 164us/step - loss: 0.0487 - accuracy: 0.9714 - val_loss: 0.0911 - val_accuracy: 0.9778\n",
      "Epoch 766/1000\n",
      "105/105 [==============================] - 0s 112us/step - loss: 0.0479 - accuracy: 0.9810 - val_loss: 0.0868 - val_accuracy: 0.9778\n",
      "Epoch 767/1000\n",
      "105/105 [==============================] - 0s 103us/step - loss: 0.0495 - accuracy: 0.9714 - val_loss: 0.0826 - val_accuracy: 0.9778\n",
      "Epoch 768/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.0476 - accuracy: 0.9714 - val_loss: 0.0840 - val_accuracy: 0.9778\n",
      "Epoch 769/1000\n",
      "105/105 [==============================] - 0s 107us/step - loss: 0.0472 - accuracy: 0.9714 - val_loss: 0.0831 - val_accuracy: 0.9778\n",
      "Epoch 770/1000\n",
      "105/105 [==============================] - 0s 124us/step - loss: 0.0473 - accuracy: 0.9714 - val_loss: 0.0826 - val_accuracy: 0.9778\n",
      "Epoch 771/1000\n",
      "105/105 [==============================] - 0s 122us/step - loss: 0.0475 - accuracy: 0.9714 - val_loss: 0.0834 - val_accuracy: 0.9778\n",
      "Epoch 772/1000\n",
      "105/105 [==============================] - 0s 109us/step - loss: 0.0474 - accuracy: 0.9714 - val_loss: 0.0825 - val_accuracy: 0.9778\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 137us/step - loss: 0.0474 - accuracy: 0.9714 - val_loss: 0.0832 - val_accuracy: 0.9778\n",
      "Epoch 774/1000\n",
      "105/105 [==============================] - 0s 132us/step - loss: 0.0474 - accuracy: 0.9714 - val_loss: 0.0838 - val_accuracy: 0.9778\n",
      "Epoch 775/1000\n",
      "105/105 [==============================] - 0s 119us/step - loss: 0.0482 - accuracy: 0.9714 - val_loss: 0.0814 - val_accuracy: 0.9778\n",
      "Epoch 776/1000\n",
      "105/105 [==============================] - 0s 115us/step - loss: 0.0475 - accuracy: 0.9714 - val_loss: 0.0829 - val_accuracy: 0.9778\n",
      "Epoch 777/1000\n",
      "105/105 [==============================] - 0s 115us/step - loss: 0.0476 - accuracy: 0.9714 - val_loss: 0.0843 - val_accuracy: 0.9778\n",
      "Epoch 778/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.0478 - accuracy: 0.9714 - val_loss: 0.0829 - val_accuracy: 0.9778\n",
      "Epoch 779/1000\n",
      "105/105 [==============================] - 0s 197us/step - loss: 0.0470 - accuracy: 0.9714 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 780/1000\n",
      "105/105 [==============================] - 0s 171us/step - loss: 0.0469 - accuracy: 0.9810 - val_loss: 0.0861 - val_accuracy: 0.9778\n",
      "Epoch 781/1000\n",
      "105/105 [==============================] - 0s 106us/step - loss: 0.0473 - accuracy: 0.9810 - val_loss: 0.0848 - val_accuracy: 0.9778\n",
      "Epoch 782/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.0470 - accuracy: 0.9810 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
      "Epoch 783/1000\n",
      "105/105 [==============================] - 0s 229us/step - loss: 0.0467 - accuracy: 0.9810 - val_loss: 0.0872 - val_accuracy: 0.9778\n",
      "Epoch 784/1000\n",
      "105/105 [==============================] - 0s 185us/step - loss: 0.0469 - accuracy: 0.9810 - val_loss: 0.0871 - val_accuracy: 0.9778\n",
      "Epoch 785/1000\n",
      "105/105 [==============================] - 0s 270us/step - loss: 0.0469 - accuracy: 0.9810 - val_loss: 0.0866 - val_accuracy: 0.9778\n",
      "Epoch 786/1000\n",
      "105/105 [==============================] - 0s 230us/step - loss: 0.0463 - accuracy: 0.9810 - val_loss: 0.0831 - val_accuracy: 0.9778\n",
      "Epoch 787/1000\n",
      "105/105 [==============================] - 0s 209us/step - loss: 0.0470 - accuracy: 0.9714 - val_loss: 0.0812 - val_accuracy: 0.9778\n",
      "Epoch 788/1000\n",
      "105/105 [==============================] - 0s 147us/step - loss: 0.0485 - accuracy: 0.9810 - val_loss: 0.0803 - val_accuracy: 0.9778\n",
      "Epoch 789/1000\n",
      "105/105 [==============================] - 0s 144us/step - loss: 0.0475 - accuracy: 0.9810 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
      "Epoch 790/1000\n",
      "105/105 [==============================] - 0s 146us/step - loss: 0.0472 - accuracy: 0.9810 - val_loss: 0.0814 - val_accuracy: 0.9778\n",
      "Epoch 791/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.0465 - accuracy: 0.9714 - val_loss: 0.0832 - val_accuracy: 0.9778\n",
      "Epoch 792/1000\n",
      "105/105 [==============================] - 0s 136us/step - loss: 0.0471 - accuracy: 0.9714 - val_loss: 0.0859 - val_accuracy: 0.9778\n",
      "Epoch 793/1000\n",
      "105/105 [==============================] - 0s 140us/step - loss: 0.0464 - accuracy: 0.9810 - val_loss: 0.0843 - val_accuracy: 0.9778\n",
      "Epoch 794/1000\n",
      "105/105 [==============================] - 0s 112us/step - loss: 0.0461 - accuracy: 0.9714 - val_loss: 0.0835 - val_accuracy: 0.9778\n",
      "Epoch 795/1000\n",
      "105/105 [==============================] - 0s 125us/step - loss: 0.0460 - accuracy: 0.9714 - val_loss: 0.0823 - val_accuracy: 0.9778\n",
      "Epoch 796/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0478 - accuracy: 0.9810 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
      "Epoch 797/1000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.0476 - accuracy: 0.9810 - val_loss: 0.0809 - val_accuracy: 0.9778\n",
      "Epoch 798/1000\n",
      "105/105 [==============================] - 0s 125us/step - loss: 0.0466 - accuracy: 0.9810 - val_loss: 0.0822 - val_accuracy: 0.9778\n",
      "Epoch 799/1000\n",
      "105/105 [==============================] - 0s 113us/step - loss: 0.0461 - accuracy: 0.9714 - val_loss: 0.0837 - val_accuracy: 0.9778\n",
      "Epoch 800/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.0459 - accuracy: 0.9810 - val_loss: 0.0862 - val_accuracy: 0.9778\n",
      "Epoch 801/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0461 - accuracy: 0.9810 - val_loss: 0.0879 - val_accuracy: 0.9778\n",
      "Epoch 802/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0461 - accuracy: 0.9810 - val_loss: 0.0886 - val_accuracy: 0.9778\n",
      "Epoch 803/1000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.0464 - accuracy: 0.9810 - val_loss: 0.0882 - val_accuracy: 0.9778\n",
      "Epoch 804/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.0468 - accuracy: 0.9810 - val_loss: 0.0895 - val_accuracy: 0.9778\n",
      "Epoch 805/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.0471 - accuracy: 0.9810 - val_loss: 0.0874 - val_accuracy: 0.9778\n",
      "Epoch 806/1000\n",
      "105/105 [==============================] - 0s 122us/step - loss: 0.0460 - accuracy: 0.9810 - val_loss: 0.0866 - val_accuracy: 0.9778\n",
      "Epoch 807/1000\n",
      "105/105 [==============================] - 0s 103us/step - loss: 0.0459 - accuracy: 0.9810 - val_loss: 0.0883 - val_accuracy: 0.9778\n",
      "Epoch 808/1000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.0460 - accuracy: 0.9810 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
      "Epoch 809/1000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.0464 - accuracy: 0.9810 - val_loss: 0.0892 - val_accuracy: 0.9778\n",
      "Epoch 810/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.0460 - accuracy: 0.9810 - val_loss: 0.0867 - val_accuracy: 0.9778\n",
      "Epoch 811/1000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.0459 - accuracy: 0.9810 - val_loss: 0.0836 - val_accuracy: 0.9778\n",
      "Epoch 812/1000\n",
      "105/105 [==============================] - 0s 75us/step - loss: 0.0454 - accuracy: 0.9714 - val_loss: 0.0820 - val_accuracy: 0.9778\n",
      "Epoch 813/1000\n",
      "105/105 [==============================] - 0s 122us/step - loss: 0.0462 - accuracy: 0.9714 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
      "Epoch 814/1000\n",
      "105/105 [==============================] - 0s 78us/step - loss: 0.0468 - accuracy: 0.9905 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
      "Epoch 815/1000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.0460 - accuracy: 0.9810 - val_loss: 0.0823 - val_accuracy: 0.9778\n",
      "Epoch 816/1000\n",
      "105/105 [==============================] - 0s 72us/step - loss: 0.0451 - accuracy: 0.9714 - val_loss: 0.0855 - val_accuracy: 0.9778\n",
      "Epoch 817/1000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 0.0464 - accuracy: 0.9810 - val_loss: 0.0882 - val_accuracy: 0.9778\n",
      "Epoch 818/1000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.0460 - accuracy: 0.9810 - val_loss: 0.0861 - val_accuracy: 0.9778\n",
      "Epoch 819/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 0.0453 - accuracy: 0.9810 - val_loss: 0.0863 - val_accuracy: 0.9778\n",
      "Epoch 820/1000\n",
      "105/105 [==============================] - 0s 110us/step - loss: 0.0451 - accuracy: 0.9810 - val_loss: 0.0866 - val_accuracy: 0.9778\n",
      "Epoch 821/1000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.0453 - accuracy: 0.9810 - val_loss: 0.0865 - val_accuracy: 0.9778\n",
      "Epoch 822/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0450 - accuracy: 0.9810 - val_loss: 0.0833 - val_accuracy: 0.9778\n",
      "Epoch 823/1000\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.0448 - accuracy: 0.9714 - val_loss: 0.0800 - val_accuracy: 0.9778\n",
      "Epoch 824/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 0.0466 - accuracy: 0.9905 - val_loss: 0.0789 - val_accuracy: 0.9778\n",
      "Epoch 825/1000\n",
      "105/105 [==============================] - 0s 110us/step - loss: 0.0482 - accuracy: 0.9905 - val_loss: 0.0797 - val_accuracy: 0.9778\n",
      "Epoch 826/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.0466 - accuracy: 0.9905 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
      "Epoch 827/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0463 - accuracy: 0.9810 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 101us/step - loss: 0.0449 - accuracy: 0.9714 - val_loss: 0.0841 - val_accuracy: 0.9778\n",
      "Epoch 829/1000\n",
      "105/105 [==============================] - 0s 98us/step - loss: 0.0446 - accuracy: 0.9714 - val_loss: 0.0855 - val_accuracy: 0.9778\n",
      "Epoch 830/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.0446 - accuracy: 0.9810 - val_loss: 0.0863 - val_accuracy: 0.9778\n",
      "Epoch 831/1000\n",
      "105/105 [==============================] - 0s 106us/step - loss: 0.0447 - accuracy: 0.9810 - val_loss: 0.0866 - val_accuracy: 0.9778\n",
      "Epoch 832/1000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.0448 - accuracy: 0.9810 - val_loss: 0.0858 - val_accuracy: 0.9778\n",
      "Epoch 833/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 0.0446 - accuracy: 0.9714 - val_loss: 0.0819 - val_accuracy: 0.9778\n",
      "Epoch 834/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0457 - accuracy: 0.9905 - val_loss: 0.0796 - val_accuracy: 0.9778\n",
      "Epoch 835/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0497 - accuracy: 0.9905 - val_loss: 0.0786 - val_accuracy: 0.9778\n",
      "Epoch 836/1000\n",
      "105/105 [==============================] - 0s 82us/step - loss: 0.0484 - accuracy: 0.9810 - val_loss: 0.0830 - val_accuracy: 0.9778\n",
      "Epoch 837/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.0443 - accuracy: 0.9714 - val_loss: 0.0858 - val_accuracy: 0.9778\n",
      "Epoch 838/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0447 - accuracy: 0.9810 - val_loss: 0.0889 - val_accuracy: 0.9778\n",
      "Epoch 839/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0449 - accuracy: 0.9810 - val_loss: 0.0886 - val_accuracy: 0.9778\n",
      "Epoch 840/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0452 - accuracy: 0.9810 - val_loss: 0.0887 - val_accuracy: 0.9778\n",
      "Epoch 841/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.0447 - accuracy: 0.9810 - val_loss: 0.0865 - val_accuracy: 0.9778\n",
      "Epoch 842/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0444 - accuracy: 0.9810 - val_loss: 0.0853 - val_accuracy: 0.9778\n",
      "Epoch 843/1000\n",
      "105/105 [==============================] - 0s 215us/step - loss: 0.0443 - accuracy: 0.9810 - val_loss: 0.0840 - val_accuracy: 0.9778\n",
      "Epoch 844/1000\n",
      "105/105 [==============================] - 0s 202us/step - loss: 0.0447 - accuracy: 0.9714 - val_loss: 0.0838 - val_accuracy: 0.9778\n",
      "Epoch 845/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.0441 - accuracy: 0.9714 - val_loss: 0.0860 - val_accuracy: 0.9778\n",
      "Epoch 846/1000\n",
      "105/105 [==============================] - 0s 166us/step - loss: 0.0442 - accuracy: 0.9810 - val_loss: 0.0877 - val_accuracy: 0.9778\n",
      "Epoch 847/1000\n",
      "105/105 [==============================] - 0s 183us/step - loss: 0.0453 - accuracy: 0.9810 - val_loss: 0.0888 - val_accuracy: 0.9778\n",
      "Epoch 848/1000\n",
      "105/105 [==============================] - 0s 147us/step - loss: 0.0443 - accuracy: 0.9810 - val_loss: 0.0867 - val_accuracy: 0.9778\n",
      "Epoch 849/1000\n",
      "105/105 [==============================] - 0s 146us/step - loss: 0.0444 - accuracy: 0.9810 - val_loss: 0.0852 - val_accuracy: 0.9778\n",
      "Epoch 850/1000\n",
      "105/105 [==============================] - 0s 146us/step - loss: 0.0446 - accuracy: 0.9810 - val_loss: 0.0857 - val_accuracy: 0.9778\n",
      "Epoch 851/1000\n",
      "105/105 [==============================] - 0s 191us/step - loss: 0.0445 - accuracy: 0.9810 - val_loss: 0.0849 - val_accuracy: 0.9778\n",
      "Epoch 852/1000\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.0447 - accuracy: 0.9810 - val_loss: 0.0880 - val_accuracy: 0.9778\n",
      "Epoch 853/1000\n",
      "105/105 [==============================] - 0s 148us/step - loss: 0.0446 - accuracy: 0.9810 - val_loss: 0.0886 - val_accuracy: 0.9778\n",
      "Epoch 854/1000\n",
      "105/105 [==============================] - 0s 151us/step - loss: 0.0441 - accuracy: 0.9810 - val_loss: 0.0862 - val_accuracy: 0.9778\n",
      "Epoch 855/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.0437 - accuracy: 0.9810 - val_loss: 0.0855 - val_accuracy: 0.9778\n",
      "Epoch 856/1000\n",
      "105/105 [==============================] - 0s 204us/step - loss: 0.0439 - accuracy: 0.9810 - val_loss: 0.0853 - val_accuracy: 0.9778\n",
      "Epoch 857/1000\n",
      "105/105 [==============================] - 0s 143us/step - loss: 0.0438 - accuracy: 0.9810 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 858/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.0437 - accuracy: 0.9810 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 859/1000\n",
      "105/105 [==============================] - 0s 130us/step - loss: 0.0437 - accuracy: 0.9714 - val_loss: 0.0844 - val_accuracy: 0.9778\n",
      "Epoch 860/1000\n",
      "105/105 [==============================] - 0s 187us/step - loss: 0.0437 - accuracy: 0.9714 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 861/1000\n",
      "105/105 [==============================] - 0s 259us/step - loss: 0.0433 - accuracy: 0.9714 - val_loss: 0.0832 - val_accuracy: 0.9778\n",
      "Epoch 862/1000\n",
      "105/105 [==============================] - 0s 137us/step - loss: 0.0437 - accuracy: 0.9714 - val_loss: 0.0829 - val_accuracy: 0.9778\n",
      "Epoch 863/1000\n",
      "105/105 [==============================] - 0s 159us/step - loss: 0.0437 - accuracy: 0.9714 - val_loss: 0.0831 - val_accuracy: 0.9778\n",
      "Epoch 864/1000\n",
      "105/105 [==============================] - 0s 120us/step - loss: 0.0437 - accuracy: 0.9714 - val_loss: 0.0836 - val_accuracy: 0.9778\n",
      "Epoch 865/1000\n",
      "105/105 [==============================] - 0s 130us/step - loss: 0.0442 - accuracy: 0.9714 - val_loss: 0.0854 - val_accuracy: 0.9778\n",
      "Epoch 866/1000\n",
      "105/105 [==============================] - 0s 162us/step - loss: 0.0437 - accuracy: 0.9810 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
      "Epoch 867/1000\n",
      "105/105 [==============================] - 0s 219us/step - loss: 0.0434 - accuracy: 0.9810 - val_loss: 0.0873 - val_accuracy: 0.9778\n",
      "Epoch 868/1000\n",
      "105/105 [==============================] - 0s 194us/step - loss: 0.0437 - accuracy: 0.9810 - val_loss: 0.0892 - val_accuracy: 0.9778\n",
      "Epoch 869/1000\n",
      "105/105 [==============================] - 0s 185us/step - loss: 0.0439 - accuracy: 0.9810 - val_loss: 0.0889 - val_accuracy: 0.9778\n",
      "Epoch 870/1000\n",
      "105/105 [==============================] - 0s 111us/step - loss: 0.0434 - accuracy: 0.9810 - val_loss: 0.0859 - val_accuracy: 0.9778\n",
      "Epoch 871/1000\n",
      "105/105 [==============================] - 0s 134us/step - loss: 0.0433 - accuracy: 0.9810 - val_loss: 0.0851 - val_accuracy: 0.9778\n",
      "Epoch 872/1000\n",
      "105/105 [==============================] - 0s 145us/step - loss: 0.0435 - accuracy: 0.9714 - val_loss: 0.0856 - val_accuracy: 0.9778\n",
      "Epoch 873/1000\n",
      "105/105 [==============================] - 0s 136us/step - loss: 0.0431 - accuracy: 0.9810 - val_loss: 0.0842 - val_accuracy: 0.9778\n",
      "Epoch 874/1000\n",
      "105/105 [==============================] - 0s 126us/step - loss: 0.0431 - accuracy: 0.9714 - val_loss: 0.0839 - val_accuracy: 0.9778\n",
      "Epoch 875/1000\n",
      "105/105 [==============================] - 0s 131us/step - loss: 0.0431 - accuracy: 0.9714 - val_loss: 0.0841 - val_accuracy: 0.9778\n",
      "Epoch 876/1000\n",
      "105/105 [==============================] - 0s 134us/step - loss: 0.0433 - accuracy: 0.9714 - val_loss: 0.0836 - val_accuracy: 0.9778\n",
      "Epoch 877/1000\n",
      "105/105 [==============================] - 0s 125us/step - loss: 0.0426 - accuracy: 0.9810 - val_loss: 0.0809 - val_accuracy: 0.9778\n",
      "Epoch 878/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.0457 - accuracy: 0.9905 - val_loss: 0.0789 - val_accuracy: 0.9778\n",
      "Epoch 879/1000\n",
      "105/105 [==============================] - 0s 112us/step - loss: 0.0463 - accuracy: 0.9905 - val_loss: 0.0809 - val_accuracy: 0.9778\n",
      "Epoch 880/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.0431 - accuracy: 0.9810 - val_loss: 0.0856 - val_accuracy: 0.9778\n",
      "Epoch 881/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.0427 - accuracy: 0.9810 - val_loss: 0.0883 - val_accuracy: 0.9778\n",
      "Epoch 882/1000\n",
      "105/105 [==============================] - 0s 113us/step - loss: 0.0431 - accuracy: 0.9810 - val_loss: 0.0869 - val_accuracy: 0.9778\n",
      "Epoch 883/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 117us/step - loss: 0.0430 - accuracy: 0.9810 - val_loss: 0.0846 - val_accuracy: 0.9778\n",
      "Epoch 884/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 0.0429 - accuracy: 0.9714 - val_loss: 0.0827 - val_accuracy: 0.9778\n",
      "Epoch 885/1000\n",
      "105/105 [==============================] - 0s 88us/step - loss: 0.0432 - accuracy: 0.9810 - val_loss: 0.0833 - val_accuracy: 0.9778\n",
      "Epoch 886/1000\n",
      "105/105 [==============================] - 0s 82us/step - loss: 0.0430 - accuracy: 0.9714 - val_loss: 0.0852 - val_accuracy: 0.9778\n",
      "Epoch 887/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.0431 - accuracy: 0.9714 - val_loss: 0.0837 - val_accuracy: 0.9778\n",
      "Epoch 888/1000\n",
      "105/105 [==============================] - 0s 98us/step - loss: 0.0427 - accuracy: 0.9714 - val_loss: 0.0838 - val_accuracy: 0.9778\n",
      "Epoch 889/1000\n",
      "105/105 [==============================] - 0s 108us/step - loss: 0.0427 - accuracy: 0.9714 - val_loss: 0.0857 - val_accuracy: 0.9778\n",
      "Epoch 890/1000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.0448 - accuracy: 0.9810 - val_loss: 0.0882 - val_accuracy: 0.9778\n",
      "Epoch 891/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0427 - accuracy: 0.9810 - val_loss: 0.0840 - val_accuracy: 0.9778\n",
      "Epoch 892/1000\n",
      "105/105 [==============================] - 0s 109us/step - loss: 0.0424 - accuracy: 0.9714 - val_loss: 0.0818 - val_accuracy: 0.9778\n",
      "Epoch 893/1000\n",
      "105/105 [==============================] - 0s 107us/step - loss: 0.0437 - accuracy: 0.9905 - val_loss: 0.0813 - val_accuracy: 0.9778\n",
      "Epoch 894/1000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.0433 - accuracy: 0.9905 - val_loss: 0.0828 - val_accuracy: 0.9778\n",
      "Epoch 895/1000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.0431 - accuracy: 0.9714 - val_loss: 0.0843 - val_accuracy: 0.9778\n",
      "Epoch 896/1000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.0425 - accuracy: 0.9714 - val_loss: 0.0828 - val_accuracy: 0.9778\n",
      "Epoch 897/1000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.0426 - accuracy: 0.9810 - val_loss: 0.0833 - val_accuracy: 0.9778\n",
      "Epoch 898/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.0428 - accuracy: 0.9714 - val_loss: 0.0853 - val_accuracy: 0.9778\n",
      "Epoch 899/1000\n",
      "105/105 [==============================] - 0s 79us/step - loss: 0.0429 - accuracy: 0.9810 - val_loss: 0.0869 - val_accuracy: 0.9778\n",
      "Epoch 900/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.0422 - accuracy: 0.9810 - val_loss: 0.0893 - val_accuracy: 0.9778\n",
      "Epoch 901/1000\n",
      "105/105 [==============================] - 0s 114us/step - loss: 0.0430 - accuracy: 0.9810 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
      "Epoch 902/1000\n",
      "105/105 [==============================] - 0s 74us/step - loss: 0.0426 - accuracy: 0.9810 - val_loss: 0.0870 - val_accuracy: 0.9778\n",
      "Epoch 903/1000\n",
      "105/105 [==============================] - 0s 79us/step - loss: 0.0421 - accuracy: 0.9810 - val_loss: 0.0856 - val_accuracy: 0.9778\n",
      "Epoch 904/1000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.0421 - accuracy: 0.9810 - val_loss: 0.0865 - val_accuracy: 0.9778\n",
      "Epoch 905/1000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.0424 - accuracy: 0.9810 - val_loss: 0.0880 - val_accuracy: 0.9778\n",
      "Epoch 906/1000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 0.0428 - accuracy: 0.9810 - val_loss: 0.0871 - val_accuracy: 0.9778\n",
      "Epoch 907/1000\n",
      "105/105 [==============================] - 0s 114us/step - loss: 0.0426 - accuracy: 0.9810 - val_loss: 0.0831 - val_accuracy: 0.9778\n",
      "Epoch 908/1000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.0425 - accuracy: 0.9714 - val_loss: 0.0851 - val_accuracy: 0.9778\n",
      "Epoch 909/1000\n",
      "105/105 [==============================] - 0s 98us/step - loss: 0.0415 - accuracy: 0.9810 - val_loss: 0.0891 - val_accuracy: 0.9778\n",
      "Epoch 910/1000\n",
      "105/105 [==============================] - 0s 107us/step - loss: 0.0426 - accuracy: 0.9810 - val_loss: 0.0913 - val_accuracy: 0.9778\n",
      "Epoch 911/1000\n",
      "105/105 [==============================] - 0s 116us/step - loss: 0.0431 - accuracy: 0.9810 - val_loss: 0.0941 - val_accuracy: 0.9778\n",
      "Epoch 912/1000\n",
      "105/105 [==============================] - 0s 136us/step - loss: 0.0446 - accuracy: 0.9810 - val_loss: 0.0964 - val_accuracy: 0.9778\n",
      "Epoch 913/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0444 - accuracy: 0.9810 - val_loss: 0.0940 - val_accuracy: 0.9778\n",
      "Epoch 914/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0435 - accuracy: 0.9810 - val_loss: 0.0919 - val_accuracy: 0.9778\n",
      "Epoch 915/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.0426 - accuracy: 0.9810 - val_loss: 0.0885 - val_accuracy: 0.9778\n",
      "Epoch 916/1000\n",
      "105/105 [==============================] - 0s 130us/step - loss: 0.0417 - accuracy: 0.9810 - val_loss: 0.0862 - val_accuracy: 0.9778\n",
      "Epoch 917/1000\n",
      "105/105 [==============================] - 0s 92us/step - loss: 0.0418 - accuracy: 0.9810 - val_loss: 0.0836 - val_accuracy: 0.9778\n",
      "Epoch 918/1000\n",
      "105/105 [==============================] - 0s 134us/step - loss: 0.0419 - accuracy: 0.9810 - val_loss: 0.0832 - val_accuracy: 0.9778\n",
      "Epoch 919/1000\n",
      "105/105 [==============================] - 0s 147us/step - loss: 0.0421 - accuracy: 0.9810 - val_loss: 0.0839 - val_accuracy: 0.9778\n",
      "Epoch 920/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.0423 - accuracy: 0.9810 - val_loss: 0.0844 - val_accuracy: 0.9778\n",
      "Epoch 921/1000\n",
      "105/105 [==============================] - 0s 128us/step - loss: 0.0411 - accuracy: 0.9810 - val_loss: 0.0887 - val_accuracy: 0.9778\n",
      "Epoch 922/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.0421 - accuracy: 0.9810 - val_loss: 0.0896 - val_accuracy: 0.9778\n",
      "Epoch 923/1000\n",
      "105/105 [==============================] - 0s 118us/step - loss: 0.0416 - accuracy: 0.9810 - val_loss: 0.0856 - val_accuracy: 0.9778\n",
      "Epoch 924/1000\n",
      "105/105 [==============================] - 0s 116us/step - loss: 0.0413 - accuracy: 0.9714 - val_loss: 0.0832 - val_accuracy: 0.9778\n",
      "Epoch 925/1000\n",
      "105/105 [==============================] - 0s 123us/step - loss: 0.0432 - accuracy: 0.9810 - val_loss: 0.0806 - val_accuracy: 0.9778\n",
      "Epoch 926/1000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.0434 - accuracy: 0.9905 - val_loss: 0.0819 - val_accuracy: 0.9778\n",
      "Epoch 927/1000\n",
      "105/105 [==============================] - 0s 99us/step - loss: 0.0420 - accuracy: 0.9905 - val_loss: 0.0852 - val_accuracy: 0.9778\n",
      "Epoch 928/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0424 - accuracy: 0.9810 - val_loss: 0.0909 - val_accuracy: 0.9778\n",
      "Epoch 929/1000\n",
      "105/105 [==============================] - 0s 136us/step - loss: 0.0421 - accuracy: 0.9810 - val_loss: 0.0894 - val_accuracy: 0.9778\n",
      "Epoch 930/1000\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.0417 - accuracy: 0.9810 - val_loss: 0.0875 - val_accuracy: 0.9778\n",
      "Epoch 931/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0413 - accuracy: 0.9810 - val_loss: 0.0868 - val_accuracy: 0.9778\n",
      "Epoch 932/1000\n",
      "105/105 [==============================] - 0s 155us/step - loss: 0.0412 - accuracy: 0.9810 - val_loss: 0.0870 - val_accuracy: 0.9778\n",
      "Epoch 933/1000\n",
      "105/105 [==============================] - 0s 203us/step - loss: 0.0411 - accuracy: 0.9810 - val_loss: 0.0860 - val_accuracy: 0.9778\n",
      "Epoch 934/1000\n",
      "105/105 [==============================] - 0s 119us/step - loss: 0.0418 - accuracy: 0.9714 - val_loss: 0.0853 - val_accuracy: 0.9778\n",
      "Epoch 935/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0411 - accuracy: 0.9714 - val_loss: 0.0862 - val_accuracy: 0.9778\n",
      "Epoch 936/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0416 - accuracy: 0.9810 - val_loss: 0.0877 - val_accuracy: 0.9778\n",
      "Epoch 937/1000\n",
      "105/105 [==============================] - 0s 112us/step - loss: 0.0410 - accuracy: 0.9810 - val_loss: 0.0855 - val_accuracy: 0.9778\n",
      "Epoch 938/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 125us/step - loss: 0.0417 - accuracy: 0.9714 - val_loss: 0.0833 - val_accuracy: 0.9778\n",
      "Epoch 939/1000\n",
      "105/105 [==============================] - 0s 114us/step - loss: 0.0433 - accuracy: 0.9810 - val_loss: 0.0818 - val_accuracy: 0.9778\n",
      "Epoch 940/1000\n",
      "105/105 [==============================] - 0s 107us/step - loss: 0.0417 - accuracy: 0.9810 - val_loss: 0.0839 - val_accuracy: 0.9778\n",
      "Epoch 941/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.0420 - accuracy: 0.9714 - val_loss: 0.0877 - val_accuracy: 0.9778\n",
      "Epoch 942/1000\n",
      "105/105 [==============================] - 0s 90us/step - loss: 0.0410 - accuracy: 0.9810 - val_loss: 0.0895 - val_accuracy: 0.9778\n",
      "Epoch 943/1000\n",
      "105/105 [==============================] - 0s 88us/step - loss: 0.0412 - accuracy: 0.9810 - val_loss: 0.0900 - val_accuracy: 0.9778\n",
      "Epoch 944/1000\n",
      "105/105 [==============================] - 0s 135us/step - loss: 0.0418 - accuracy: 0.9810 - val_loss: 0.0889 - val_accuracy: 0.9778\n",
      "Epoch 945/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0411 - accuracy: 0.9810 - val_loss: 0.0899 - val_accuracy: 0.9778\n",
      "Epoch 946/1000\n",
      "105/105 [==============================] - 0s 110us/step - loss: 0.0416 - accuracy: 0.9810 - val_loss: 0.0906 - val_accuracy: 0.9778\n",
      "Epoch 947/1000\n",
      "105/105 [==============================] - 0s 91us/step - loss: 0.0433 - accuracy: 0.9810 - val_loss: 0.0919 - val_accuracy: 0.9778\n",
      "Epoch 948/1000\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.0421 - accuracy: 0.9810 - val_loss: 0.0845 - val_accuracy: 0.9778\n",
      "Epoch 949/1000\n",
      "105/105 [==============================] - 0s 102us/step - loss: 0.0407 - accuracy: 0.9810 - val_loss: 0.0828 - val_accuracy: 0.9778\n",
      "Epoch 950/1000\n",
      "105/105 [==============================] - 0s 117us/step - loss: 0.0433 - accuracy: 0.9905 - val_loss: 0.0814 - val_accuracy: 0.9778\n",
      "Epoch 951/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.0427 - accuracy: 0.9905 - val_loss: 0.0818 - val_accuracy: 0.9778\n",
      "Epoch 952/1000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.0424 - accuracy: 0.9905 - val_loss: 0.0850 - val_accuracy: 0.9778\n",
      "Epoch 953/1000\n",
      "105/105 [==============================] - 0s 78us/step - loss: 0.0405 - accuracy: 0.9714 - val_loss: 0.0871 - val_accuracy: 0.9778\n",
      "Epoch 954/1000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.0405 - accuracy: 0.9810 - val_loss: 0.0880 - val_accuracy: 0.9778\n",
      "Epoch 955/1000\n",
      "105/105 [==============================] - 0s 114us/step - loss: 0.0413 - accuracy: 0.9810 - val_loss: 0.0888 - val_accuracy: 0.9778\n",
      "Epoch 956/1000\n",
      "105/105 [==============================] - 0s 122us/step - loss: 0.0412 - accuracy: 0.9714 - val_loss: 0.0853 - val_accuracy: 0.9778\n",
      "Epoch 957/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0404 - accuracy: 0.9714 - val_loss: 0.0843 - val_accuracy: 0.9778\n",
      "Epoch 958/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.0406 - accuracy: 0.9810 - val_loss: 0.0849 - val_accuracy: 0.9778\n",
      "Epoch 959/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.0412 - accuracy: 0.9714 - val_loss: 0.0874 - val_accuracy: 0.9778\n",
      "Epoch 960/1000\n",
      "105/105 [==============================] - 0s 109us/step - loss: 0.0404 - accuracy: 0.9714 - val_loss: 0.0858 - val_accuracy: 0.9778\n",
      "Epoch 961/1000\n",
      "105/105 [==============================] - 0s 118us/step - loss: 0.0404 - accuracy: 0.9714 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
      "Epoch 962/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0404 - accuracy: 0.9714 - val_loss: 0.0855 - val_accuracy: 0.9778\n",
      "Epoch 963/1000\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.0399 - accuracy: 0.9810 - val_loss: 0.0833 - val_accuracy: 0.9778\n",
      "Epoch 964/1000\n",
      "105/105 [==============================] - 0s 92us/step - loss: 0.0456 - accuracy: 0.9905 - val_loss: 0.0812 - val_accuracy: 0.9778\n",
      "Epoch 965/1000\n",
      "105/105 [==============================] - 0s 92us/step - loss: 0.0411 - accuracy: 0.9905 - val_loss: 0.0860 - val_accuracy: 0.9778\n",
      "Epoch 966/1000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.0425 - accuracy: 0.9714 - val_loss: 0.0926 - val_accuracy: 0.9778\n",
      "Epoch 967/1000\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.0415 - accuracy: 0.9810 - val_loss: 0.0931 - val_accuracy: 0.9778\n",
      "Epoch 968/1000\n",
      "105/105 [==============================] - 0s 120us/step - loss: 0.0410 - accuracy: 0.9810 - val_loss: 0.0908 - val_accuracy: 0.9778\n",
      "Epoch 969/1000\n",
      "105/105 [==============================] - 0s 139us/step - loss: 0.0404 - accuracy: 0.9714 - val_loss: 0.0863 - val_accuracy: 0.9778\n",
      "Epoch 970/1000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 0.0400 - accuracy: 0.9714 - val_loss: 0.0860 - val_accuracy: 0.9778\n",
      "Epoch 971/1000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 0.0400 - accuracy: 0.9714 - val_loss: 0.0862 - val_accuracy: 0.9778\n",
      "Epoch 972/1000\n",
      "105/105 [==============================] - 0s 98us/step - loss: 0.0399 - accuracy: 0.9714 - val_loss: 0.0872 - val_accuracy: 0.9778\n",
      "Epoch 973/1000\n",
      "105/105 [==============================] - 0s 104us/step - loss: 0.0399 - accuracy: 0.9810 - val_loss: 0.0897 - val_accuracy: 0.9778\n",
      "Epoch 974/1000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.0405 - accuracy: 0.9810 - val_loss: 0.0944 - val_accuracy: 0.9778\n",
      "Epoch 975/1000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.0432 - accuracy: 0.9810 - val_loss: 0.0991 - val_accuracy: 0.9778\n",
      "Epoch 976/1000\n",
      "105/105 [==============================] - 0s 112us/step - loss: 0.0443 - accuracy: 0.9810 - val_loss: 0.0934 - val_accuracy: 0.9778\n",
      "Epoch 977/1000\n",
      "105/105 [==============================] - 0s 88us/step - loss: 0.0412 - accuracy: 0.9810 - val_loss: 0.0916 - val_accuracy: 0.9778\n",
      "Epoch 978/1000\n",
      "105/105 [==============================] - 0s 121us/step - loss: 0.0416 - accuracy: 0.9810 - val_loss: 0.0890 - val_accuracy: 0.9778\n",
      "Epoch 979/1000\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.0407 - accuracy: 0.9810 - val_loss: 0.0908 - val_accuracy: 0.9778\n",
      "Epoch 980/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.0400 - accuracy: 0.9810 - val_loss: 0.0886 - val_accuracy: 0.9778\n",
      "Epoch 981/1000\n",
      "105/105 [==============================] - 0s 97us/step - loss: 0.0398 - accuracy: 0.9810 - val_loss: 0.0877 - val_accuracy: 0.9778\n",
      "Epoch 982/1000\n",
      "105/105 [==============================] - 0s 79us/step - loss: 0.0398 - accuracy: 0.9714 - val_loss: 0.0861 - val_accuracy: 0.9778\n",
      "Epoch 983/1000\n",
      "105/105 [==============================] - 0s 74us/step - loss: 0.0400 - accuracy: 0.9714 - val_loss: 0.0865 - val_accuracy: 0.9778\n",
      "Epoch 984/1000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.0400 - accuracy: 0.9810 - val_loss: 0.0859 - val_accuracy: 0.9778\n",
      "Epoch 985/1000\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.0401 - accuracy: 0.9714 - val_loss: 0.0873 - val_accuracy: 0.9778\n",
      "Epoch 986/1000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.0397 - accuracy: 0.9714 - val_loss: 0.0881 - val_accuracy: 0.9778\n",
      "Epoch 987/1000\n",
      "105/105 [==============================] - 0s 129us/step - loss: 0.0397 - accuracy: 0.9810 - val_loss: 0.0894 - val_accuracy: 0.9778\n",
      "Epoch 988/1000\n",
      "105/105 [==============================] - 0s 149us/step - loss: 0.0397 - accuracy: 0.9810 - val_loss: 0.0893 - val_accuracy: 0.9778\n",
      "Epoch 989/1000\n",
      "105/105 [==============================] - 0s 136us/step - loss: 0.0398 - accuracy: 0.9810 - val_loss: 0.0891 - val_accuracy: 0.9778\n",
      "Epoch 990/1000\n",
      "105/105 [==============================] - 0s 115us/step - loss: 0.0400 - accuracy: 0.9810 - val_loss: 0.0879 - val_accuracy: 0.9778\n",
      "Epoch 991/1000\n",
      "105/105 [==============================] - 0s 110us/step - loss: 0.0393 - accuracy: 0.9810 - val_loss: 0.0899 - val_accuracy: 0.9778\n",
      "Epoch 992/1000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.0407 - accuracy: 0.9810 - val_loss: 0.0935 - val_accuracy: 0.9778\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 131us/step - loss: 0.0404 - accuracy: 0.9810 - val_loss: 0.0931 - val_accuracy: 0.9778\n",
      "Epoch 994/1000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.0405 - accuracy: 0.9810 - val_loss: 0.0914 - val_accuracy: 0.9778\n",
      "Epoch 995/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.0398 - accuracy: 0.9810 - val_loss: 0.0905 - val_accuracy: 0.9778\n",
      "Epoch 996/1000\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.0398 - accuracy: 0.9810 - val_loss: 0.0885 - val_accuracy: 0.9778\n",
      "Epoch 997/1000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.0391 - accuracy: 0.9810 - val_loss: 0.0867 - val_accuracy: 0.9778\n",
      "Epoch 998/1000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.0392 - accuracy: 0.9714 - val_loss: 0.0848 - val_accuracy: 0.9778\n",
      "Epoch 999/1000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.0398 - accuracy: 0.9810 - val_loss: 0.0843 - val_accuracy: 0.9778\n",
      "Epoch 1000/1000\n",
      "105/105 [==============================] - 0s 113us/step - loss: 0.0408 - accuracy: 0.9905 - val_loss: 0.0832 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x142b5c9e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(X_train, y_train, epochs = 1000, # quantidade de épocas utilizadas para aprender\n",
    "           validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerar predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.8% de acertos.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "previsoes = modelo.predict(X_test)\n",
    "previsoes = [np.argmax(t) for t in previsoes]\n",
    "\n",
    "y_test_cm = [np.argmax(t) for t in y_test]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "confusao = confusion_matrix(y_test_cm, previsoes)\n",
    "tx_acerto = accuracy_score(y_test_cm, previsoes)\n",
    "distinct = np.unique(y_test_cm)\n",
    "\n",
    "print('%.1f%% de acertos.' % (tx_acerto * 100))\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df_cm = pd.DataFrame(confusao, index = distinct, columns = distinct)\n",
    "\n",
    "ax = sns.heatmap(df_cm, annot = True, linewidths = 0.5, cmap = 'BuPu', fmt='g')\n",
    "ax.set(xlabel='Predict class', ylabel='Original class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar a base e declarar variáveis para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exibir imagem de um registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[10])\n",
    "plt.title(y_train[10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformar colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(len(X_train), np.prod(X_train.shape[1:]))\n",
    "X_test = X_test.reshape(len(X_test), np.prod(X_test.shape[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizar dados transformando o RGB em um float até 1 para otimizar o processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpor classes para resultar em booleano binário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definir quantidade de neurônios nas camadas ocultas, na de entrada e na de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "modelo.add(Dense(units = 64,\n",
    "                 activation = 'relu', # impede valores negativos subtituindo por zero\n",
    "                 input_dim = np.shape(X_train)[1]))\n",
    "modelo.add(Dropout(0.2)) # zerar uma porcentagem x dos neurônios durante o treinamento\n",
    "modelo.add(Dense(units = 64,\n",
    "                 activation = 'relu'))\n",
    "modelo.add(Dropout(0.2))\n",
    "modelo.add(Dense(units = 64,\n",
    "                 activation = 'relu'))\n",
    "modelo.add(Dropout(0.2))\n",
    "modelo.add(Dense(units = 10,\n",
    "                 activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 59,210\n",
      "Trainable params: 59,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.4575 - accuracy: 0.8599 - val_loss: 0.1639 - val_accuracy: 0.9489s - loss: 0.4643 - accuracy\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2319 - accuracy: 0.9338 - val_loss: 0.1456 - val_accuracy: 0.9568\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1930 - accuracy: 0.9438 - val_loss: 0.1213 - val_accuracy: 0.9635\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1648 - accuracy: 0.9516 - val_loss: 0.1119 - val_accuracy: 0.9654\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1511 - accuracy: 0.9560 - val_loss: 0.1074 - val_accuracy: 0.9656\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1386 - accuracy: 0.9593 - val_loss: 0.0908 - val_accuracy: 0.9728\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1311 - accuracy: 0.9614 - val_loss: 0.0938 - val_accuracy: 0.9704\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1233 - accuracy: 0.9636 - val_loss: 0.0909 - val_accuracy: 0.9739\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1189 - accuracy: 0.9641 - val_loss: 0.0931 - val_accuracy: 0.9711\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1123 - accuracy: 0.9663 - val_loss: 0.0878 - val_accuracy: 0.9739\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1081 - accuracy: 0.9670 - val_loss: 0.0844 - val_accuracy: 0.9739\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1043 - accuracy: 0.9691 - val_loss: 0.0835 - val_accuracy: 0.9747\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1011 - accuracy: 0.9704 - val_loss: 0.0886 - val_accuracy: 0.9727\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0975 - accuracy: 0.9709 - val_loss: 0.0873 - val_accuracy: 0.9742\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0992 - accuracy: 0.9703 - val_loss: 0.0799 - val_accuracy: 0.9757\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0934 - accuracy: 0.9719 - val_loss: 0.0877 - val_accuracy: 0.9740\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0936 - accuracy: 0.9719 - val_loss: 0.0811 - val_accuracy: 0.9769\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0901 - accuracy: 0.9723 - val_loss: 0.0818 - val_accuracy: 0.9775\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0859 - accuracy: 0.9736 - val_loss: 0.0847 - val_accuracy: 0.9776\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0882 - accuracy: 0.9733 - val_loss: 0.0879 - val_accuracy: 0.9753\n"
     ]
    }
   ],
   "source": [
    "historico = modelo.fit(X_train, y_train, epochs = 20,\n",
    "                       validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotar evolução da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8FXW+//HXJxUCoSWhd0SaIGBoNhQb2FBxd8ECuq4ua1n3+nOte717uddr3XXdXddVBBXFvquCBQuiqEgJJRA6hB5CEgIhBEj9/v44Ez3GhBzSTpLzfj4eeWTKd2Y+MzmZz5nvfGe+5pxDREQkLNgBiIhI/aCEICIigBKCiIh4lBBERARQQhAREY8SgoiIAEoIIrXCzP5pZo8FWPYBM3uhtmMSqYzpOQQJFWb2JXAq0N45l1+L2zkb+G/gfOdccW1tR6Sm6QpBQoKZdQfOAhxweS2sP8JvtBswSclAGholBAkVk4HFwEvAlNKJZtbUzP5kZjvMLMfMvvGmnWNmu/1XYGbbzex8b/iPZvaOmb1qZoeAG8xsuJl9B/wNWGlmfzezKL/lB5jZZ2aWbWb7zOwBv3W96lfubTNL9+JZaGYDavG4iHxPCUFCxWRgtvdzkZm186Y/CZwGnA60Ae4BSgJc53jgHaCVt94S4C4gHhgFnAfcCmBmscDnwDygI3ASML+C9X4M9AbaAiu8dYvUuojKi4g0bGZ2Jr5qnLecc1lmthW4xsyeBn4JjHTO7fGKL/KWCWTV3znn3vOGjwJJfvO2m9lzwGjgL8ClQLpz7k/e/GPAkvJW6pyb6Rf7H4EDZtbSOZcTSFAiVaUrBAkFU4BPnXNZ3vhr3rR4oAmwtYrr3eU/YmY9vWqkVDPbCfzB2wZAl0C2Y2bhZvaomW31qqK2e7Pij7OYSI1QQpBGzcyaAj8HRnv18unAf+BrbdQB3zf1XuUsmgfE+K0nHEgoU6ZsE73ngM1AP+dcV+BhoPRSY1cF2ynrGnxVUecDLYHupSEEsKxItSghSGN3BVAM9AcGez/9gK/x3VeYCfzZzDp6385HmVk0sAloYmaXmFkkvm/70ZVsqxWQDxSYWV9gqt+8D4D2ZvY7M4s2s1gzG1HOOmK9dezHl5D+r2q7LXLilBCksZsCvOic2+mcSy/9Af4OXAvcB6wBlgHZwGNAmFdffyvwArAH3xXD7vI24Of/AROBXGA68GbpDOdcLnABcBmQju9K4txy1jEL2OFtcx2+llEidUIPpomICKArBBER8SghiIgIoIQgIiIeJQQREQEa2JPK8fHxrnv37sEOQ0SkQVm+fHmWc67sczQ/0aASQvfu3UlKSqq8oIiIfM/MdgRSTlVGIiICKCGIiIhHCUFERAAlBBER8SghiIgIoIQgIiIeJQQREQEa2HMIIiL1gXOOo4XFHCko5miB7/eRgqIfhguLOVpQ5E0vpnl0BJOGdyUqon5/B1dCEBEpR3rOMRZtzWLR1v2k7MnhcP4PJ/yjhcUnvL5vtmTxzDVD63VSUEIQEQH2H85ncWo2i7Zm8d3W/aRm5QHQKiaSoV1b07JpJE2jwomJDCcmKpymURHeb994TFQ4TSMjfhiOCifGK/NW0i4een8tv3l1Of+4bijREeFB3tvyKSGISEjKPVbI0m3ZLNq6n2+3ZLEhPReAZlHhjOgZxzUjujKqVxz92rcgLKx6XVpPHtWdMDP+8F4KU19ZzrPXnUaTyPqXFJQQRCQkHC0oZvmOA99XA63Zk0NxiSM6IozE7q35/UV9GNUrjoGdWhIZXvPVOteN7EaYGQ+8u4Zfv7Kc566vf0lBCUFEGrV1aYeY9sFaVuw4SEFxCRFhxuAurbjtnF6M6hXPkK6t6uzEfM2IroSHwX3/XsPNs5KYPjmxXiUFJQQRabSyDufzq5eXUVDsuOGM7ozqFcew7m1oHh28U98vhnUlzIx7/rWam15exguTh9E0qn4kBSUEEWmUCotLuG32CvbnFfCv35zOKZ1aBjuk7/0ssQthZtz9TjK/fGkZM25IJCYq+Kfj+tv+SUSkGh7+cD1LtmXz6ISB9SoZlJpwWmee+vlglmzbz40vLiMvvyjYISkhiEjj83bSLl5atJ2bzuzBlUM6BzucCl0xpBNP/WIwy7Znc+OLyzgc5KSghCAijUryroM8+F4Kp/eK4/5xfYMdTqXGD+7EXycNYfnOA9wwcym5xwqDFosSgog0Gpm5+Ux9dTkJzaP5+zVDiaiF5qO14dJBHfnbpCGs2nWQKTOXcihISaFhHC0RkUoUFPluIh84UsDzk0+jTbOoYId0Qi4e2IG/XzOU1btzmDwjOElBCUFEatW+Q8eYl7KXkhJXq9v53w/XsXR7No9NGMSAjvXvJnIgxp7Snn9cO5S1aTlc/8ISco7WbVJQQhCRWlFS4nhtyU7O/9NXTH11BVNeXEpG7rFa2dZbSbuY9d0Objm7J+MHd6qVbdSVCwe059lrT2Pd3kNcP2MJOUfqLikoIYhIjduWlcek6Yt54N01nNKpJQ9c3Jel27K5+Omv+WpTZo1ua+XOA/zh3RTOPCmeey7qU6PrDpbz+7fjuetPY8PeXK6dsZiDRwrqZLsBJQQzG2tmG81si5ndV878bmY238xWm9mXZtbZm36uma3y+zlmZld4814ys21+8wbX7K6JSF0rKi7h2S+3MvYvC1m39xCPTRjIazeP4JazezH3jjNp0yyKKTOX8shH6ykoKqn29jJyjzH11eW0axnN3yYNaTA3kQMxpm87npt8Gpv2Heaa6Us4kFf7SaHSo2dm4cAzwDigPzDJzPqXKfYkMMs5NwiYBjwC4Jxb4Jwb7JwbDIwBjgCf+i33+9L5zrlV1d8dEQmWlD05jH/mWx6bt4Fz+7Rl/l2j+cWwrpj53hR6crtY5tx+JteO6MpzC1P52T8XsXP/kSpvr6CohFtfXcGho0U8d10irRvYTeRAnNunLdMnJ5KbX8jBOrifEEg6HQ5scc6lOucKgDeA8WXK9Afme8MLypkPcDXwsXOu6p8AEal3jhUW8+jHGxj/zLdk5Obz7LVD+ef1p9G2RZOflG0SGc7DVw7k2WuHsi0rj4v/+jXvr9pTpe1O+2AtSTsO8MTPBtG/Y4vq7ka9NfrkBObfdQ494pvV+rYCSQidgF1+47u9af6SgQne8JVArJnFlSkzEXi9zLSHvWqmp8wsuryNm9ktZpZkZkmZmTVb9ygi1bM4dT/jnv6af361lQlDO/H5f4xm3MAOlS43bmAHPrrzLPq0j+XON1bx+7eTOVIQ+FO6byzdyauLd/Lr0T25dFDH6uxCg1BXvawFspXyeoYo237sbmC0ma0ERgN7gO//umbWARgIfOK3zP1AX2AY0Aa4t7yNO+eed84lOucSExISAghXpPE4VljMvJS9vJW0i+JabrZ5Ig4dK+SBd9cw8fnFFJc4Zv9qBI9ffSotYyIDXkfn1jG8ectIbj/3JN5ZsZtL//YNa9NyKl1uxc4DPPT+Ws7qHc89F9X/J5EbkkBer7cb6OI33hlI8y/gnEsDrgIws+bABOec/1/258C7zrlCv2X2eoP5ZvYivqQiEvIKi0v4ZksWc1el8em6fd+/3+bTtfv466TBQX8r5mfr9vGH99aQmZvPzWf14K4L+lT59c0R4WHcfVEfTu8Vx+/eXMWVzyziwUv6MXlUt+/vPfjLOHSMqa8sp33LJvxt0hDCq9mTmfxYIJ+sZUBvM+uB75v/ROAa/wJmFg9kO+dK8H3zn1lmHZO86f7LdHDO7TXfX/0KIKVquyDS8BWXOJZs28/c5L18nLKXg0cKadEkgksGduCyUzuyJSOXaR+s4+fPfceMKcNoV079fG3LzM3nj3PX8uHqvfRtH8vz1ydyapdWNbLu00+K5+M7z+Lut5P5rzlr+WZLFo9PGPSjG8X5RcVMfXU5h/OLmHXTcFrFNL6byMFmzlV+GWpmFwN/AcKBmc65h81sGpDknJtjZlfja1nkgIXAbc65fG/Z7sC3QBcvYZSu8wsgAV+V1CpgqnPu8PHiSExMdElJSSe8kyL1kXOOFTsPMjc5jQ/X7CUzN5+YqHAu6N+OywZ15KyT43/UGfv89fu44/WVtGoaycwbh9G3fd3cSHXO8a8Ve/ifD9ZxtKCY3553Er8e3atWupl0zjHjm208Nm8D8c2j+csvBjOip+925P3/XsPrS3fyj2uHcnEA9ynkB2a23DmXWGm5QBJCfaGEIA2dc461aYeYuzqND5L3sufgUaIiwhjTpy2XndqRMX3bHrf6JWVPDje9vIy8/GKeuXYoo0+u3ftqu7KP8MC7a/h6cxaJ3Vrz6IRBnNS2ea1uE2DN7hzueH0FO7OP8NvzehPXPJr/fC+FW8/pxT1jdd/gRCkhSKPinCu3TrmuFBaXUJ1/lR3785i7ei8fJKeRmpVHRJhxVu94Lju1Ixf0b0dsk8Bvxu7NOcovX0pi075cpo0fwLUjulU9sAoUlzheWrSdJz/ZSJjBveP6ct2IboTVYZ394fwiHnovhX+v9DVLPadPAjOmDNN9gypQQpBG47F5G/h83T5ev2Uk8c3LbZ1cqx75aD3PLUyt9nrMYFTPOC47tSNjB7Sv1oNUh/OLuOO1FSzYmMktZ/fkvrF9a+xkvTE9l3v/tZpVuw5ybp8E/vfKgXRq1bRG1l0V767czefrMvi/KweeUCsm+YESgjQK323dz6TpiwFI7Naa2TeP+FG9em17dfEO/vBeCpcM6kD/DlWvs2/ZNJIL+7cr92GtqioqLuG/567jlcU7GHdKe/7888HV6qw9v6iYfyzYyj++3EJsk0j+67L+XH5qx6BemUnNCDQhBL9XZ5EKHCko4p5/JdMtLoY7xvTm7reTefDdFJ64elCdnKQWbcniv+as5dw+Cfx1Yv1r4hgRHsa08QPoHt+M//1wHWnTF/PC5EQSYk/8KmrFzgPc+85qNmcc5orBHfnPS/sTF4SrMQkuJQSptx6ft5HdB47y5i2jGN6jDbuyj/D0/M2c3K45t5zdq1a3vT0rj9/MXkHP+Gb8tR63dzczbjqzB51bN+XON1ZyxTPf8tKNw+jdLjag5fPyi3jik428/N12OrRowos3DOPcvm1rN2iptxrPqwGlUVmcup+XFm1nyqjuDO/RBoA7z+vNJQM78MjHG5i/fl+tbTvnaCE3vbyMMIMZU4ad0A3fYLloQHve+vUoCopLuOrZRXy7JavSZb7alMmFTy3k5e+2c/3Ibnx612glgxCnhCD1zpGCIu7912q6tonhnrE/vN8+LMx48menMqBjC377+ko2pufW+LaLiku44/WV7Nh/hGevO42ucTE1vo3aMqhzK9699XQ6tmzKlJlLeWvZrnLLHcgr4K43VzFl5lKaRIbx9q9HMW38KTSPVoVBqFNCkHrniU82smP/ER6/etBPXtPQNCqc6ZMTaRYdwa9mLSO7ht8R/38fbWDhpkz+54pTGNmz7PsZ67/OrWN4+zejGNUrjnv+tZrH5234vutK5xxzk9M4/89fMSc5jTvGnMSHvz2LxO5tghy11BdKCFKptINHWbotu062tXRbtldV1K3CE3KHlk15fnIiGYfymfrq8hrpaAV8b9Cc+e02bjyjO5OGd62RdQZDiyaRzLxhGJOGd+EfX27lt2+sZHtWHjfPSuKO11fSuXVT5t5xJv/vwj40iay7FltS/6nZqVTqhheX8uXGTB6fMIifD+tS+QJVdLSgmHFPL6TYOebdeTbNKqnCeH/VHu58YxUTh3XhkasGVqvl0ZLU/Vw3YwmjesUzc0pio+h5yznH8wtTeeTjDQA0iQzj7gv7cOMZPertTXKpHWp2KjUi52gh327JIiYqnHv/vZroyLBa68T8yU83sn3/EV6/eWSlyQBg/OBObN53mL8v2ELvdrHcdGaPKm135/4jTH11OV3axDSqbhjNjF+P7kW3uGZ8ujad351/coO6JyJ1TwlBjuuLDfsoLHa8/MtE/jp/M3e9lUxkeFiNv1xs2fZsZn67jcmjujGqV+B193ddcDKbM3J5+MN19Epoxjl9TqyVTO6xQn41axklzteiqGXT+t+i6ESNPaU9Y09pH+wwpAFoHF+FpNZ8vCad9i2aMLJHHDOmDGNIl1b89vWVfL6u5pp9Hi0o5p53VtOpVVPuPcEXl4WFGU/9YjB92rfgjtdWsiUj8JZHxSWOO99YxdbMPJ69dmiddFEoUp8pIUiF8vKL+GpTJmNPaU9YmNEsOoIXbxzGgE4tuXX2Cr7aVDNdmv7p041sy8rj8QmDAqoqKismKoIXpiQSHRnOTS8ncSDAlkePzdvAFxsy+OPlAzj9pPgT3q5IY6OEIBX6cmMm+UUlP6puiG0Syawbh3NS2+bcMiuJRVsrfwDqeJbvyGbGt9u4bmTXap2UO7VqynPXn8beg8e4dfYKCouP3/Lo7aRdPL8wlcmjunH9yJp/W6hIQ6SEIBWatzaduGZRDCvTTr1lTCSv/moE3eJiuOmlJJZtr1qT1GOFxfz+7dV0bNmU+8b1q3a8p3VrzaMTBvJd6n7+OGctFbWgS9qezYPvpnDGSXH856X9q71dkcZCCUHKdaywmC/W7+PCAe3KbaLYplkUs381kg6tmnDji8tYtevgCW/jz59tIjUrj8evHlRjT8leNbQzU0f3YvaSncz6bsdP5u/KPsKvX1lOp9ZN+cc1p9VKr18iDZX+G6Rc32zOIq+gmLGnVNyaKCE2mtd+NZI2zaKYPGMJKXtyAl7/8h0HeOHrVK4Z0ZUzarj+/p6L+nB+v3ZM+2AdX2/+4T5HXn4RN89KoqC4hOmTE/VufZEylBCkXPPWphPbJIJRlby+oX3LJrx28whim0Ry/YwlAb1f6FhhMb9/J5kOLZty/7ia7w4xLMz4y8TB9G7bnNtmryA18zAlJY7fvbmKzRmHeeaaoXXSDaRIQ6OEID9RWFzCZ+v2cUG/dkRFVP4R6dw6hte8jmuufWExWzIOH7f8U59vIjUzj0cnDKy1N4k2j45g+uREIsPDuOnlJKZ9sI7P1u3jPy/px9m13A+xSEOlhCA/sTh1PzlHC0/oYaZucc2YffMIwLj2hcXs2J9XbrkVOw8wfWEqk4Z34azetXti7tImhn9efxq7DxzhpUXbmTS8K1NO716r2xRpyJQQ5CfmpaQTExV+wt+keyU057WbR1BY7Lhm+hJ2Hzjyo/m+VkXJtG/RhAcurn6rokAM696Gv04cwnUjuzJt/AB1BylyHEoI8iPFJY5P1u7j3D5tq/QmzJPbxfLKTcPJPVbINdOXsDfn6Pfz/vL5ZrZm5vHohEF12unMuIEd+N8rBqpFkUgl9B8iP7J8xwGyDudX6903Azq25JWbRpCdV8C105eQkXuMVbsO8vzCrUwc1kV1+CL1lF5uJz/yccpeoiLCqt2V4qldWvHSjcOYPHMp105fggPatWjCA5fUTVWRiJy4gK4QzGysmW00sy1mdl8587uZ2XwzW21mX5pZZ2/6uWa2yu/nmJld4c3rYWZLzGyzmb1pZlE1u2tyopxzfJKSztm942vkQbHE7m2YMWUYO7OPsCXjMI9cNZAWDaB/YpFQVWlCMLNw4BlgHNAfmGRmZZ/3fxKY5ZwbBEwDHgFwzi1wzg12zg0GxgBHgE+9ZR4DnnLO9QYOADfVwP5INazenUNazrHjPox2okb1iuO1m0fwxNWDTvjV1CJStwK5QhgObHHOpTrnCoA3gPFlyvQH5nvDC8qZD3A18LFz7oj5mnqMAd7x5r0MXHGiwUvN+jglnYgw4/x+NXviPq1bG36WWHs9rYlIzQgkIXQCdvmN7/am+UsGJnjDVwKxZlb2EdeJwOvecBxw0DlXdJx1Sh1yzjEvZS+jesXRKka1dyKhKJCEUF7D7bKvkbwbGG1mK4HRwB6g9GSPmXUABgKfnMA6S5e9xcySzCwpM7Nm3r8vP7VxXy7b9x9Rz1oiISyQhLAb8L/e7wyk+RdwzqU5565yzg0BHvSm+b/p7OfAu865Qm88C2hlZqV3Ln+yTr91P++cS3TOJSYkqLlibfl4TTpmcGF/JQSRUBVIQlgG9PZaBUXhq/qZ41/AzOLNrHRd9wMzy6xjEj9UF+F8L6pfgO++AsAU4P0TD19qyidr0xnWrQ0JsdHBDkVEgqTShODV89+Or7pnPfCWc26tmU0zs8u9YucAG81sE9AOeLh0eTPrju8K46syq74XuMvMtuC7pzCjWnsiVbYtK48N6bmqLhIJcQE1NnfOfQR8VGbaQ37D7/BDi6Gyy26nnBvGzrlUfC2YJMg+TtkLoIQgEuL06gphXko6p3ZpRcdWTYMdiogEkRJCiNtz8Cird+cwdoCuDkRCnRJCiJuXkg7AOFUXiYQ8JYQQNy9lL33bx9I9vlmwQxGRIFNCCGEZucdI2nFAN5NFBFBCCGmfrt2HczCuBl9mJyINlxJCCJuXkk7P+Gac3K55sEMRkXpACSFEHTxSwHep+xl7Snv1MywigBJCyPps3T6KS5zuH4jI95QQQtS8lHQ6tWrKwE4tgx2KiNQTSgghKPdYIV9vzlJ1kYj8iBJCCFqwMZOC4hJVF4nIjyghhKB5KXtJiI3mtK6tgx2KiNQjSggh5mhBMQs2ZHLRgHaEham6SER+oIQQYhZuzuRoYTFjB+hhNBH5MSWEEDMvJZ1WMZGM6Nkm2KGISD2jhBBCCopK+Hz9Pi7o147IcP3pReTHdFYIIYu2ZpF7rIhxA9W6SER+SgkhhMxLSad5dARnnBQf7FBEpB5SQggRRcUlfLpuH2P6tiU6IjzY4YhIPaSEECKWbs8mO69APaOJSIWUEELEJynpNIkMY3SfhGCHIiL1lBJCCCgpccxbm87okxOIiYoIdjgiUk8pIYSAlbsOsu9QvnpGE5Hj0tfFBu5YYTFZh/PZf7iA7LwC33BeAfu9aVl5BWzNOExkuHFu37bBDldE6jElhAYgeddBPl2X7jvBHy5gf57vZL//cD55BcXlLtMkMoz45tHENY+mb/tYbjm7Jy2bRtZx5CLSkASUEMxsLPA0EA684Jx7tMz8bsBMIAHIBq5zzu325nUFXgC6AA642Dm33cxeAkYDOd5qbnDOrar2HjUyry/dyUPvp1DioE2zKOKaRRHfPJquXWOIaxZNXPMo4ptH+Q37futegYicqErPGmYWDjwDXADsBpaZ2Rzn3Dq/Yk8Cs5xzL5vZGOAR4Hpv3izgYefcZ2bWHCjxW+73zrl3amJHGpvC4hL+54N1zPpuB2efnMDfJg6hZYy+4YtI7Qnka+RwYItzLhXAzN4AxgP+CaE/8B/e8ALgPa9sfyDCOfcZgHPucA3F3ahl5xVw2+wVfJe6n5vP6sF94/oRrldVi0gtC6SVUSdgl9/4bm+av2Rggjd8JRBrZnHAycBBM/u3ma00sye8K45SD5vZajN7ysyiy9u4md1iZklmlpSZmRnQTjVkG9IPMf6Zb1i+8wB/+tmpPHhJfyUDEakTgSSE8s5Grsz43cBoM1uJ777AHqAI3xXIWd78YUBP4AZvmfuBvt70NsC95W3cOfe8cy7ROZeYkNC4H6qal5LOVf9YRH5hCW/9ehQTTusc7JBEJIQEkhB247shXKozkOZfwDmX5py7yjk3BHjQm5bjLbvSOZfqnCvCV5U01Ju/1/nkAy/iq5oKSSUljqc/38zUV5fTu10sc+84k8FdWgU7LBEJMYEkhGVAbzPrYWZRwERgjn8BM4s3s9J13Y+vxVHpsq3NrPSr/Ri8ew9m1sH7bcAVQEp1dqShyssv4rbXVvDU55u4amgn3rxlJO1aNAl2WCISgiq9qeycKzKz24FP8DU7nemcW2tm04Ak59wc4BzgETNzwELgNm/ZYjO7G5jvnfiXA9O9Vc/2EoUBq4CpNbtr9d+u7CPcPCuJTfty+cMl/bjpzB74DpOISN0z58reDqi/EhMTXVJSUrDDqBGLU/dz6+wVFBaX8PdrhjL65MZ9f0REgsfMljvnEisrp6eXguCVxTv47zlr6RoXwwuTE+mZ0DzYIYmIKCHUpYKiEv577lpmL9nJuX0SeHrSEFo00cNmIlI/KCHUkf2H8/nN7BUs3ZbN1NG9+P1FffR8gYjUK0oIdWBjei6/fGkZWYfzeXriYMYPLvtcn4hI8Ckh1IE/vLeG/KIS3p46ikGd9XyBiNRP6iCnlu05eJRl2w9w4xndlQxEpF5TQqhlc5N9D3VfNqhjkCMRETk+JYRaNmdVGoO7tKJrXEywQxEROS4lhFq0JeMw6/Ye4rJTdXUgIvWfEkItmpOchhlcOkid24tI/aeEUEucc3yQnMbIHnF6WZ2INAhKCLVkbdohUrPyuHywqotEpGFQQqglc5LTiAw3xp3SPtihiIgERAmhFpSUOOYmp3F27wRaxUQFOxwRkYAoIdSCpB0H2JtzTNVFItKgKCHUgjnJe2gSGcb5/doFOxQRkYApIdSwwuISPlqTznn92tEsWq+KEpGGQwmhhi3aup/svAIu18NoItLAKCHUsDmr0ohtEsE5fdQlpog0LEoINehYYTGfrk1n7ID2REeEBzscEZETooRQg77cmEFufpFaF4lIg6SEUIPmJKcR3zyKUT3jgh2KiMgJU0KoIbnHCpm/PoOLB3YgIlyHVUQaHp25ashn6/aRX1Si1kUi0mApIdSQuclpdGrVlKFdWwc7FBGRKgkoIZjZWDPbaGZbzOy+cuZ3M7P5ZrbazL40s85+87qa2admtt7M1plZd296DzNbYmabzexNM2uwL/05kFfA15uzuPTUDoSFWbDDERGpkkoTgpmFA88A44D+wCQz61+m2JPALOfcIGAa8IjfvFnAE865fsBwIMOb/hjwlHOuN3AAuKk6OxJMH6XspajEqbpIRBq0QK4QhgNbnHOpzrkC4A1gfJky/YH53vCC0vle4ohwzn0G4Jw77Jw7YmYGjAHe8ZZ5GbiiWnsSRHNWpdEroRn9O7QIdigiIlUWSELoBOzyG9/tTfOXDEzwhq8EYs0sDjgZOGhm/zazlWb2hHfFEQccdM4VHWedAJjZLWaWZGZJmZmZge1VHUrPOcbS7dlcdmpHfHlORKRhCiQhlHc/1v/7AAAOvUlEQVSWc2XG7wZGm9lKYDSwBygCIoCzvPnDgJ7ADQGu0zfRueedc4nOucSEhPr3OogPVqfhHKouEpEGL5CEsBvo4jfeGUjzL+CcS3POXeWcGwI86E3L8ZZd6VU3FQHvAUOBLKCVmUVUtM6GYk5yGqd0akHPhObBDkVEpFoCSQjLgN5eq6AoYCIwx7+AmcWbWem67gdm+i3b2sxKv9qPAdY55xy+ew1Xe9OnAO9XfTeCY3tWHqt35+jqQEQahUoTgvfN/nbgE2A98JZzbq2ZTTOzy71i5wAbzWwT0A542Fu2GF910XwzW4Ovqmi6t8y9wF1mtgXfPYUZNbZXdWRusu+i5tJBSggi0vCZ78t6w5CYmOiSkpKCHQYAzjkufGohrWOieGvqqGCHIyJSITNb7pxLrKycnlSuog3puWzOOMxlerOpiDQSSghVNCc5jfAw4+JT2gc7FBGRGqGEUAXOOeYmp3HGSfHENY8OdjgiIjVCCaEKVuw8yO4DR9W6SEQaFSWEKpibnEZURBgXDWgX7FBERGqMEsIJKi5xfLhmL2P6tCW2SWSwwxERqTFKCCdocep+MnPz1W+yiDQ6SggnaM6qNJpFhTOmb9tghyIiUqOUEE5AflExH6fs5cIB7WkSGR7scEREapQSwglYuCmLQ8eK1LpIRBolJYQTMCc5jdYxkZzZOz7YoYiI1DglhAAdKSji83X7GDewA5HhOmwi0vjozBagz9dncLSwWNVFItJoKSEEaM6qNNq3aMLw7m2CHYqISK1QQghAzpFCvtqUwaWDOhAWpn6TRaRxUkIIwLy1eyksdlym6iIRacSUEALw4Zp0usXFMKhzy2CHIiJSa5QQKpGXX8Tirfu5oF87zFRdJCKNlxJCJb7dkkVBcYleVSEijZ4SQiW+2JBBbHQEiWpdJCKNnBLCcTjnWLAxg7NOjicqQodKRBo3neWOY23aIfYdyufcPqouEpHGTwnhOL7YkIEZnKOEICIhQAnhOL7YkMGgzq1IiI0OdigiIrVOCaECWYfzSd59kDG6OhCREKGEUIEvN2biHJzXTwlBREJDQAnBzMaa2UYz22Jm95Uzv5uZzTez1Wb2pZl19ptXbGarvJ85ftNfMrNtfvMG18wu1YwFGzJoGxvNgI4tgh2KiEidiKisgJmFA88AFwC7gWVmNsc5t86v2JPALOfcy2Y2BngEuN6bd9Q5V9HJ/vfOuXeqHn7tKCwuYeGmTC4Z1EFPJ4tIyAjkCmE4sMU5l+qcKwDeAMaXKdMfmO8NLyhnfoOybHs2uflFnKunk0UkhASSEDoBu/zGd3vT/CUDE7zhK4FYM4vzxpuYWZKZLTazK8os97BXzfSUmZXblMfMbvGWT8rMzAwg3OpbsCGDqPAwzjxJXWWKSOgIJCGUV2fiyozfDYw2s5XAaGAPUOTN6+qcSwSuAf5iZr286fcDfYFhQBvg3vI27px73jmX6JxLTEhICCDc6pu/IYMRPdvQLLrSGjURkUYjkISwG+jiN94ZSPMv4JxLc85d5ZwbAjzoTcspnef9TgW+BIZ443udTz7wIr6qqaDbsT+P1Mw8vcxOREJOIAlhGdDbzHqYWRQwEZjjX8DM4s2sdF33AzO96a1Lq4LMLB44A1jnjXfwfhtwBZBS/d2pvi82ZAAoIYhIyKm0TsQ5V2RmtwOfAOHATOfcWjObBiQ55+YA5wCPmJkDFgK3eYv3A54zsxJ8yedRv9ZJs80sAV+V1Cpgag3uV5V9sSGDXgnN6BbXLNihiIjUqYAqyZ1zHwEflZn2kN/wO8BPmo865xYBAytY55gTirQO5OUXsSQ1mymndwt2KCIidU5PKvv55vvOcNoFOxQRkTqnhODni/UZxDaJILF762CHIiJS55QQPCUlvs5wzu6dQGS4DouIhB6d+Txr0w6RkZuv1kUiErKUEDw/dIZTNw+/iYjUN0oIni82ZnBq51bENVdnOCISmpQQgMzcfJJ3HeQ8VReJSAhTQgC+3Oh7OllvNxWRUKaEACzYmEG7FuoMR0RCW8gnhIKiEhZuymJM37bqDEdEQlrIJ4Sk7dkczi/i3D6qLhKR0BbyCeGLDRlERYRxhjrDEZEQp4SwIYORPePUGY6IhLyQTgjbs/JIzcpjjB5GExEJ7YTwQ2c4erupiEjIJ4ST2jana1xMsEMREQm6kE0Ih/OLWLJtv55OFhHxhGxC+GZzJoXFTk8ni4h4QjYhfLHB1xnOad3UGY6ICIRoQvB1hpPJ6JPVGY6ISKmQPBumpOWQqc5wRER+JCQTQmlnOKNP1vMHIiKlQjIhLNiQwZAu6gxHRMRfyCWEjNxjJO/OUXWRiEgZIZcQvtyYCejpZBGRsgJKCGY21sw2mtkWM7uvnPndzGy+ma02sy/NrLPfvGIzW+X9zPGb3sPMlpjZZjN708yiamaXjm/Bhgw6tGxCvw6xdbE5EZEGo9KEYGbhwDPAOKA/MMnM+pcp9iQwyzk3CJgGPOI376hzbrD3c7nf9MeAp5xzvYEDwE3V2I+AFBSV8PXmLM7po85wRETKCuQKYTiwxTmX6pwrAN4Axpcp0x+Y7w0vKGf+j5jvbDwGeMeb9DJwRaBBV9UyrzMcva5CROSnAkkInYBdfuO7vWn+koEJ3vCVQKyZxXnjTcwsycwWm1npST8OOOicKzrOOgEws1u85ZMyMzMDCLdi89f7OsM5/aS4yguLiISYQBJCeXUrrsz43cBoM1sJjAb2AKUn+67OuUTgGuAvZtYrwHX6Jjr3vHMu0TmXmJBQvecGFmzMYFTPOGKi1BmOiEhZgSSE3UAXv/HOQJp/AedcmnPuKufcEOBBb1pO6TzvdyrwJTAEyAJamVlEReusaamZh9mWlcd5/VRdJCJSnkASwjKgt9cqKAqYCMzxL2Bm8WZWuq77gZne9NZmFl1aBjgDWOecc/juNVztLTMFeL+6O3M8pZ3hnNtHCUFEpDyVJgSvnv924BNgPfCWc26tmU0zs9JWQ+cAG81sE9AOeNib3g9IMrNkfAngUefcOm/evcBdZrYF3z2FGTW0T+VasDGD3m2b06WNOsMRESlPQJXpzrmPgI/KTHvIb/gdfmgx5F9mETCwgnWm4mvBVOtyjxWydFs2vzyzR11sTkSkQQqJJ5W/2ZxFYbFjjKqLREQqFBIJ4YsNGbRQZzgiIscVEgmhR0Izrh3ZjQh1hiMiUqGQaJB/6zknBTsEEZF6T1+ZRUQEUEIQERGPEoKIiABKCCIi4lFCEBERQAlBREQ8SggiIgIoIYiIiMd8b6JuGMwsE9hRxcXj8fXDUF8pvupRfNWj+KqnvsfXzTlXaQ9jDSohVIeZJXk9t9VLiq96FF/1KL7qqe/xBUpVRiIiAighiIiIJ5QSwvPBDqASiq96FF/1KL7qqe/xBSRk7iGIiMjxhdIVgoiIHIcSgoiIAI0wIZjZWDPbaGZbzOy+cuZHm9mb3vwlZta9DmPrYmYLzGy9ma01szvLKXOOmeWY2Srv56G6is/b/nYzW+NtO6mc+WZmf/WO32ozG1qHsfXxOy6rzOyQmf2uTJk6PX5mNtPMMswsxW9aGzP7zMw2e7/L7bvVzKZ4ZTab2ZQ6jO8JM9vg/f3eNbNWFSx73M9CLcb3RzPb4/c3vLiCZY/7v16L8b3pF9t2M1tVwbK1fvxqnHOu0fwA4cBWoCcQBSQD/cuUuRX4pzc8EXizDuPrAAz1hmOBTeXEdw7wQRCP4XYg/jjzLwY+BgwYCSwJ4t86Hd8DN0E7fsDZwFAgxW/a48B93vB9wGPlLNcGSPV+t/aGW9dRfBcCEd7wY+XFF8hnoRbj+yNwdwB//+P+r9dWfGXm/wl4KFjHr6Z/GtsVwnBgi3Mu1TlXALwBjC9TZjzwsjf8DnCemVldBOec2+ucW+EN5wLrgU51se0aNB6Y5XwWA63MrEMQ4jgP2Oqcq+qT6zXCObcQyC4z2f8z9jJwRTmLXgR85pzLds4dAD4DxtZFfM65T51zRd7oYqBzTW83UBUcv0AE8r9ebceLzztv/Bx4vaa3GyyNLSF0Anb5je/mpyfc78t4/xQ5QFydROfHq6oaAiwpZ/YoM0s2s4/NbECdBgYO+NTMlpvZLeXMD+QY14WJVPyPGMzjB9DOObcXfF8CgLbllKkvx/GX+K74ylPZZ6E23e5Vac2soMqtPhy/s4B9zrnNFcwP5vGrksaWEMr7pl+2XW0gZWqVmTUH/gX8zjl3qMzsFfiqQU4F/ga8V5exAWc454YC44DbzOzsMvPrw/GLAi4H3i5ndrCPX6Dqw3F8ECgCZldQpLLPQm15FugFDAb24quWKSvoxw+YxPGvDoJ1/KqssSWE3UAXv/HOQFpFZcwsAmhJ1S5Zq8TMIvElg9nOuX+Xne+cO+ScO+wNfwREmll8XcXnnEvzfmcA7+K7NPcXyDGubeOAFc65fWVnBPv4efaVVqN5vzPKKRPU4+jdxL4UuNZ5Fd5lBfBZqBXOuX3OuWLnXAkwvYLtBvv4RQBXAW9WVCZYx686GltCWAb0NrMe3rfIicCcMmXmAKUtOq4GvqjoH6KmeXWOM4D1zrk/V1Cmfek9DTMbju9vtL+O4mtmZrGlw/huPqaUKTYHmOy1NhoJ5JRWj9ShCr+ZBfP4+fH/jE0B3i+nzCfAhWbW2qsSudCbVuvMbCxwL3C5c+5IBWUC+SzUVnz+96SurGC7gfyv16bzgQ3Oud3lzQzm8auWYN/VrukffK1gNuFrgfCgN20avg8/QBN8VQ1bgKVAzzqM7Ux8l7WrgVXez8XAVGCqV+Z2YC2+VhOLgdPrML6e3naTvRhKj59/fAY84x3fNUBiHf99Y/Cd4Fv6TQva8cOXmPYChfi+td6E757UfGCz97uNVzYReMFv2V96n8MtwI11GN8WfPXvpZ/B0lZ3HYGPjvdZqKP4XvE+W6vxneQ7lI3PG//J/3pdxOdNf6n0M+dXts6PX03/6NUVIiICNL4qIxERqSIlBBERAZQQRETEo4QgIiKAEoKIiHiUEEREBFBCEBERz/8HQh/BWQmy1pYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(historico.history['val_loss'])\n",
    "plt.title('Erro')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(historico.history['val_accuracy'])\n",
    "plt.title('Acurácia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerar predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.5% de acertos.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "previsoes = modelo.predict(X_test)\n",
    "previsoes = [np.argmax(t) for t in previsoes]\n",
    "\n",
    "y_test_cm = [np.argmax(t) for t in y_test]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "confusao = confusion_matrix(y_test_cm, previsoes)\n",
    "tx_acerto = accuracy_score(y_test_cm, previsoes)\n",
    "distinct = np.unique(y_test_cm)\n",
    "\n",
    "print('%.1f%% de acertos.' % (tx_acerto * 100))\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(confusao, index = distinct, columns = distinct)\n",
    "\n",
    "ax = sns.heatmap(df_cm, annot = True, linewidths = 0.5, cmap = 'BuPu', fmt='g')\n",
    "ax.set(xlabel='Predict class', ylabel='Original class')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
